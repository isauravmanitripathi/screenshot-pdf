{
    "New item": {
        "chapters": [
            {
                "chapter_id": 1,
                "chapter_name": "CHAPTER 1",
                "chapter_path": "./screenshots-images-2/chapter_1",
                "sections": [
                    {
                        "section_id": 1.1,
                        "section_name": "Popular Approaches\nto Developing Trading\nSystems",
                        "section_path": "./screenshots-images-2/chapter_1/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_1/c93aae08-a0be-4fca-930d-e38102a6d394.png",
                            "./screenshots-images-2/chapter_1/section_1/ca6dff88-37fc-4b98-a301-a60f1a01b92f.png",
                            "./screenshots-images-2/chapter_1/section_1/58bb9952-2967-4add-941f-153a174c2e6b.png",
                            "./screenshots-images-2/chapter_1/section_1/4c30ad53-7942-4bc5-9f80-b42d9b37d6ac.png",
                            "./screenshots-images-2/chapter_1/section_1/9df384ba-fbd2-4e7f-9ff2-416bc3ed254c.png",
                            "./screenshots-images-2/chapter_1/section_1/ebf713f4-1676-41f6-8ea6-f48f8eabbf96.png",
                            "./screenshots-images-2/chapter_1/section_1/ad31329e-6dfa-4a93-b5e5-81feaac2f696.png",
                            "./screenshots-images-2/chapter_1/section_1/c1f188fc-d842-4252-8d9e-366696a18362.png",
                            "./screenshots-images-2/chapter_1/section_1/72a3531c-d492-430f-a1c4-ef1644824a49.png",
                            "./screenshots-images-2/chapter_1/section_1/ee5f696a-dcf3-4107-8264-f233f32a6ef3.png",
                            "./screenshots-images-2/chapter_1/section_1/bd9066c6-c4b3-432a-9334-3a0d4ef18c78.png",
                            "./screenshots-images-2/chapter_1/section_1/1cbbdddc-0ea4-4eaa-a7d3-996cd3a70c59.png",
                            "./screenshots-images-2/chapter_1/section_1/49f6f3de-206b-4fb5-b4ff-fb5e36fa632f.png",
                            "./screenshots-images-2/chapter_1/section_1/31406212-da8d-46eb-a977-d4f22f942a14.png",
                            "./screenshots-images-2/chapter_1/section_1/32f8a83d-631e-4e02-829a-96614e96725c.png",
                            "./screenshots-images-2/chapter_1/section_1/9a854369-7e9d-4393-8833-2b25f361179d.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "Before you start creating your own system, you must first look for possible\nways to implement it. Perhaps someone has already implemented your\nidea and there is no need to create your own program. Even if there is\nnothing like your idea on the market, you can still glean valuable insights\nfrom existing products.\n\nCurrently, there are many approaches to creating trading systems,\nranging from using conventional manual trading systems on the stock\nexchange to hiring third-party developers or a company to implement\nyour ideas. In fact, you can not only find ideas for trading systems on the\nInternet, but also find their implementations.\n\nIn this chapter, you will learn about the main approaches to creating\ntrading systems and consider their advantages and disadvantages. I will\nalso describe my approach and explain why I chose it.\n\nManual Trading\n\nThe most famous traders earned their fortunes through their knowledge,\neffort, and vast experience. If you want to follow their path, you need to\nhone your trading skills and increase your knowledge every day.\n\nThe essence of a trading system based on manual trading is an\nindependent search for successful strategies, gaining experience from\ndaily failures and successes. I am fascinated by successful traders who do\nnot use third-party assistant programs to trade. Naturally, these people use\nclassic charts provided by brokers, but they do the main work of analyzing\ntheir strategies on their own. No matter how popular artificial neural\nnetworks are, they do not yet have intuition and subconsciousness\u2014an.\nundeniable advantage of humans.\n\nHowever, it is worth noting that this plus is also a minus. Emotions and\ngreed have long plagued humanity, and traders are no exception. Often,\nwhen an important decision needs to be made, a person succumbs to the\ncrowd effect, or even panic, and thoughtlessly takes on unnecessary risk.\nThat is why, in manual trading, human error is high. Mistakes, in turn, lead\nto undermining the human nervous system.\n\nEmotions will never get the best of a trading robot. In addition, it is\ncapable of making decisions much faster than a human, and it does not\nrequire rest or sleep; therefore, the number of trading transactions it can\ncomplete is significantly greater than that of a human.\n\nReady-Made Signals and Algorithms\n\nThe easiest trading system to understand and implement can be based\neither on trading signals from other trading participants or on the signals\nor automatic trading of a trading robot that you have purchased. Both of\nthese approaches can generate income, but only if used correctly. Don\u2019t be\nduped by what their sellers promise. That is, you need to use them as tools\nand not all-encompassing solutions.\n\nSignals\n\nSignals in trading are hints or recommendations from a signal provider to\nmake purchases and sales of financial instruments. That is, a signal tells\nyou to buy or sell. In practice, if this signal is in the form an alert, it could\nlook like a short text message, as shown here:\n\nTSLA. Buy price 203, Sell price 208\n\nSignal providers can be both ordinary traders and serious experienced\nanalysts at specialized companies. There are a huge number of signal\nproviders on the market; the main problem is finding a high-quality and\nhonest company.\n\nSignals are convenient because they require absolutely no time to\ndevelop and test. When you buy one, you receive a ready-made solution;\nall that is required is to follow the instructions. But as they say, the devil is\nin the details. Despite the apparent simplicity of the signals, suppliers often\nhide or provide partial information about the logic of the decision-making\ninvolved, so users do not know exactly what logic the signal is based on.\nTherefore, to decide whether to work with a certain provider and its signal,\nyou need to carefully study its analytics.\n\nSignals come in different types depending on the control and price.\nThese divisions are somewhat superficial, but here are the distinctions:\n\n\u00a2 Hand signals. These are signals that the supplier\nprovides using manual trading. They are often the result\nof sitting in front of a monitor for a long time and studying\nthe instrument for a long time. Most likely, there will not\nbe very many of these signals from one supplier.\n\n\u00ab Automatic signals. These are signals based on the\ntrading algorithm of the supplier. That is, these signals\nare generated automatically. Naturally, with this\napproach, the number of generated signals will most\nlikely be higher than with manual signals.\n\n\u00ab Copy trading. When copying a trade, the seller\u2019s\naccount and the buyer\u2019s account are linked, and\nwhen the seller\u2019s account opens a transaction, it is\nautomatically opened in the buyer's account. This is a\nsimple principle that allows the buyer not to spend a\nlot of time trading. But the biggest disadvantage of this\ncase is the lack of sufficient control over your account.\n\n\u00ab Alerts. These are signals in the form of text messages\nthat tell the user what to do. I showed an example of\nan alert earlier. This is one of the safest types of signals,\nsince the decision for action and position size always\nremains with the account owner.\n\n\u00ab Account management. With this option, the client\ncompletely transfers control of their account to the\nsupplier. For this, the supplier will most likely take a\ncertain percentage of the profit. When choosing this\noption, you should carefully read the information about\nthe company providing such services. Also, there is a\nhigh risk of fraud here.\n\n\u00ab Free. Free signals are generally of lower quality than\nones that cost money. This is logical as almost no one\nwants to share the results of their work for free.\n\nAt first glance, the task of creating a trading system based on ready-\nmade signals looks simple. The user creates a portfolio of such signals\nfrom different suppliers and works on it. The main difficulty here is that it\nis necessary to spend quite a lot of time on analytics and on testing such\nsignals, constantly adding new ones and eliminating outdated ones. This\nmeans that the relative simplicity of creating such a system results in\nenormous difficulties and costs to maintain it.\n\nThird-Party Algorithms\n\nThe global trend to automate and algorithmize everything has now come\nto trading, and every year the number of algorithmic systems that help\ntraders or that even trade independently is growing. Anyone can buy an\nalgorithmic robot; you don\u2019t need to be a programmer.\n\nThere are so many of trading robots that the question becomes, why\nhaven't the people who created them used them to make themselves\nmillions? Some may have, of course, but ironically it\u2019s not so much thanks\nto trading, but rather thanks to the proceeds from selling the robots to\nconsumers.\n\nMy point is that you need to understand that no one would be selling\na trading robot if trading with it could bring in more money than the sales\nfrom the robot itself. This does not mean that there are no helpful robots,\njust that robots can only do so much with search and analytics.\n\nYou should also pay attention to the rather high price of robots. That\nis, you'll want to get a profitable trading algorithm but also earn back the\nmoney you invested in the robot. In fact, finding a decent robot that will\nwork consistently is quite difficult. At the time of writing this book, one of\nthe popular sites for selling algorithmic robots sells about 4,000 \u201cexpert\u201d\nrobots. Imagine how hard it is to analyze them all and make sure they\nwork! You should not only be looking at the reviews but also analyzing the\nindicators yourself before buying one.\n\nThat said, anyone who does not want to create all this from scratch\ncan easily buy a robot. In fact, some people have hundreds of such\nrobots in their portfolio and yet they don\u2019t spend a second of their time\ncreating them.\n\nThere are different types of algorithms used in robots. The types differ\nnot only in the logic of decision-making but also in money management,\naverage trading time, trading method, price, and many other parameters.\nIn addition, any trading robot must contain the analytical data of its work,\nwhich is valuable information for the buyer.\n\nThe following is a short list of indicators that can be used to analyze\na robot's performance; I will talk about them in more detail in the next\nchapter:\n\n\u00ab Expected value. This is an estimate of the average\nexpected return of a strategy during its long-term use.\nEssentially, it tells you how successful a strategy can be\nover the long term.\n\n\u00a2 Profit factor. This is an indicator of the effectiveness\nof a trading strategy, which is the ratio of the amount\nof profit to the amount of losses. This shows how your\nprofits compare to your losses.\n\n\u00ab Absolute drawdown. This represents the change in\nfunds in a trading account from the beginning to the\nend of the trading period.\n\n\u00ab Relative drawdown. This drawdown is the trader\u2019s\nlargest loss as a percentage relative to the previous\nmaximum balance.\n\n\u00ab Maximum drawdown. This shows the maximum\ndecrease in capital from the highest level it has ever\nbeen to the lowest it has ever been.\n\n\u00ab Recovery factor. The recovery factor is equal to the\nabsolute value of net profit divided by the maximum\ndrawdown. The higher the recovery factor, the faster\nthe system recovers after a drawdown.\n\nAs you can understand, there are many types of robots. The following\nare some of them:\n\n\u00ab Long-term, medium-term, short-term. This is a\nclassification based on the average time a position\nis held.\n\n\u00ab Short-term ones, in turn, are divided into arbitrage\nand scalping. Arbitrage robots open positions not on\none exchange but on several, but their positions are\nalways short-term and last literally milliseconds. In this\nthey are similar to scalping ones, but the latter trade on\nonly one exchange.\n\n\u00ab Automatic and semi-automatic. While automatic\nsystems carry out activities without human assistance,\nsemi-automatic ones require constant attention. This\nis because semi-automatic systems have much less\nfunctionality and are replaced by human labor. For\nexample, such a system may require information about\nthe size of the position being opened.\n\n\u00ab Expert advisors based on the Martingale principle.\nThis is a money management system in which after\neach unprofitable closing of a position, it is necessary\nto double the size of the next position. If the outcome\nis profitable, you can cover losses from the previous\ntransaction and return to the original position size.\n\n\u00ab Trend and oscillator. These are systems based on\ntechnical analysis.\n\n\u00a2 Nonindicator. These are specific algorithmic robots.\nExamples are systems that make decisions based on the\nanalysis of news sites or forums.\n\nFor short-term signals, one of the most important analytical indicators\nis the average time of holding a position. After all, if this indicator is equal\nto or less than one minute, this means you are dealing with scalper or\narbitrage signals. These signals are extremely sensitive to ping, and most\nlikely you will not have a chance to trade them in time. Therefore, I advise\nyou to consider signals only with a holding position of at least several\n\nminutes or more. Lengthy deals are also a bad sign. Perhaps the robot is\ntrying to wait out the accumulated losses on transactions and the decision-\nmaking logic contains a serious flaw, reflected in an untimely exit from the\nposition.\n\nIn addition, you should absolutely be scared off by Martingale advisors.\nDespite its apparent simplicity, this system will almost always lead you to\nlosing all your capital. With a long series of losing trades, your capital will\nbe reset to zero. It is quite easy to determine whether a system belongs\nto Martingale by looking at the balance chart and the funds chart. These\ngraphs for normal systems should be as close as possible and naturally\ntend to grow. A uniform alternation of open and closed positions also\nindicates the reliability of the system. But large gaps between charts and\nan increase in the number of open positions and a decrease in closed ones\nindicates Martingale.\n\nAutomatic robots are generally considered more reliable than semi-\nautomated ones. After all, the human factor is completely excluded from\nthem. But it should also be noted that they are much more complex in\ndevelopment than semi-automatic ones, and the price for the highest\nquality ones is, accordingly, higher. It is also worth noting the need for total\ncontrol over the operation of such a system so that you or the monitoring\nsystem can detect a problem in a timely manner and stop trading.\n\nThe market for algorithmic robots is dominated by trend and\noscillatory systems. And this is logical, because the formulas of technical\nindicators can be easily transferred into the program. They are easy to see\non stock charts and easy to analyze.\n\nThe undeniable advantage of any algorithmic robot is its ability\nto trade different instruments. In fact, this feature alone suggests that\nthe robot is quite reliable; it is obvious that this robot does not work by\nadjustment, which means that it will give good results in the long term and\nrespond well to market changes.\n\nSomeone who wants to create their own trading system based on\npurchasing algorithms can take the path of diversification and risk\nreduction. Buy a large number of robots for your portfolio, preferably\nworking on different principles, and use them comprehensively. In\nessence, the principle is similar to creating a portfolio from trading signals.\nHere, too, most of the time will be spent on constant analysis and testing.\nBut this approach, unfortunately, is more expensive.\n\nSpecialized Services\n\nAll the previous options have one drawback\u2014they do not implement your\nideas for trading strategies exactly. Of course, you can create your own\ntrading system using your own ideas. But what do you do if you have no\nprogramming skills? In this case, special services can come to the rescue,\nwhere it is possible, without any special knowledge, to assemble your robot\nstep-by-step. You can simply implement the decision-making logic and\nthen test and analyze the resulting strategy. Some services even allow you\nto set up the money management rules and risk control, and others allow\nyou to complicate the logic using a special scripting language.\n\nUnfortunately, it\u2019s difficult to create something specific with these\ntypes of services. For more advanced strategies, you need to learn at least\nan easy scripting language to go beyond simple logic. Some services\nprovide programming capabilities using languages such as Python or C#,\nboth of which allow you to create more complex algorithms. In addition,\nthere are many more such services other than \u201cconstructor\u201d services.\nThey usually have a large number of users and thus a developed learning\nenvironment.\n\nDifficulties arise when you want to create something unique to test a\ntheory that does not fit into the standard framework. This is the time to\nswitch to independent development or to hire third-party developers.\n\nIndependent Creation of a Trading Platform\n\nHaving your own trading system has a big advantage over other\napproaches\u2014you have the ability to test any of your theories since you are\nnot limited by the functionality included in a ready-made solution. The\nprospects for this direction are enormous, because they are not limited in\nany way, by anyone, or by anything. The process is surprisingly creative\nand unique to each developer. Moreover, the developer is not tied to any\nspecific programming language; you can use the technology stack that you\nknow. Most likely, once you choose this course, you will never switch to\nanother, simpler one.\n\nThe division into different approaches in this category is arbitrary.\nAfter all, adding or removing a functionality to/from a program changes\nthe system every time, and it becomes completely different. But still, let\u2019s\nlook at some different approaches so that you have an idea of what suits\nyou best.\n\nTesting a Single Strategy\n\nLet\u2019s imagine that you have a brilliant idea and want to test it. You will\nquickly program the logic and test it through your own or some third-\nparty service. Everything that your trading system will contain is a single\nstrategy. At the same time, the functionality of your trading platform is not\nimportant; it may or may not contain a testing or optimization module. All\nyour platform does is trade according to a single given scenario.\n\nThe undeniable advantage of this approach is its high development\nspeed. You don\u2019t need to worry about the optimal value of your strategy\nparameters or the impact of any indicator on performance.\n\nThe obvious disadvantage is the lack of understanding of what can\nbe improved in the strategy or how the performance would change if you\nadded or removed some condition or changed some indicator parameter.\n\nRoughly speaking, the main disadvantage is a lack of searching for the\noptimal strategy for your theory. But there is a theory in your strategy; you\njust immediately set certain parameters for it.\n\nHere is an example of this strategy.\n\nInput signal:\n\nBBW > 0.05\n\nWMaA < Open Price\nOutput signal:\n\nBBW < 0.01\n\nRSI > 30\n\nYou can, of course, evaluate this strategy in terms of performance\nindicators, but it would be much better to consider how these indicators\nchange if the specific parameters of the strategy also changed. The brute-\nforce method will be the easiest to implement here.\n\nThe brute-force method, although ancient and elementary, has always\nhelped humanity in incomprehensible situations. It can also serve an\nexcellent purpose for a simple developer. If you implement the brute-force\nmethod into the previous strategy, you can see how the specific value of\neach parameter affects performance. That is, by setting a specific range\nand step, you can build a graph of changes in any performance indicator\ndepending on changes in the parameter.\n\nThe brute-force method does an excellent job of analyzing the influence\nof specific values of indicator parameters on the effectiveness of the theory.\nThus, by sequentially or comprehensively going through all the possible\noptions for parameters, you can conduct an accurate analysis of the theory.\nBut this method is effective only on a small number of parameters. If the\ntheory contains a large number of possible strategy options, then finding the\noptimal value will take an incredibly large amount of time.\n\nVarious Developer Approaches\n\nBasically, those who really take the matter seriously develop entire\ntrading platforms with a lot of functionality. Some write their own analog\nof the exchange to have their own independent testing. Optimization\nmodules, modules for searching for optimal strategies, real trading\nmodule, money management module, and much more. Some write\ntheir own analog of the exchange to have their own independent\ntestingTrading system developmentindependent testing, optimization\nmodules, modules for searching for optimal strategies, real trading\nmodule, money management module, and much more.\n\nThe theories that cannot be verified by standard auxiliary services\ncan be verified in your own system. For example, say you want to test the\nmarket psychological theory that the stock price of a certain company\ndirectly depends on mentions of this company on social networks. You\ncan create a parser that could analyze the mood of the masses using\nhashtags and generate signals when a critical mass is reached in a positive\nor negative direction. Or you have the idea that some stocks are directly\ndependent on other stocks. Or that a certain company\u2019s stock goes up\nwhen it rains. Crazy? Maybe, but you can test all your ideas when you do\nindependent development.\n\nHiring Third-Party Developers\n\nAt some point, a mechanical trading trader may decide to automate\ntheir system, in whole or in part, which will allow them to free up more\ntime for deeper analysis and improvement of trading strategies and\ntheories. However, if the trader has no programming experience, this can\nbe intimidating. After all, no one wants to spend months or even years\nstudying this when it\u2019s unclear whether the time spent will pay off.\nTherefore, despite that there are many services on the market that\nhelp you create a full-fledged trading robot, it is still a very labor-intensive\n\ntask. As a result, it is often the successful traders who consider hiring an\nexperienced engineer to design and develop their own trading system.\nThat is, when someone has a great theory but neither the time nor the\nopportunity to implement the idea programmatically, they often hire third-\nparty developers.\n\nThe first disadvantage of this approach is the need to share your\nprofitable idea with other people. This may lead to the emergence of\ncompetitors who then start working according to your theory. So, you need\nto protect your intellectual property. A special contract may help with\nthis, but it still may not help. In any case, you definitely shouldn't trust the\ndevelopers\u2019 word. It may seem right to share only part of your idea with\nthe developer, but in this case, the developed system may not work as you\noriginally planned. Therefore, if you decide to hire programmers, then it is\nbetter to draw up the detailed technical specifications yourself.\n\nThe second disadvantage is that it is unclear whether you will recoup\nyour development costs. You spend a lot of money to bring your theory to\nlife, but it might not lead to any profit.\n\nAnother important question is where to find a good developer for your\nsystem. There are also many paths here. The route of hiring a third-party\ncompany seems to be the most suitable, and most likely your intellectual\nproperty will remain yours. After all, a company\u2019s reputation is worth a\nlot. But be prepared to spend more money than if you hired a freelance\ndeveloper.\n\nMy Approach\n\nEach of the previously discussed approaches has its place, and each of\nthem is capable of bringing profit to the trader. In this book, I will describe\nmy approach and how I created a trading platform without hiring third-\nparty developers, without using specialized programs, and so on.\n\nIn the beginning, I analyzed the existing approaches of developing\ntrading robots, studied the robots for sale at that time, read blogs of\nsuccessful practicing algorithmic traders, and so on. As a result, I realized\nalmost all traders were looking for super-profitable strategies. It had to be\na strategy that brought 1,000 percent per month and had a drawdown of 1\npercent and no more. Of course, each trader had their own concept of an\nextremely profitable strategy, but most of them would not even look at a\nstrategy with a very modest result of 3 percent per year.\n\nI didn\u2019t initially understand this concept. After all, even if a person\nis very smart, there is a possibility that they will not be able to find such\na strategy even if they spend their whole life searching. I understood\nthat the likelihood that I would find a super-profitable strategy was very\nlow. So, I decided to try the diversification approach. I thought, what if I\ncreate strategies that are fundamentally different, with modest indicators,\nfor example, 0.5 to 1 percent per month, but use them in real trading in\nhundreds? Most likely, there are many more such strategies than super-\nprofitable ones, and, naturally, they are much easier to find.\n\nAs a result, I chose the option of completely independent development\nwith the idea of automatically searching for many profitable strategies, but\nwith modest indicators. Of course, if the system finds a super-profitable\nstrategy, then good; if it doesn\u2019t find it, it\u2019s OK. Thus, I wanted to create\na system that every developer could do independently and that could\nalmost 100 percent of the time generate additional income. Yes, it may\nnot be millions of dollars, but it will work consistently and will require low\noperating costs.\n\nThe big disadvantage of this approach is that it takes a huge amount of\ntime to implement. In fact, this process will never end. I constantly want\nto improve something or add some functionality. But this is a very creative\nand interesting process that I advise for everyone.\n\nSummary\n\nIn this chapter, I briefly discussed the types of trading systems and how to\ncreate them, and I discussed their advantages and disadvantages.\n\n\u00ab Manual trading. The main advantage of this approach\nis the complete absence of labor costs for creating a\ntrading system, as well as the use of human intelligence\nand experience. Among the shortcomings, the most\nstriking are instability due to the emotional state of\na person, as well as a relatively low number of open\npositions.\n\n\u00ab Trading using ready-made signals. The advantage of\nthis approach is that there is no need to implement a\ntrading system. The main disadvantage is that you must\ntrust the experience of others, with a possible lack of\nunderstanding of the logic of how the signals work.\n\n\u00a2 Trading using purchased algorithmic robots. Again,\nthe undeniable advantage of this approach is that\nthere is no need to create a trading system. You will be\nworking using someone else's system. This also entails\ndisadvantages: you will understand the real capabilities\nof system only after the purchase. And often you will\nmisunderstand the internal logic of such systems.\n\n\u00ab Independent development of individual strategies.\nThis is a popular approach primarily because of its\nsimplicity and flexibility. You can implement your own\nunique strategy, but speed comes at the cost of limited\nfunctionality.\n\nHiring third-party developers. With this approach\nyou can get almost anything, including implementing\nmy approach in developing a trading system. The\nmain disadvantages are the difficulty of finding good\ndevelopers, the need to share your ideas, and the\nhigh cost.\n\nIndependent development of a trading system.\n\nWith this approach, you either independently or in a\ncircle of a small number of partners independently\nimplement nota single strategy but an entire system\nwith automatic search, testing, and launch strategies.\nThe obvious advantage of this idea is the flexibility of\nstrategy implementation. The big disadvantage of this\napproach is the large labor costs for implementing such\na system.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 2,
                "chapter_name": "CHAPTER 2",
                "chapter_path": "./screenshots-images-2/chapter_2",
                "sections": [
                    {
                        "section_id": 2.1,
                        "section_name": "Introduction to\nDeveloping Trading\nSystems",
                        "section_path": "./screenshots-images-2/chapter_2/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_2/section_1/df20bcae-96d7-4c53-aae0-31d98d02e7b7.png",
                            "./screenshots-images-2/chapter_2/section_1/3f494ef3-6634-411d-bfb8-4054ac3cb5cc.png",
                            "./screenshots-images-2/chapter_2/section_1/1d6e2437-513b-4f8d-99a8-c0e2e3f095d9.png",
                            "./screenshots-images-2/chapter_2/section_1/6aaf2ab3-d39b-4ff7-9f37-9fffc791da37.png",
                            "./screenshots-images-2/chapter_2/section_1/9854cd9e-4b49-41e1-bdb7-679533ae9b1d.png",
                            "./screenshots-images-2/chapter_2/section_1/420a13de-a969-44f7-9f51-c40d6d36e4a3.png",
                            "./screenshots-images-2/chapter_2/section_1/22204e70-ec9e-4ba3-8ba5-bea2109eb1dd.png",
                            "./screenshots-images-2/chapter_2/section_1/106e54c2-6daa-44f7-88d9-c1ff6817455f.png",
                            "./screenshots-images-2/chapter_2/section_1/71ea096b-1d84-457f-8050-dea5c7ba6ac4.png",
                            "./screenshots-images-2/chapter_2/section_1/78d2c33b-15e3-4d5e-b810-99227aabc816.png",
                            "./screenshots-images-2/chapter_2/section_1/99ed6039-55a0-4b6e-9bd8-24416f376686.png",
                            "./screenshots-images-2/chapter_2/section_1/026bfff9-911c-43a0-88eb-04e4c28a7af1.png",
                            "./screenshots-images-2/chapter_2/section_1/4a913f20-f9c4-41af-a2f0-c8491cb3d378.png",
                            "./screenshots-images-2/chapter_2/section_1/60a2ff8d-d7f0-4232-bc9d-02cf7043a24e.png",
                            "./screenshots-images-2/chapter_2/section_1/9199f051-caf2-4af6-a51a-5f092c31d813.png",
                            "./screenshots-images-2/chapter_2/section_1/812c8361-a7a9-432c-b039-88b5d6583b62.png",
                            "./screenshots-images-2/chapter_2/section_1/bfa9737b-6217-4543-bf71-756a252a38b7.png",
                            "./screenshots-images-2/chapter_2/section_1/0c36ba94-c39b-4e62-937c-d1e825f7c5a8.png",
                            "./screenshots-images-2/chapter_2/section_1/62644da6-04d4-4903-b19e-8b7691acb2bd.png",
                            "./screenshots-images-2/chapter_2/section_1/1dd7ea06-1da9-4dd7-89e8-bab4667472a8.png",
                            "./screenshots-images-2/chapter_2/section_1/c620a9a2-e815-4450-89c6-1f62ad502a93.png",
                            "./screenshots-images-2/chapter_2/section_1/fba6569b-bd05-432f-8a9f-07a3f4c80aac.png",
                            "./screenshots-images-2/chapter_2/section_1/d0da8303-db1d-4209-8f91-0fc96e583c19.png",
                            "./screenshots-images-2/chapter_2/section_1/3f4ae662-fe11-491d-86e5-5ea638596278.png",
                            "./screenshots-images-2/chapter_2/section_1/e051bb27-a927-4541-8d4e-918515bb8a64.png",
                            "./screenshots-images-2/chapter_2/section_1/c0e59cfa-9e59-49df-af05-c1cfbe574ffa.png",
                            "./screenshots-images-2/chapter_2/section_1/d31b6376-2acd-4806-bb3e-c6a6b50a81cd.png",
                            "./screenshots-images-2/chapter_2/section_1/64d0ad60-ab45-4819-8bb4-16a675ac6b5b.png",
                            "./screenshots-images-2/chapter_2/section_1/dec6e253-7a87-4a81-b75f-5736183938ef.png",
                            "./screenshots-images-2/chapter_2/section_1/4fc4e479-6f05-4090-a354-713c5b1cff5c.png",
                            "./screenshots-images-2/chapter_2/section_1/26e44e91-5ae4-4a85-b18e-5fd1131bdd75.png",
                            "./screenshots-images-2/chapter_2/section_1/171e699c-ce24-44a8-beea-7ca2bd2b98ad.png",
                            "./screenshots-images-2/chapter_2/section_1/09941dd6-8d78-49ef-9f24-04362b6913db.png",
                            "./screenshots-images-2/chapter_2/section_1/b68a2478-60d0-4172-9f88-307b570dacc4.png",
                            "./screenshots-images-2/chapter_2/section_1/6336463d-540f-44bf-b4df-d514fd1990d9.png",
                            "./screenshots-images-2/chapter_2/section_1/baefe368-707e-4034-9684-fde53ec49d68.png",
                            "./screenshots-images-2/chapter_2/section_1/b7ce6a61-987b-4bc6-b4e6-aa7224106d91.png",
                            "./screenshots-images-2/chapter_2/section_1/9443f9fb-b286-4dcc-9765-30bb3fa6cd21.png",
                            "./screenshots-images-2/chapter_2/section_1/471f55af-cd4d-4cb5-b38d-289acc1949c9.png",
                            "./screenshots-images-2/chapter_2/section_1/d929425c-b379-4ae4-af19-8dea84913ce1.png",
                            "./screenshots-images-2/chapter_2/section_1/67bccf5e-30a9-4501-87f3-8e9b4a87803e.png",
                            "./screenshots-images-2/chapter_2/section_1/fe97801e-0606-4b7a-a27a-0a1a59ad9b98.png",
                            "./screenshots-images-2/chapter_2/section_1/25bab102-7bb2-474c-9ebe-834c384e9b68.png",
                            "./screenshots-images-2/chapter_2/section_1/2d86a96b-b9bf-4926-84b4-427c8732c7d5.png",
                            "./screenshots-images-2/chapter_2/section_1/c019a2de-2737-45c0-b5e2-fe457c468c65.png",
                            "./screenshots-images-2/chapter_2/section_1/8570533e-7f66-4182-bf22-03f39a98a2ee.png",
                            "./screenshots-images-2/chapter_2/section_1/8feebb94-c9cf-4eef-b60c-54ed53ab3ac9.png",
                            "./screenshots-images-2/chapter_2/section_1/45087daf-2dbf-424f-b41b-41a4f6868e84.png",
                            "./screenshots-images-2/chapter_2/section_1/a05a05c7-ffa7-4d50-b24f-c9f9cf097926.png",
                            "./screenshots-images-2/chapter_2/section_1/4685fd76-d9a2-4efb-b6fc-5da76fc3b983.png",
                            "./screenshots-images-2/chapter_2/section_1/81d1943b-fd40-4319-8db5-2810c9234ec2.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "To move on to the next chapters, which contain specific information about\nthe architecture and technical solution of my system, we must consider\nthe basic concepts related to stock trading. If you know what types of\nmarkets exist, how limit orders work, and what anti-Martingale money\nmanagement is, you can skip this chapter and move on to the next one.\nBut if you want to create your own trading system and don\u2019t know where\nto start, then I strongly recommend reading this chapter so that you don\u2019t\nhave questions when studying further topics.\n\nIn this chapter, we will briefly review the general theory of exchange\ntrading, consider the approximate composition of a trading system, and\ndwell in detail on the formation of a trading theory, since this is the main\ntopic of this book. We will also study the main approaches to capital\nmanagement and risk control and touch on the topic of testing and\noptimization a little. This chapter, in fact, is just a bit of the knowledge that\nis necessary to start creating your own trading robot but without which the\nfurther steps are impossible.\n\nGeneral Theory\n\nFirst, we need to understand what stock trading is. To do this, let\u2019s look at\nthe basic concepts in simple terms.\n\n\u00ab Anexchange is a kind of organized trading platform\nwhere buyers and sellers meet to make purchase/sale\ntransactions in financial instruments such as stocks,\nbonds, commodities, and currencies.\n\n\u00ab Abroker is an intermediary between the investor\n(trader) and the exchange. It provides access to stock\ntrading, fulfils customer orders, provides market\ninformation, and provides various financial services.\n\nThe relationship between the broker and the exchange consists of two\nmain points. First, this is the order execution chain. This is when a broker\nexecutes various orders from investors, sending them to the exchange for\nprocessing by the exchange itself, thereby ensuring that traders interact\nwith the real market. It is worth noting that the broker can provide access\nnot only to one specific exchange but to many different ones, which\nallows the trader to expand their working hours and the list of financial\ninstruments with which they can work.\n\nSecond, the broker provides traders with current information on the\nstate of the market, analyst reviews, news, and other data that can help\nmake a trading decision. The broker also conducts a technical analysis of\nthe trader\u2019s transactions, showing the status of orders and the movement\nof funds in the account.\n\nIn addition, some brokers provide advice and counsel to clients\nregarding their investment strategies and portfolio state. Or they can even\ndirectly manage clients\u2019 financial accounts. Thus, the broker and the\nexchange are closely interconnected in the process of exchange trading,\n\nwhere the broker acts as an intermediary, providing traders with access to\nreal exchange markets and providing them with the necessary services and\nfacilities for successful participation in trading.\n\nWhen people talk about financial instruments, they mean anything\nthat can be bought or sold to make or save money. For example, company\nstocks, bonds, debt obligations, and even cryptocurrencies such as Bitcoin\nand Ethereum are all financial instruments. These tools help people invest\n\nand manage their finances.\nLet\u2019s take a closer look at the main types of these financial instruments.\n\nStocks. In short, a stock is ownership in part of the\ncompany\u2019s property. Traders who hold shares are\ncalled shareholders.\n\nBonds. These are debt securities that represent some\nkind of promise by a company or government to\nrepay the trader's borrowed funds with interest. But\nunfortunately, they may not keep their promise.\n\nCommodities. These are the most tangible assets\u2014real\nphysical goods such as gold, oil, or grain\u2014which can be\nbought and sold on the market.\n\nCurrencies. The simplest asset is the monetary units of\nvarious countries that have the right to be traded on the\nforeign exchange market.\n\nDerivatives. These are financial instruments whose\nvalue depends on changes in the price of another\nfinancial instrument, called an underlying asset. Simply\nput, derivatives \u201cderive\u201d from another asset and allow\ninvestors to bet on changes in its value. Examples\ninclude futures, options, and swaps.\n\n+ Indexes. They can easily be thought of as a portfolio of\nstocks or other financial instruments that represent the\noverall performance of a market or sector.\n\n\u00ab Investment funds. These are funds that pool money\nfrom different traders to invest in a variety of assets.\n\n\u00ab Cryptocurrencies. This is the newest type of asset.\nCryptocurrencies are decentralized digital currencies\nthat use cryptography to ensure transaction security.\n\nIt\u2019s also worth mentioning dividends. Some companies pay out a\nportion of their profits to their shareholders. Dividends are paid to attract\nnew shareholders and reward old ones. The amount paid is directly\nproportional to the number of shares held by the holder. Overall, dividends\nare an important aspect for investors, providing them with additional\nincome from owning shares in a company. Finally, it is worth adding\nthat dividends are not only paid to stockholders; some types of bonds,\ninvestment funds, exchange-traded funds (ETFs), and derivatives can also\nbe a source of this income.\n\nThe concept of a financial instrument goes hand in hand with the\nconcept of a ticker, which is a unique symbolic code. It is used to identify\na specific asset in the financial market. A ticker usually consists of several\nletters that are associated with a specific company, currency, commodity,\nor other type of financial asset. They make it easier to identify and track\nprice changes in the market because they are a compact and unique\ndesignation for each asset.\n\nThe following are some examples of tickers:\n\n\u00ab TSLA: Tesla Inc. stock ticker\n\n\u00ab JPYUSD: Ticker for the Japanese yen to U.S. dollar\ncurrency pair\n\n\u00a2  CC1!: Ticker for the commodity Cocoa\n\n\u00ab ADAUSD: Ticker for the Cardano cryptocurrency\nagainst the U.S. dollar\n\nOrder Execution\n\nNow that you know what a financial instrument is, you need to understand\nhow to sell and buy it. To carry out these actions, the broker provides us\nwith such a tool as an order. In trading, an order is an instruction sent from\na trader to a broker or trading platform to execute a trade in a financial\nmarket. The order specifies what operation the trader wants to perform\n(buy or sell) and also determines the main parameters of the transaction,\nsuch as volume (number of assets) and price. Any order contains special\ncharacteristics, such as order type, order direction, instrument ticker,\nand volume.\n\nLet's take a quick look at what each characteristic means.\n\n\u00a2 Order type. This determines the way a trader can\ninteract with the market and implement their trading\nstrategies. The main types are Market, Limit, Stop\nOrder, Stop Limit Order, Take Profit Order, Stop Limit\nFor Sale, Market On Open, Market On Close, Market If\nTouched Order, and One Cancels The Other Order.\n\n\u00a2 Direction of the Order. This indicates the trader\u2019s\ndesired action in relation to the asset. It determines\nwhether the trader wants to buy or sell an asset. Two\npossible directions are Buy Order and Sell Order. Buy\nexpresses the trader\u2019s desire to purchase an asset, and\nSell expresses the trader's desire to sell.\n\n\u00ab Volume. This is the quantity (of shares, bonds, etc.)\nthat the trader wants to buy or sell\n\n\u00a2 Price. For limit orders, this is the price level at which\nthe trader wants to carry out a transaction, for stop\norders, upon reaching which the order is activated.\n\n\u00a2 TimelnForce. This indicates the duration of the order's\nrelevance.\n\nIn fact, there are only two main types of orders: market and limit.\nMarket reflects a trader's request to buy or sell an asset at the current\nmarket price. Limit is the same request, but the purchase or sale must be\ncarried out at the price level specified by the trader. To better understand\nthe difference between them, let's look at what happens after an order is\ncreated.\n\nAfter it is created by the trader, it is sent to the so-called Depth of\nMarket order book (order book). The order book is a representation of the\ninteraction of all orders for the current financial instrument. Market orders\nmake instant changes to the order book, while limit orders form a display\nof it, providing information about the price levels, resistance, and support\nlevels at which market participants are willing to trade.\n\nThis happens because the nature of a market and limit order is\ndifferent. The market order is immediately executed at the current buy or\nsell price, changing the level of supply and demand, and the limit order\nfixes the specific price at which the trader is ready to buy or sell a specific\nasset. Let's take a look at Figure 2-1.\n\nMarket Buy\nVolume - 20\n\nLimit order Market order\n\nBuy Price Sell Buy Price Sell Buy Price Sell\n\nBuy Price Sell Buy Price Sell Buy Price Sell\n\nFigure 2-1. Limit and market purchase and sale process\n\nFirst, we see the order book before the trader creates any orders. Then\nthe trader created a limit sell order with a volume of 7 lots at a price of\n20.02. On the second order book you can see how the total volume in the\nexchange order book at the level of 20.02 increased by exactly 7 units. It's\neasy to guess that our trader\u2019s limit order contributed to this. Next, the\ntrader decides to create a market buy order with a volume of 20 lots. This\norder will work immediately: first, 18 lots will be purchased at a price of\n20.01 and then another 2 lots at a price of 20.02. The example is given only\nfrom the point of view of the nature of order execution. It is unlikely that\na real trader will make such a chain of orders on one instrument at the\n\nsame time.\n\nAs you might have guessed, a financial instrument essentially has two\nprices; one is the maximum buy price (bid), and the other is the minimum\nsell price (ask). The combination of these two prices is called the quote.\nThat is, a quote means the current price of a financial instrument at which\na trader can buy or sell this instrument. The difference between these\nprices is called a spread, which depends mainly on the liquidity, volatility\nof the financial instrument and the cost of order processing at the broker.\nI'll talk more about volatility later in this chapter.\n\nMargin and Leverage\n\nSome traders use a broker\u2019s service such as leverage to increase potential\nprofits. Leverage gives them the ability to trade larger volumes than their\nown funds allow. It shows the ratio of how many more funds can be used\nin a transaction compared to your own funds. For example, with a leverage\nof 1:50, a trader can trade 50 times more than they have in their account.\nThis allows the trader to invest in more expensive assets that they would\nnot have enough money for using only their personal funds.\n\nLeverage implies the use of another concept: margin. Both of these\nconcepts relate to the use of brokerage leverage but are expressed in\ndifferent forms. Thus, margin is a specific amount of money that a trader\nis required to provide to participate in trades, while leverage determines\nhow much these funds increase their purchasing power in the market.\n\nIt turns out that the trader deposits margin as collateral, which ensures\nthe execution of transactions and covers potential losses, and the broker\nprovides the remaining funds.\n\nThere are two main types of margin.\n\n\u00a2 Initial margin. This is the minimum amount to open a\nnew position.\n\n\u00ab Maintenance margin. This is the minimum amount to\nmaintain an open position.\n\nIt is worth noting that when using margin and leverage, the trader pays\nthe broker a commission for providing borrowed funds. These expenses\nmay reduce the overall profit from transactions. But the main drawback is\nthe greatly increased risk in conditions of strong market fluctuations, since\nthe losses can exceed the trader\u2019s own funds. Therefore, it is important to\nuse these tools with caution.\n\nComposition of the Trading System\n\nFor a trader to begin to think through the architecture of their trading\nsystem, they still need to know what it consists of and what its main\npurpose is. Let\u2019s start with the goal.\n\nThe goal of any trading system created will most likely be to obtain\na main or additional source of income. But bad news\u2014we will not be\nable to assess the potential of the system either at the idea stage or at the\ntesting stage. The efficiency will be visible only when the minimum set\nof necessary functionality is developed and when the system is tested in\nreal trading. Therefore, the stage of determining the financial goal for the\ntrading system being developed can be a thankless task.\n\nBut this minus more than outweighs the plus that the more time we\ninvest in developing and thinking about the strategy and functionality\nitself, the higher the potential efficiency. It turns out that our main goal is\nthe continuous improvement of the system. This is our guiding star and\nour motivation. After all, our financial results will be directly related to this\nstrategic goal.\n\nWith this goal figured out, what's next? The trader needs to come\nup with their own trading strategy, test it, think through risk control and\nmoney management, and evaluate the effectiveness of the system. For\neach of these tasks, the trading system should have its own separate\nmodule. Each of these key modules will perform specific functions.\n\nMoreover, these modules must work interconnectedly, providing a full\ncycle of trading operations. Effective interaction between them is the key to\nthe successful operation of the trading system.\n\nNow let\u2019s look at these main modules:\n\n\u00a2 Formation ofa trading theory. This module is based\non a multistep process that includes various steps\nsuch as choosing an approach (technical analysis,\nfundamental analysis, etc.), choosing a market\nstructure to trade (volatile, bearish, bullish, etc.),\nchoosing a time frame, choosing a trading strategy, and\ncreating rules trading and specific signals generated\nbased on these rules.\n\n\u00a2 Testing. This is an important step before using the\nsystem in real markets. This includes the selection\nof market data, determination of evaluation criteria,\npreliminary testing, backtesting, forward testing, and\nevaluation of results.\n\n\u00ab Capital management. The main goal here is to\nensure sustainability and minimize risks in trade.\nThis includes choosing an approach to determine the\noptimal position size.\n\n\u00a2 Risk control. This module closely intersects with\nmoney management and is responsible for ensuring\nfinancial stability and protection against potential\nlosses. The purpose of the module is to determine\nthe maximum level of risk, use stop-loss orders,\ndiversify the portfolio, and reassess risks when market\nconditions change.\n\n\u00a2 Efficiency mark. This is an important stage to\ndetermine its quality and potential success in the\nmarket. The main task is to calculate performance\nindicators such as profitability, Sharpe ratio, maximum\ndrawdown, profit factor, and other metrics.\n\n\u00a2 Optimization. This module is based on a dynamic\nprocess, the task of which is to find the best parameters\nand settings of the strategy to achieve maximum\nefficiency and profitability. Great importance is paid to\noptimization algorithms.\n\nIn my opinion, each of these modules is desirable but not required.\nAfter all, each algorithmic trader has their own path, and they can create a\ntrading program that is completely unique in structure.\n\nTrading Theory\n\nIf we do not want to play roulette, then before real trading, we must\nformulate our trading theory: the idea on which all deals will be based.\nThe purpose of trading theory is to create a system of rules and strategies\nthat allow a trader to make reasoned decisions about entering and exiting\nthe market. Based on these rules, specific signals will be generated in the\nfuture. This is one of the most important stages of creating your system, so\nwe will start with it.\n\nJust as a plant cannot grow without a seed, a trading system will never\nbecome profitable without a quality theory. But how is one formulated?\nWhere do ideas come from? There are actually a lot of options, and first,\nlet's highlight the main approaches in the formation of trading theories,\nand then I will talk in more detail about some of them.\n\nTechnical analysis. This method of analyzing financial\nmarkets relies on examining and interpreting price and\ntrading volume charts to identify trends and predict\nfuture price movements.\n\nFundamental analysis. This method of analysis is\nbased on the study of financial, economic, and other\nfundamental data to make trading decisions.\n\nMixed approach. This is a combination of technical\nand fundamental analysis. This approach uses both\nfundamental data and technical indicators to more\nfully and informedly predict market movements.\n\nAutomatic theory formation in algorithmic trading.\nIn this approach, a trading strategy is created and\noptimized automatically using algorithms and/or\nmachine learning. This method allows algorithms to\nanalyze historical data, identify patterns and trends,\nand then generate trading signals and strategies based\non this data.\n\nEvent trading. This is a sibling of fundamental analysis,\nbut while the fundamental approach is primarily\nfocused on the long term, event trading focuses on\nshort-term price changes associated with specific\nevents or news. Traders using this approach often seek\nto make a quick profit on the volatility caused by the\nmarket's reaction to news. Event trading is a dynamic\nand fast-paced approach to trading that requires the\ntrader to be alert to news and events occurring in real\ntime and to respond quickly to create profitable trading\nopportunities.\n\n\u00ab Own unique theories. This is an interesting and\ncreative approach where everyone can see a\nconnection or pattern that has not previously been\nnoticed by other traders.\n\nAs a result, the choice of a specific approach or a combination of\nthem is a personal matter for everyone. Now let's look at some of them in\nmore detail.\n\nTechnical Analysis\n\nTechnical analysis is perhaps the most popular. This is easily explained\nby the fact that it uses graphs, making it relatively easy to understand.\nGraphs can be easily understood and interpreted by most traders, making\ntechnical analysis accessible even to beginners. Additionally, technical\nanalysis techniques are applicable to a wide range of financial instruments\nand markets, including stocks, commodities, and others. It turns out that\nthis is one of the most universal trading tools. And its easy automation\nmakes it easy to use in the development of robotic trading systems. This\nhelps traders use strategies without constantly monitoring the market.\nAnother advantage is that technical analysis uses historical data for testing,\nwhich makes it possible to easily analyze strategies.\n\nTechnical analysis includes different areas, each of which focuses on\ndifferent formats of price movement.\n\nThese are the main functions of technical analysis:\n\n\u00ab Graphical analysis\n\n\u00ab Indicators and oscillators\n\u00abTrend analysis\n\n\u00a2 Geometric analysis\n\n\u00ab Fibonacci retracement and extension\n\nGraphical Analysis\n\nGraphical analysis means using visual representations of price activity to\nmake trading decisions. The basic idea is that price information is reflected\nin charts, and analyzing these charts can help traders predict future price\nmovements and come up with the right strategies. This allows you to identify\ntrends, resistance, and support levels, as well as patterns and optimal entry\nand exit points. Graphical analysis mainly uses candlestick, bar, line, point,\nfigure, and Renko charts. You can see examples of these charts in Figure 2-2.\n\nPoint & Figure! Renko\n\nfi i\n\nCandlestick\n\nitt\n\nFigure 2-2. Types of charts\n\nLine\n\nIndicators and Oscillators\n\nIndicators and oscillators are mathematical expressions that are based on\nprice and volume activity in the market. They can be visualized on a chart\nand can be conveniently used for analysis when making trading decisions.\nIndicators and oscillators help traders assess the current market situation,\nidentify potential reversal points or continuation of a trend, and determine\noverbought or oversold levels of an asset.\n\nIndicators also help traders determine general trends, the direction\nof market movement, and the strength of the trend. They are often\nrepresented on charts as lines or curves, plotting values on a price axis\nor separate scale. Indicators are varied and can be classified according to\ntheir main functions.\n\nThe following are several main types of indicators:\n\nTrend indicators. Examples are Moving Average (MA),\nMoving Average Convergence Divergence (MACD),\n\nthe Bollinger Band (BB), and Parabolic SAR. They help\ndetermine the general direction and strength of a trend.\n\nOscillators. They are typically used to measure\nwhether a market is overbought or oversold and\nprovide signals about possible turning points. They\nusually fluctuate around a central line (such as the\n\nzero line) and are charts often located below the main\nprice chart. Examples including Relative Strength Index\n(RSI), Stochastic Oscillator, Commodity Channel Index\n(CCI), and MACD.\n\nVolume indicators. Examples include On-Balance\nVolume (OBV), Chaikin Money Flow, and Volume\nPrice Trend (VPT). Their function is to analyze\n\ntrading volumes and help in assessing the strength of\na trend and confirming its direction. And some still\ndepend not only on volume but also on price such as\nVolume Weighted Average Price (VWAP) and Money\nFlow Index (MFI). They combine price and volume\ninformation to help determine the average price based\non trading volume.\n\nVolatility indicators. Examples are Bollinger\nBands and Average True Range (ATR). They reflect\nprice volatility, allowing you to identify support\nand resistance levels, as well as when the market is\noverbought or oversold.\n\n\u00ab Momentum indicators. Examples include Relative\nStrength Index (RSI), Momentum, and Stochastic\nMomentum Index. Their function is to measure the\nmomentum of price movements and help identify\npossible turning points.\n\n\u00ab Cyclical indicators. Examples include Detrended\nPrice Oscillator (DPO) and Schaff Trend Cycle. They\nhighlight cyclical components in price data, which can\nhelp predict future trend changes.\n\n\u00a2 Other indicators. Examples include Ichimoku Cloud,\nElliott Wave Theory, and Gartley Pattern. Their\nfunction is to identify certain formations and structures\non charts, providing signals about possible price\nmovements. The list of indicators and their possible\nfunctions does not end there.\n\nIndicators are also divided into leading and lagging indicators. Leading\nindicators seek to predict future price changes and trends before they\nhappen. Examples are RSI and Stochastic Oscillator. Lagging indicators\nreflect past price changes and trends, confirming the current state of the\nmarket. Examples include MA, Bollinger Bands, and MACD.\n\nThe choice between leading and lagging indicators depends on the\ntrading strategy and style of the trader. Some prefer leading indicators to\ntry to identify potential market changes in the early stages, while others\nprefer lagging indicators to more reliably confirm the current trend.\n\nIt is important to remember that no single indicator guarantees success\nin the market, but combining them and analyzing supporting factors may\nbe a more effective approach.\n\nTrend Analysis\n\nTrend analysis is aimed at identifying the general direction of price\nmovement of a particular financial instrument. The essence of this method\nis to determine the current trend and understand whether it will continue or\nchange in the future. Traders are looking for optimal points to enter a trade\nin the direction of the trend and exit it before its possible change. Trends can\nbe divided by duration: short-term, medium-term, long-term. But still, the\nmain division occurs in the direction of the trend (see Figure 2-3).\n\n\u00a2 Upward. There is a gradual increase in price. The graph\nlooks like a staircase going up when viewed from left\nto right.\n\n\u00a2 Downward. There is a gradual decrease in price. The\ngraph looks like a staircase going downward when\nviewed from left to right.\n\n\u00ab Sideways. Prices move in a horizontal range without a\nclear dominant direction.\n\nUpward\n\nFigure 2-3. Types of trends\n\nGeometric analysis is mainly represented by the study of graphic\npatterns, searching for them in market data and predicting future price\nmovements based on them. Basic geometric shapes: triangles (ascending\nand descending), diamond, wedge, flags, double peaks, head and\nshoulders, and others.\n\nFibonacci Retracement and Extension\n\nFibonacci retracements and extensions are technical analysis tools based\non Fibonacci numbers. They are used to determine potential support\n\nand resistance levels in financial markets. Fibonacci retracement uses\nlevels based on the Fibonacci number sequence (e.g., 23.6%, 38.2%, 50%,\n61.8%, 76.4%). After the price of an asset rises or falls, traders can use the\nFibonacci retracement tool from the initial move to identify possible levels\nat which the price may change direction. For example, 38.2%, 50%, and\n61.8% are often used as potential support and resistance levels (50% is not\na Fibonacci number but is often used). If the price of an asset rises and\nthen experiences a correction, a trader can apply Fibonacci retracement\nfrom the start of the move to the end of the correction to identify support\nlevels. Fibonacci extensions also use Fibonacci numbers, but instead of\nretracement levels, they are used to determine the levels at which the price\ncan complete a move or continue in the same direction.\n\nTraders can use Fibonacci extensions to determine possible future\nlevels where the price may go. The 161.8%, 261.8%, and 423.6% levels are\nsome of the Fibonacci extension levels often used by traders. If the price\nbegins to move higher after a correction, a trader can apply a Fibonacci\nextension from the beginning of the movement to the end of the correction\nto identify potential resistance and support levels.\n\nFundamental Analysis\n\nFundamental analysis in trading is a method of market analysis based\n\non the assessment of fundamental factors affecting the value of financial\nassets. The basic idea is to estimate the intrinsic value of an asset and then\ncompare it to the current market price to identify potential overvaluations\nor undervaluations.\n\nTo make a decision to buy/sell the financial instrument in question,\na trader needs to analyze the company\u2019s financial indicators, such as\nprofit and loss statements, balance sheets, and cash flow statements;\nevaluate the company\u2019s management; and of course evaluate the trends\nand prospects of the industry in which it operates this company. Also, an\nimportant stage is the assessment of competitors and their market shares,\nassessment of the impact of global and political events on the company\u2019s\nactivities, and assessment of profitability and dividend payments. As you\ncan see, a colossal amount of work is being done. Therefore, given the\nvolume of data being studied, fundamental analysis is widely used by\ninvestors to make long-term decisions.\n\nIt is important to emphasize that fundamental analysis can be\ncombined with other methods, such as technical analysis, to gain a more\ncomplete understanding of the market.\n\nMixed Approach\n\nTechnical-fundamental analysis in trading is an approach that combines\nelements of technical and fundamental analysis to make trading decisions.\nThis method allows traders to evaluate assets, taking into account both\ntheir current value and trends obtained from technical analysis tools and\nthe main factors influencing their value, obtained from fundamentals.\nThis combination gives a more complete picture of the direction of price\nmovement. Combining the two methods can help not only minimize the\nrisks associated with a limited view of only the technical or fundamental\nside of the market but also provide more accurate forecasts and informed\ntrading decisions. A trader can use technical indicators to confirm or refute\nfundamental signals and vice versa.\n\nVolatility\n\nIt is worth mentioning such an important concept as volatility. Volatility in\ntrading is a measure of price volatility in financial markets. This concept\nreflects the degree of fluctuation in asset prices over a certain period of\ntime. The higher the volatility, the more significant the up and down price\nmovements can be.\n\nVolatility shows the following to a trader:\n\n\u00ab Describes how much asset prices can change in a\nshort period of time. High volatility may indicate\nunstable times.\n\n\u00ab Serves as an important risk indicator. Higher volatility\ncan mean greater potential gain but also greater\npotential loss. For example, with higher volatility, larger\nstop loss levels should be set.\n\n\u00ab Affects the choice of strategies. Volatile markets can\nprovide more opportunities for profit, but they can also\nbe riskier.\n\n\u00ab Affects the choice of analysis period, which may\ndepend on the degree of volatility. For example, when\nvolatility is high, traders may prefer shorter time frames\nto respond more quickly to market changes.\n\nThis concept refers to aspects of two main types of analysis: technical\nand fundamental. In the context of technical analysis, volatility can be\nseen as a key parameter for making decisions about entering and exiting\ntrades. Thus, many technical indicators and strategies take volatility into\naccount when generating signals. In fundamental analysis, fundamental\nfactors such as news, economic events, and data can influence market\nvolatility. For example, important announcements about large companies\n\nor changes in a country\u2019s economic policies can cause prices to change\ndramatically. Thus, volatility is not a separate type of analysis but rather a\nfactor taken into account within analytical approaches, be it technical or\nfundamental analysis.\n\nIn practice, volatility is assessed by a trader using volatility indicators.\nExamples are Volatility Index (VIX), True Average Range (ATR), Bollinger\nBands, Chaikin Volatility, Volatility Stop, Volatility Momentum, and Market\nFacilitation Index (MFI).\n\nSignals\n\nWe have dealt with the approaches to forming a trading theory. That is, by\nnow the trader knows the necessary theory to generate their own trading\nstrategy. Next, to the trader needs to define clear trading rules according to\nwhich the signals will be generated.\n\n1. Selecting one or more financial instruments\nfor trading\n\n2. Choosing an approach for developing a trading\nstrategy\n\n3. Formulating the conditions for opening a position\n4. Formulating the conditions for closing a position\n\nFormulating entry and exit conditions in trading is the process of\ndefining clear rules on the basis of which a trader makes a decision to enter\nthe market (buy or sell an asset) or exit a position. These terms are based\non the various aspects of market analysis that we have already covered.\nThey must be clearly defined and are often subject to optimization and\nbacktesting.\n\nThey can be roughly described as follows:\n\n\u00ab Entry conditions. First, we determine which condition\nor event will serve as a signal to open a position;\nthen we determine which time chart the strategy will\nwork; and at the end, if necessary, we need to receive\nconfirmation of the signal through some additional\nindicator.\n\n\u00a2 Exit conditions. First, we determine which signal or\nevent indicates the need to close the position; and then\nwe look for confirmation indicating a change in the\ndirection of the trend, set the level at which the position\nis automatically closed to limit losses and the level at\nwhich the position is closed to take profit.\n\nLet\u2019s look at an example:\n\n\u00ab Conditions for opening a position: Buy when the price\ntouches the lower Bollinger band on the daily chart and\nits width is at a relatively low level. Confirmation of the\nsignal is the presence of oversold conditions on the RSI\nindicator on the four-hour chart.\n\n\u00a2 Conditions for closing a position: Sell when the price\ntouches the upper Bollinger band on the daily chart\nand its width becomes relatively high. Confirmation of\nthe signal is the presence of overbought conditions on\nthe RSI indicator on the four-hour chart.\n\nGreat, now we can generate trading signals based on these trading\nconditions. While entry and exit conditions are more general concepts,\ntrading signals are specific instructions indicating the need to take certain\nactions in the market, such as buying or selling an asset.\n\nFor example, trading signals based on the conditions from the example\nearlier would look like this:\nSignal to input\n\nDaily chart\nPrice <= lower Bollinger Bands\nBBW < 0.05\n\n4 hour chart\nRSI < 30\n\nExit signal\n\nDaily chart\nPrice >= upper Bollinger Bands\nBBW > 0.08\n\n4 hour chart\nRSI > 70\n\nIn practice, traders begin to follow the path taken by many and start\nwith the now classic crossing of moving averages and then gradually learn\nmore complex strategies and test them in practice. I think this is the right\napproach; without basic knowledge of indicators, it will be difficult to do\nanything worthwhile.\n\nCapital Management\n\nLet's say a trader comes up with a promising trading theory and starts\ntrading on the stock exchange without thinking about the size of each\nposition. What could this lead to? The answer, it seems to me, is serious\nfinancial losses. Let me give you a clear example. Let\u2019s say an experienced\ntrader has $10,000 in capital and is engaged in short-term trading in the\n\nstock market. They decide not to follow any capital management strategy\nand instead invest their entire amount in four large and high-risk orders.\nMarket conditions unexpectedly go wrong, and all four orders lose money\ndue to sudden price declines. As a result, the trader loses up to 70% of their\ncapital.\n\nIf the trader had decided to use even a simple capital management\nstrategy, such as a fixed interest rate, the trader would have retained most\nof their capital. That is, we see that capital management not only helps\nreduce losses but also helps preserve capital in difficult market conditions.\nIt turns out that the goal of capital management is to maintain and grow a\ntrading account, avoid large losses, control risks, and help avoid emotional\ndecisions.\n\nOddly enough, the most banal and effective way to manage capital is\nto divide capital into parts. Yes, you don\u2019t need to put all your eggs in one\nbasket. This is already clear to everyone, but what makes this management\neffective, unfortunately, is not for everyone. That same efficiency primarily\nfollows from the optimal position size, and this size, in turn, depends\non the method of capital management. There are quite a few of these\nmethods.\n\nHere are the main ones:\n\n\u00ab Fixed position size\n\u00abKelly criterion\n\n\u00ab Optimal f\n\n\u00ab Martingale\n\n\u00ab Anti-Martingale\n\n\u00ab Fixed proportional position sizing\n\nFixed Position Sizing\n\nThe fixed position sizing method implies a fixed position size for each\ntrade, regardless of the current capital amount or risk level. This means\nthe trader always risks the same fixed amount, or a fixed amount or a fixed\npercentage of their capital on every single trade. If a trader decides to work\non a fixed volume (amount), then they need to set each time the exact\n\nand constant number of units (money) in which the financial instrument\nis measured, which they will always buy or sell. If they choose a fixed\npercentage, then they need to make a transaction for a constant fixed\npercentage of their current capital.\n\nThe first method is simple and straightforward, but it does not depend\non the amount of capital and the volatility of the asset. With little capital, it\nbecomes very risky. The second method automatically adapts to changes\nin capital, but volatility is also not taken into account and requires constant\nrecalculation of the position size when the account changes.\n\nFor example, let's say a trader has $10,000 in capital. At a fixed volume,\nafter purchasing shares at $60 per share and a constant volume of 100\nshares, they would be risking $6,000, which is more than half of their\ncapital. This is not normal and about the same thing will happen if you\nwait for a fixed amount! The picture is different for a fixed percentage.\n\nIf they decide to risk 1.5% of their capital on each position, then the\nmaximum amount they can lose on one trade is $150. At a stock price of\n$60 per share, they can afford to buy 2 shares ($150 / $60). As you can see,\nthis approach is more secure.\n\nKelly Criterion\n\nThe Kelly criterion is a formula proposed by American mathematician and\nstatistician John L. Kelly in 1956, used to determine the optimal bet size\nunder conditions of uncertainty or risk in money management. Most often,\ntraders use this criterion for trading using leverage.\n\nThe basic Kelly formula looks like this:\n\neT\nf=2-%\n\nf*: The optimal share of capital to invest in each\ntransaction\n\nx: The probability of winning\ny: The probability of loss (y = 1 - x)\nz: The average win relative to the average loss\n\nBased on the proposed formula, it is always necessary to risk a certain\npercentage of the total capital on each order. For example, ifx is 0.05, then\nyour bet on each order should be 5% of your total capital.\n\nLet me give you a small example. Let's assume that a trader trades\nusing a strategy where for every 100 positions, 52 positions were losses and\n48 were profits. This means our x = 48% and y = 52%. Substituting into the\nformula, they will take the following form:\n\nx= 0.48, and y = 0.52\n\nIn monetary terms, the total profit was $7,000, and the loss was $3,000.\nThen z will be equal to this:\nz= 7000/3000 = 2.33\nThen:\n+ \u2014 9.48 \u2014 252 _\nf\u00b0 = 0.48 \u2014 >>> = 0.2268\n\nIt turns out that f* = 0.2268, or 22.68%. The risk on each position can be\na maximum of 22.68% of capital.\n\nWe will also change the amount of profit and loss for clarity. Now the\nprofit will be $3,800, and the loss will be $3,600.\n\nf - share of capital,\n\n\u2014Trade;\n\n- profit or loss on that trade (with the opposite sign so that the loss\nbecomes a positive number and the profit a negative number)\n\nBiggestLoss\n\n- largest loss per trade (this is always a negative number)\n\nWhen the optimal f deviates by only insignificant values, the value of\nTWR changes sharply, and the trader's task is to find such f* so that TWR is\nmaximum. TWR itself is maximized by searching f* from 0 to 1 with a step\nof 0.01.\n\nThis method is much closer to optimal position sizing in real life\nthan the Kelly criterion. But at the same time, its main drawback is the\nimpossibility of determining the optimal f during live trading, since it is\nbased on past data. The optimal share for one trading period may be 25%,\nwhile for another period it may be 20%, and so on. A precise determination\nof the optimal share for the current situation remains impossible.\n\nMartingale\n\nMartingale is a capital management method used in stock trading that uses\nthe principle of increasing position size when losing in order to compensate\nfor losses. This can involve significant risks and is not recommended\nby many professional traders. The Martingale principle is to double the\nposition size after each losing trade so that on the next profitable trade the\ntrader can cover previous losses and even make a profit.\n\nThis method is based on the assumption that a winning trade will\neventually occur and will offset all previous losses. However, it should\nbe noted that Martingale does not take into account capital limits\nand can lead to significant losses if the market does not move in the\ndesired direction and can create the risk of quickly losing all capital,\n\nf* - share of capital,\n\n\u2014Trade;\n\n- profit or loss on that trade (with the opposite sign so that the loss\nbecomes a positive number and the profit a negative number)\n\nBiggestLoss\n\n- largest loss per trade (this is always a negative number)\n\nWhen the optimal f deviates by only insignificant values, the value of\nTWR changes sharply, and the trader's task is to find such f* so that TWR is\nmaximum. TWR itself is maximized by searching f* from 0 to 1 with a step\nof 0.01.\n\nThis method is much closer to optimal position sizing in real life\nthan the Kelly criterion. But at the same time, its main drawback is the\nimpossibility of determining the optimal f during live trading, since it is\nbased on past data. The optimal share for one trading period may be 25%,\nwhile for another period it may be 20%, and so on. A precise determination\nof the optimal share for the current situation remains impossible.\n\nMartingale\n\nMartingale is a capital management method used in stock trading that uses\nthe principle of increasing position size when losing in order to compensate\nfor losses. This can involve significant risks and is not recommended\nby many professional traders. The Martingale principle is to double the\nposition size after each losing trade so that on the next profitable trade the\ntrader can cover previous losses and even make a profit.\n\nThis method is based on the assumption that a winning trade will\neventually occur and will offset all previous losses. However, it should\nbe noted that Martingale does not take into account capital limits\nand can lead to significant losses if the market does not move in the\ndesired direction and can create the risk of quickly losing all capital,\n\nespecially with prolonged streaks of losing trades. For these reasons,\nmost professional traders prefer more conservative capital management\nmethods.\n\nConsider an example where a trader sets an initial bet of 1% of their\ntotal capital, which is $10,000. If the first trade ends in a loss, the trader\ndoubles their bet and risks 2% of their capital on the next position. In case\nof additional losing trades, the trader continues to double the bet size.\nWhen a trader closes a profitable trade, they return to the initial rate of 1%\nof capital.\n\nThese are examples of positions:\n\n\u00a2 Inthe first position, the trader uses 1% of $10,000\n($100). The position is closed at a loss.\n\n\u00ab Inthe second position, the trader uses 2% of $10,000\n($200). The position is closed at a loss.\n\n\u00a2 Inthe third position, the trader uses 4% of $10,000\n($400). The position is closed at a loss.\n\n\u00ab Inthe fourth position, the trader uses 8% of $10,000\n($800). The position is closed with a profit.\n\nIn this example, even after three losing positions, a successful fourth\nposition allows the trader to return to the initial level. However, it should\nbe remembered that with a long series of unprofitable positions, you can\nsimply destroy your capital. Therefore, to reduce risk, some traders use\nlower odds instead of doubling the bet. But personally, I still advise you\nnever to use it.\n\nAnti-Martingale\n\nThe key element for both Martingale and anti-Martingale is changing the\nbet size. In Martingale, the rate increases after a losing position, while in\nanti-Martingale it increases only after a profitable position and decreases\n\nafter a losing one. The essence of anti-Martingale is also simple, as simple\nas one, two, three. If the first position in the series brought a profit, then the\nnext position is opened in the same direction, but in double volume; if the\nposition brought a loss, then we reduce the volume accordingly.\n\nThe price level at which a new position is opened is chosen by each\ntrader himself, following their trading strategy. But it is not recommended\nto open more than three orders. As in Martingale, you can use a smaller\ncoefficient to increase the position (for example, not 2 times, but 1.3 times)\nor completely change the progression from geometric to arithmetic (that\nis, for example, change the position by 20 percent).\n\nAnti-martingale is insidious in that if the forecast is unsuccessful, the\nprofit on the first orders is very quickly covered by the loss on the last, most\nvoluminous order. This can happen when a trader is mistaken in believing\nthat they have caught a trend.\n\nFixed Proportional Position Sizing\n\nEconomist Ryan Jones proposed fixed proportional position sizing as a\ncapital management technique. This strategy was developed to effectively\nbalance risk control and profit maximization. The fixed proportional\nmethod is a kind of variation of the anti-Martingale strategy.\n\nThe concept of this method is that in the initial stages of trading, profits\nmay be small, but at the same time, more stable results are provided over\ntime. As the deposit increases, the profit margin also increases, which\nreduces overall risk. The main idea of the method is to determine a certain\nlevel, upon reaching which the trader can increase the traded volume by a\ncertain number of lots.\n\nJones proposed using the concept of \u201cdelta\u201d to define a fixed value,\n\na certain proportion, upon reaching which a trader can increase the\nworking size of a position. When the delta is reached, the traded lot\n\nsize increases, and when losses exceed the specified delta, the lot size\ndecreases. The Jones method allows you to simultaneously control both\n\nrisks and profitability. Delta is a variable value in the calculation and is\ndetermined according to the trader's trading method or style. The degree\nof aggressiveness of a trader's trading depends on its size; the smaller its\nsize, the more aggressive capital management is.\n\nThe formula for determining levels is as follows:\n\nCapital;_, + (i * 6) = Capital;\n\nwhere:\n\ni: The level number (often coincides with the number of lots)\n\nCapital;: The next level capital\n\nCapital, _,: The previous level capital\n\n6: Delta\n\nLet's imagine that the trader\u2019s initial capital is $5,000. They select a\ndelta of $4,000 and trade one lot. Then to move to the next level, you need\nto solve this:\n\n50008 + (1 * 4000$) = 90008\n\nUpon reaching this level, they will be able to trade two lots. This is the\nnext level:\n\n90008 + (2 \u00ab 40008) = 170008\n\nAt level 3, they will be able to trade three lots. And so on. As you can\nsee, a trader can only influence the delta. It reflects the trading style:\naggressive or less risky. There is also a situation when a trader begins to\nincur losses. In this case, to reduce the growth rate of losses and maintain\nthe resulting profit, the reduction delta should be reduced (compared to\nthe delta when the account grows). That is, the delta used to calculate the\nlevel of increased position size may exceed the delta required to reduce the\nposition size in the event of a drawdown. For example, you can use a delta\nhalf as large as the growth delta or set it as a separate and independent\nreduction delta. Formulas for decline levels can be different and depend\non the style of the trader. Figure 2-4 shows one way to reduce levels.\n\nLevel up 1\nDeposit, thou 10 15 20 25 30 35 40 45 50 55 60 Thou\n\nLevel down ss\n\n2\nFigure 2-4. Example of the process of changing levels\n\nFor example, if the delta of decline is half the delta of growth, then\nthe decrease in the traded lot during the period of drawdown will occur\ntwice as fast as its growth during the period of rise. Then the formula for\ncalculating the reduction level will look like this:\n\nCapital, \u2014 (Capital; \u2014 Capital,_, + 0.5) = Capitalnew\n\nwhere Capital,,.,, is the capital of a new level.\n\nLet's imagine that a trader rose to level 8 and their account became\nequal to $150,000, the previous level was equal to $115,000, and they\ninitially chose a delta equal to $5,000. The reduction level will be equal to\nthe following:\n\n1500008 \u2014 ((150000$ \u2014 1150008) + 0.5) = 1325008\n\nLike any method, the fixed proportional method has its pros and cons.\nOne of the main advantages of this strategy is the possibility of geometric\nprofit growth if all conditions are met. Reinvesting profits and increasing\ntrading volume can significantly increase profitability using this method,\nespecially due to the use of delta. The degree of aggressive or conservative\ntrading is determined by the chosen delta, where a small delta leads to a\nfaster increase in volume.\n\nHowever, the disadvantage of the fixed-proportional method is the\nlong recovery from drawdown periods. The decrease in trading volume\noccurs much faster than its increase. However, this circumstance allows\nyou to save profits received during periods of successful trading series.\n\nIn addition, even such an aspect as choosing the optimal delta can take\na long time. However, by thoroughly testing your strategy using the fixed\nproportional method, a trader will be able to optimally adjust all the\nvariables to suit their needs.\n\nRisk Control\n\nRisk control in trading is a system that gives the trader control over\npossible losses. Simply put, this is a set of actions and calculations aimed\nat one goal: preventing the loss of a deposit and preserving profits as\nmuch as possible. Effective risk management in stock trading allows you\nto wait out difficult periods associated with unprofitable transactions.\nEach successfully passed period of losses without significant losses of the\ndeposit indicates how effectively the trader manages risks. In this regard,\ncapital management and risk control go hand in hand; they are closely\nintertwined, and often one means the other. This is easy to explain, since\nposition size management plays a key role in risk control. By managing\nrisks, a trader decides how many times they can close a position in the red\nand how much they can lose. That is, they strive to save money first and\nonly then think about profitability.\n\nPerhaps the main rule of risk control is to recognize that there are no\n100% results and there will always be unprofitable trades. And its root is\nthe permissible drawdown. Thus, deliberately reducing the average loss,\nfor example reducing it by $100 per trade, has the same positive effect on\nthe account as increasing the average profit by $100. That is, risk control\ndirectly affects the trader's final profit.\n\nThere are several main approaches to risk control:\n\n\u00ab Maximum loss amount\n\u00a2 Stop loss orders\n\n\u00abTake profit orders\n\n\u00a2 Trailing stop orders\n\u00a2 Portfolio diversification\n\n\u00ab Monitoring market volatility\n\nMaximum Loss Amount\n\nTo effectively manage losses during trading operations, it is critical to\nfirst determine the maximum percentage of risk that a trader is willing\n\nto bear for each individual position. As mentioned earlier, good capital\nmanagement helps with this. An equally significant factor here is the\nlimitation on the number of simultaneously open positions. For example,\ngiven that the established risk per position can be, for example, 0.3%,\nand the maximum risk per deposit is 6%, the number of simultaneously\nopen trading transactions cannot exceed 20. This is a simple but effective\nmethod that is suitable even for a beginner.\n\nRisk control for a certain time period (for example, a day, a week, or\na month), which also includes a certain strategy for exiting a drawdown,\nis similar in nature. So, if a trader is faced with a series of unprofitable\npositions over the period under review, it is advisable for him to take a\nbreak. This makes it possible to limit losses and reassess the situation.\n\nFor example, if the maximum loss for a day has been reached, it is\nrecommended to end trading for the current day and resume it the next.\nThe same applies to weekly and monthly limits, allowing you to effectively\nmanage risks across different time frames.\n\nLet's look at an example. The trader has $10,000 on deposit. If they\nhave an acceptable daily drawdown of $200, then the entire deposit will be\nlost after 50 trading days with losses. If the allowable daily loss is $100, then\nthe trader will be able to survive 100 days with unprofitable transactions.\nWith a maximum drawdown of $50, these periods increase to 200 days,\nwith $25\u2014up to 400 days.\n\nStop Loss Orders\n\nAstop loss is a type of order that allows a trader to determine the highest\nlevel of potential loss while trading a single position. In practice, this\nmeans that when the price reaches the level at which the stop loss is set,\nthis order is closed at a loss. Setting a stop loss order allows the trader\n\nto determine in advance the maximum amount of possible losses for a\nspecific position, and this determination is made at the stage of opening\nthe position. Pre-set stop orders are an effective tool for controlling risk\nand minimizing losses in rapidly changing markets.\n\nApplying a strict stop loss rule, such as exiting a position if it loses 3%\nto 10%, is a common practice. But in turn, I will immediately make it clear\nthat not everyone uses stop losses. My personal observations and analysis\nshowed that for many strategies the use of stop losses was inappropriate.\nBut if you use a stop loss as part of your strategy, it is important to honor\nthe obligation to exit a position if the market does not move as expected.\n\nDepending on whether the trader has opened a buy or sell order, the\nstop loss will be placed differently (see Figure 2-5).\n\nBuy Order\n\n*\n\nStop Loss\n\nStop Loss\n\n> >\n\nFigure 2-5. Examples of stop-loss levels\n\nSome traders prefer to use several types of stop signals for more\nflexible position management.\n\nThe main types of brake lights include the following:\n\n\u00a2 Initial stop. This signal is related to the position\u2019s\nentry level and can be expressed as a percentage or a\nfixed amount.\n\n\u00a2 Trailing stop. This stop signal follows the price\nmovement in the direction desired by the trader,\nchanging as profits increase.\n\n\u00a2 Take profit. This stop signal causes the position to be\nclosed when a predetermined profit amount is reached.\n\n\u00ab Breakeven. This means moving the stop loss to the\nprice where the breakeven level is. Often traders set this\nstop loss in an arbitrary place, which is fundamentally\nwrong. All movements must be carefully considered\nand should not be taken at random.\n\n\u00a2 Timed stop signs. In case market behavior does not\nmeet expectations, some professionals recommend\nexiting the position even if there is no financial loss.\nTimed stop signals remind you to exit the market if it is\nunclear what is actually happening.\n\nIn conclusion, setting initial stop losses is a special form of trading art.\nThe ability to recognize false or true breakouts of resistance and support\nlevels plays a key role in this skill.\n\nTake Profit Orders\n\nTake profit, as a type of stop loss, is a preset price level, upon reaching\nwhich the trader automatically closes their position with a certain\nprofitable result. That is, the specified take profit level always exceeds the\ncurrent market price (if the trader has placed a Buy Order) of the asset, and\nif the market price rises to a predetermined value, the broker automatically\nplaces a limit order to sell (see Figure 2-6).\n\nTake Profit\n\nBuy Order\n\nTake Profit\n\n> >\n\nFigure 2-6. Examples of take profit levels\n\nMany traders determine the take profit level based on key resistance\nand support levels. Another approach is to use Elliott wave theory, which\nsuggests that markets move in cycles consisting of waves of different\norders. Additionally, many traders prefer a customized approach to\ndetermining profit levels based on their own comfort level with risk\nmanagement.\n\nTrailing Stop Orders\n\nAtrailing stop is a dynamic order that is used in trading to automatically\nupdate the stop loss level in accordance with changes in market prices.\nThis mechanism is similar to a regular stop loss but differs in that it is not\nset at a fixed price. Instead, it continuously monitors the current price of\nthe asset and automatically changes the stop loss level when the price\nchanges in a direction favorable to the trader; it also works like a regular\nstop loss if the price changes in an unfavorable direction.\n\nLet\u2019s look at an example. If a trader opens a position at a price of $50\n(Buy Order) and sets Take-Profit (TP) at $55 and Stop-Loss (SL) at $45,\nthen TP and SL will be automatically activated only when the levels are\nreached at $55 or $45, respectively. By setting limit orders at $55 and $45,\nthe trader formally agrees to a maximum potential profit and acceptable\nloss of 10%. If a trader entered a trade at $50 with a target of $55 and the\n\nprice moves up to $60, they do not receive the full profit from the move up.\nOr you can imagine the opposite situation, when the price reached $54\nand instead of taking a profit, the trader decided to wait for the upward\nmovement to continue, but as luck would have it, the price went down and\ndropped below $45. It\u2019s also sad. It turns out that instead of a realistically\nachievable profit of several percentage points, the trader received a 10%\nloss. Figure 2-7 illustrates these situations.\n\nLost Profit Zone\n\nFigure 2-7. Examples of profit losses without trailing stop order\n\nTo avoid such scenarios, you can set Take-Profit higher or not use it\nat all. However, in this case, the trader will have to constantly monitor the\nmarket and close manually. At the same time, Stop-Loss will remain at $45.\n\nAtrailing stop order prevents such situations. So in the previous\nexample, a trailing stop would automatically raise the stop loss level when\nthe market rises. For example, if we set the trailing stop to maintain the\nstop order at a distance of $5 from the current price, when the price rises, it\nwill move it according to the upward movement of the price. For example,\nif the price increases from $50 to $52.5, the stop loss moves from $45 to\n$47.5. If the price further rises from $52.5 to $62.5, the stop loss rises from\n$47.5 to $57.5. Trailing stop can be considered as a certain safe level, or as\nperiodic profit taking. At the same time, the trailing stop does not decrease\nif the price goes down. The Variable Stop Loss value is attached to the last\nmark and remains there until the price reaches its level. Figure 2-8 shows\none example of how a trailing stop works.\n\nFigure 2-8. Changing the trailing stop level\n\nThis is certainly an incredibly useful tool for a trader. Only outwardly\nit seems difficult, but after trying it several times, you will definitely like\nit. Plus, I have been convinced more than once that if you use it on some\nstrategies, their effectiveness noticeably increases.\n\nPortfolio Diversification\n\nDiversification of an investment portfolio is a method of reducing risks\nand ensuring stable income. It consists of distributing funds between\ndifferent types of exchange instruments, such as stocks, bonds, precious\nmetals, currencies, and others. This strategy helps protect against losses\n\nin the event of a decrease in the profitability of one of the assets, while\ncompensating for the losses of unsuccessful investments through profits\nfrom others. However, it is important to note that simply buying shares of\ndifferent companies does not always count as diversification. For example,\nowning shares in several oil companies will not create a diversified\nportfolio because all of these companies belong to the same industry, even\nthough they may be located in different countries. If oil prices fall, the\nprofitability of all these assets may decline.\n\nSee we) aes owes OS eee eee ee eas ee\n\n\u00a2 Division by asset class. Thus, bonds are considered\nthe most predictable and stable instruments, including\ncorporate and government securities. But investing in\nstocks, although they are riskier, can bring good profits\nwhen prices rise. Savvy investors also consider futures\nand options, although these instruments tend to be\nmore unpredictable.\n\n\u00a2 Sector division. Each sector of the economy undergoes\nits own unique development path, and even during\nperiods of crisis, when some of them experience\ndecline, others continue to demonstrate steady\ngrowth. Therefore, it is important that the investment\nportfolio is diverse and includes various sectors, such\nas the oil and gas industry, aviation manufacturing,\npharmaceuticals, information technology, and others.\n\n\u00a2 Separation by countries and currencies. Spreading\nyour investments across different currencies provides\nprotection against sharp exchange rate fluctuations.\nAnd investing in assets from different countries helps\navoid exposure to political and economic problems in\none of the unstable countries, since losses can be offset\nby securities of other countries. Experts advise limiting\nthe share of investments in one asset to 10% of capital\nand not exceeding a total of 20% for assets belonging to\none sector of the economy.\n\n\u00a2 Correlation. This shows to what extent the dynamics\nof the value of one financial instrument correlates\nwith the dynamics of another. To ensure effective\ndiversification, it is important to include instruments\n\nwith low or inverse correlations in your portfolio. That\nis, the less the financial instruments are correlated, the\nmore profitable the portfolio. This means that changes\nin the prices of one asset will be offset by changes in\nthe prices of other assets. In this way, the risk of the\ninvestment is spread across different assets, which\nhelps reduce the overall risk level of the portfolio.\n\nMonitoring Market Volatility\n\nThe risk of positions can also be assessed by analyzing the volatility of a\nfinancial instrument. You can estimate this volatility using the standard\ndeviation. If the standard deviation of an instrument is high, it indicates\nhigh risk and uncertain returns. A low standard deviation, on the contrary,\nimplies less volatility and stability of returns. This indicator is especially\nuseful when comparing different instruments.\n\nThe formula for calculating the standard deviation can be calculated as\nfollows:\n\nN\\ (Price; \u2014 MA(N,j))?\n\nStandardDeviation =\n\nPrice;: Price value on the j-th candle\n\nMA(N,j): Moving average value on the j-th candle\n\nN: Sample size\n\nLet's look at an example. The trader plans to invest each month in one\nof two funds. Both funds have an average return of 10%. The first fund has\na standard deviation of 5, which means its return can vary from 5% to 15%.\nAsecond fund with a deviation of 12 could have a return of -2% to 22%. If\na trader prefers to avoid excess volatility and reduce their risks, they are\nbetter off choosing the first fund, as it offers the same returns with less\nvolatility.\n\nTesting\n\nTesting the chosen trading strategy on historical data allows you to\nevaluate its effectiveness without the risk of real financial investments.\nThis practice is based on the assumption that a strategy that has been\nsuccessful in the past has a high probability of being effective in the\npresent. And receiving positive results during such testing strengthens the\ntrader\u2019s confidence in the prospects of their chosen approach. Negative\ntest results may require changes to parameters or a review of strategy.\n\nOne of the challenges associated with backtesting is the possibility of\ncreating a strategy that looks successful on historical data but fails in real\ntrading. For example, often when adjusting a profitability graph obtained\nduring testing or over-optimization, it is possible to create a system that\nwould demonstrate success in tests for a certain historical period, but\nretesting over a long period would show its uselessness. Therefore, it is\nimportant to follow certain rules and not use results adjustment.\n\nFor example, the choice of testing period is extremely important. The\ntesting period depends on the time scale of the chart on which the moment\nof entering the market is determined. There are general recommendations\nin this matter. For example, when planning to trade on the daily chart, it is\nrecommended to backtest at least the last five years. If you select a shorter\ntime scale, such as less than a day, it is recommended to test for at least\none year to account for seasonality. These recommendations are based\non statistical requirements for a minimum amount of data. It is important\nthat testing covers not only periods of strong economic growth but also\nthe latest crisis or recession. The longer the period of testing, the more\nreliable the results obtained will be. This is important because during the\neconomic recovery phase, almost any trend trading strategy brings a good\nprofit, while during a recession or crisis the situation may be different.\n\nYou also need to distinguish between different testing approaches.\nThus, it is possible to use a complex multistep testing algorithm, starting\nfrom preliminary testing, when the trader conducts a quick check without\n\nspending a lot of time on tests, and ending with forward and multicurrency\nmultiperiod testing, or you can limit yourself to just classic backtesting.\n\nClassic backtesting involves testing a strategy against historical data,\nwhile forward testing gives a more realistic idea of how the strategy will\nperform in reality, since it uses data that the strategy has never seen before.\nMulticurrency multiperiod testing, as you might guess from the name,\nincludes testing on different financial instruments and different historical\nperiods, which allows you to assess the stability of the system. The choice\nof testing stages, as always, depends on the trader and their desires.\n\nPerformance Indicators\n\nOf course, after testing, the obtained performance indicators should be\nadequately assessed. For this, it is important for the trader to determine\nwhat results and assessments can be considered acceptable or desirable. It\nis often considered that the main goal is to achieve high returns, taking into\naccount transaction costs. However, in this case, it would be reasonable to\ncompare returns with other alternatives, such as placing funds on a bank\ndeposit with lower risks and similar returns.\n\nThis leads to the first criterion of effectiveness: comparing the\nprofitability of the strategy with the profitability of a bank deposit. After all,\ntaking into account all the risks of exchange trading, active trading makes\nsense only with significantly higher profitability.\n\nThe second criterion is comparison with a long-term buy-and-\nhold strategy. This strategy involves an investor purchasing financial\ninstruments and not selling them for a long period of time. The investment\nhorizon ranges from several years to several decades. With this approach,\nitis also important to evaluate the return and risk of active trading with the\nreturn and risk of a buy-and-hold strategy.\n\nThus, the effectiveness of the strategy is assessed not only by the\nprofitability achieved in testing and real trading but also by the return to\nrisk ratio, especially in comparison with alternative long-term strategies.\n\nThe following types of drawdowns exist (see Figure 2-9):\n\n\u00a2 Current drawdown. This type of drawdown occurs\nwhen opening any trading position. When a position\nis opened, it always starts with a loss equal to the\ncommission established by the brokerage company.\nBrokers typically make money from the difference\nbetween the bid and ask prices they provide on trading\nplatforms. These prices are usually disadvantageous\nfor the trader but are always profitable for the brokers\nthemselves. Therefore, until the position overcomes the\ndistance corresponding to the size of the commission,\nit will be in a state of drawdown.\n\n\u00ab Recorded drawdown. This drawdown represents\nthe trader's closed position, which turned out to be\nunprofitable at the time the decision was made to close\nthe position. This recorded, or, as it is also called, actual\ndrawdown, negatively affects the total volume of the\ndeposit, since it reduces it by the percentage of the loss\nresulting from the completion of this position.\n\n\u00ab Maximum drawdown. This represents the maximum\nreduction of your deposit. Simply put, this drawdown\nshows the maximum loss you have incurred in\nmonetary terms.\n\n\u00ab Absolute drawdown. This drawdown can be equal to\nzero if the trader immediately began to make a profit\nfrom the first positions. This indicator is defined as the\ndifference between the initial capital and its minimum\nreduction.\n\nThe following types of drawdowns exist (see Figure 2-9):\n\n\u00a2 Current drawdown. This type of drawdown occurs\nwhen opening any trading position. When a position\nis opened, it always starts with a loss equal to the\ncommission established by the brokerage company.\nBrokers typically make money from the difference\nbetween the bid and ask prices they provide on trading\nplatforms. These prices are usually disadvantageous\nfor the trader but are always profitable for the brokers\nthemselves. Therefore, until the position overcomes the\ndistance corresponding to the size of the commission,\nit will be in a state of drawdown.\n\n\u00ab Recorded drawdown. This drawdown represents\nthe trader's closed position, which turned out to be\nunprofitable at the time the decision was made to close\nthe position. This recorded, or, as it is also called, actual\ndrawdown, negatively affects the total volume of the\ndeposit, since it reduces it by the percentage of the loss\nresulting from the completion of this position.\n\n\u00ab Maximum drawdown. This represents the maximum\nreduction of your deposit. Simply put, this drawdown\nshows the maximum loss you have incurred in\nmonetary terms.\n\n\u00ab Absolute drawdown. This drawdown can be equal to\nzero if the trader immediately began to make a profit\nfrom the first positions. This indicator is defined as the\ndifference between the initial capital and its minimum\nreduction.\n\n\u00ab Relative drawdown. This drawdown represents the\nmaximum loss in percentage terms. The determination\nmethod is similar to the maximum drawdown, except\nthat the most significant percentage is considered, not\nthe absolute monetary value.\n\nMaximum dravedown (18%) 3000$\n\nRelative drawdown (20%)\n\nPavsotute drawdown (1000S)\n\nFigure 2-9. Types of drawdowns\n\nSharpe ratio is a characteristic of income per unit of risk. The higher\nthe Sharpe ratio, the better the return/risk ratio.\n\nHere's the formula for calculation:\nRy \u2014 Ry\n\nSharpe Ratio\no\n\nR,: The profitability\n\nR; The risk-free profitability rate\n\no,: The standard deviation of profitability\n\nThis indicator shows how much profit an investor receives for each\nunit of risk. The higher the value, the more favorable the return in relation\nto risk is considered. A high Sharpe ratio greater than 1 is generally\nassessed as \u201cpositive,\u201d indicating that the portfolio\u2019s return exceeds its\nvolatility and therefore suggesting excess return relative to the level of risk.\n\nFor the average winning trade size and average losing trade size,\nsum up the results of all profitable positions for a certain period, and then\ndivide this sum by the total number of profitable positions. The resulting\n\nvalue represents the average size of a profitable position. Also add up\nthe results of all losing positions for the same period and divide this sum\nby the total number of losing positions. This way you will determine the\naverage size of a losing position.\n\nAlthough most traders strive for the average size of winning positions\nto be greater than the average size of losing positions, this is not a\nprerequisite for a successful strategy. But if the average size of positive\npositions is still greater than the average size of negative positions,\ntrading can remain profitable even with a low ratio of profitable to\nunprofitable positions. If the average loss exceeds the average profit, a\nhigher ratio of winning to losing positions is required to ensure a profitable\ntrading system.\n\nExpected value is a composite metric that combines the two\npreviously mentioned parameters and provides information on how much\na trader can expect to earn on each trade. The formula for calculating the\nmathematical expectation is as follows:\n\nEM = (Prob. Win + AvgWin) \u2014 (Prob. Loss + AvgLoss)\n\nProb.Win: The percentage of profitable positions\n\nAvgWin: The average winnings\n\nProb. Win: The percentage of losing positions\n\nAugWin: The average loss\n\nEssentially, the expected value provides information about the average\ndollar amount of profit or loss that can be expected over a long-term time\nhorizon.\n\nOptimization\nOptimization is the process of tuning the original trading system by\nadjusting its parameters or group of parameters. This process consists of\n\nconsidering all variations of parameter values within specified boundaries\non a time range of historical data for a specific financial instrument. It\n\nfollows that the main goal of optimization is to determine the optimal\nparameters of the system for a given time period and take into account\nthe characteristics of a particular financial instrument. And since the\ntrading algorithm mainly determines the opening and closing points of\ntrading positions, changes in the rules for entering and exiting a position\nentail changes in the overall efficiency of the trading system. Also, the\neffectiveness of the algorithm may change as market conditions change.\nThis highlights the importance of optimizing a trading system to achieve\nbetter results in the current market condition or in the limited future.\n\nThe optimization results are evaluated by the values of system\nperformance indicators for each set of optimized parameters. In other\nwords, each set of parameters is tested on a specific period of historical\ndata, and the test results provide information about what results were\nachieved under these different sets.\n\nOptimization may include various procedures, such as choosing\nthe optimal time frame, choosing optimal stop order values, choosing\nbrokerage trading conditions, choosing the trading algorithm itself, adding\nconfirmation filters, or finding optimal parameter values for an existing\nsystem. The choice is certainly great and is limited only by the trader's\ncapabilities.\n\nTo optimize a trading strategy, the following sequence of steps is\nproposed:\n\n\u00ab Fully describing the strategy. First, describe the entry\nand exit conditions, a list of financial instruments, time\nframes, etc. Also take into account the characteristics\nof the selected asset, the size of the spread, the possible\nlot sizes, the volatility, and other trading conditions.\n\n\u00a2 Preliminary testing of the system for performance\nto identify possible errors or shortcomings in the\ndescription of the trading algorithm.\n\nsearch step. Then, after rough selection, in the second\nstage the search boundaries are narrowed around the\nobtained values, and the step is reduced. This approach\nallows you to find more accurate settings.\n\n+ Inadequate results. These often arise due to the lack of\nclear restrictions on parameter combinations. Defining\ncommonsense, well-defined constraints on possible\nparameter combinations helps avoid absurd results.\n\n\u00a2 Errors in historical data. Quotation errors cannot\nbe completely avoided, and their presence should\nbe taken into account when evaluating system\nperformance.\n\n\u00a2\u00ab Human factor. This includes a wide range of possible\nproblems associated with the presence of emotions and\nirrational assessments of the system. Consideration of\nthe human factor includes constant awareness of the\nemotional influence on decision-making and the desire\nfor a more objective assessment of the performance of\nthe trading system.\n\nYet, how can a trader determine whether a trading strategy is optimal?\nAs already noted, the optimization process comes down to systematically\nchanging the values of the parameters of the trading algorithm within a\ngiven range to improve the efficiency of the system. For each unique set of\nparameters, the trading system is tested on a specific financial instrument,\ntime frame, and time interval of historical data. The results of such testing\nare expressed in the values of certain system performance indicators, some\nof which we have already reviewed. Based on these values, an optimal set\nof parameters is selected, which is considered the best for further use.\n\nIt turns out that the efficiency of the system when used in real\nconditions and the efficiency obtained after optimization will depend on\nthe efficiency indicators chosen by the trader or their combination. The\ngoal of proper optimization and analysis is to minimize this difference.\n\nSummary\n\nIn this chapter, we looked at the basic concepts of exchange trading, how\nthe process of order execution occurs, and what types of orders there are.\nWe also looked at approaches to developing a trading strategy, the main\nones being technical and fundamental analysis. In addition, we examined\nhow the process of generating trading signals takes place based on the\nformulated trading rules.\n\nWe studied the basic methods of capital management and risk control.\nWe learned a little about the process of testing and optimizing a trading\nstrategy.\n\nIn the next chapter, we'll dive right into my approach to creating an\nautomated trading system. We'll start with the architectural solution.\n\nIt turns out that the efficiency of the system when used in real\nconditions and the efficiency obtained after optimization will depend on\nthe efficiency indicators chosen by the trader or their combination. The\ngoal of proper optimization and analysis is to minimize this difference.\n\nSummary\n\nIn this chapter, we looked at the basic concepts of exchange trading, how\nthe process of order execution occurs, and what types of orders there are.\nWe also looked at approaches to developing a trading strategy, the main\nones being technical and fundamental analysis. In addition, we examined\nhow the process of generating trading signals takes place based on the\nformulated trading rules.\n\nWe studied the basic methods of capital management and risk control.\nWe learned a little about the process of testing and optimizing a trading\nstrategy.\n\nIn the next chapter, we'll dive right into my approach to creating an\nautomated trading system. We'll start with the architectural solution.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 3,
                "chapter_name": "CHAPTER 3",
                "chapter_path": "./screenshots-images-2/chapter_3",
                "sections": [
                    {
                        "section_id": 3.1,
                        "section_name": "Architectural Solution\nPart 1: Identifying\nthe Requirements",
                        "section_path": "./screenshots-images-2/chapter_3/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_3/section_1/ec20b1e9-e1e4-4ba5-b658-766e9d893f2e.png",
                            "./screenshots-images-2/chapter_3/section_1/8582670e-c925-4a5c-95ee-086d27b50041.png",
                            "./screenshots-images-2/chapter_3/section_1/c16b21bf-6198-4db3-bf0e-e28de57d8bcb.png",
                            "./screenshots-images-2/chapter_3/section_1/44ecf883-2698-4a5e-ba3f-5e9365b5985a.png",
                            "./screenshots-images-2/chapter_3/section_1/2fff80c7-9f4f-4cac-b568-ccf8cc99366f.png",
                            "./screenshots-images-2/chapter_3/section_1/a5334996-7218-4c5a-8c50-50d03a481e7a.png",
                            "./screenshots-images-2/chapter_3/section_1/417b3c3c-6243-4a1f-9109-194a560627b5.png",
                            "./screenshots-images-2/chapter_3/section_1/34e7d9de-8903-49f2-b228-57652f9be1ec.png",
                            "./screenshots-images-2/chapter_3/section_1/7d6edb99-7c71-4edb-854d-742c8d7470ab.png",
                            "./screenshots-images-2/chapter_3/section_1/8675bb52-83cc-4c95-b0cc-5073f446ba0a.png",
                            "./screenshots-images-2/chapter_3/section_1/40624e76-35b7-43e6-aeb8-576b0d3a4db8.png",
                            "./screenshots-images-2/chapter_3/section_1/9599bf74-efb6-48c6-9b6f-84e11a66f64d.png",
                            "./screenshots-images-2/chapter_3/section_1/a28ba974-3681-4706-b16d-f9d93d3070c1.png",
                            "./screenshots-images-2/chapter_3/section_1/9748daaa-0e0f-42de-bca9-86c16a4bbf0f.png",
                            "./screenshots-images-2/chapter_3/section_1/ae149edd-710a-4216-8fc9-38a349636ff6.png",
                            "./screenshots-images-2/chapter_3/section_1/7ae28ca9-c0e4-4cad-8624-4b892d21e8e3.png",
                            "./screenshots-images-2/chapter_3/section_1/be639d39-869a-46e0-8312-63d0a8cd646d.png",
                            "./screenshots-images-2/chapter_3/section_1/70215a67-0737-456e-bd43-35a6e6e80003.png",
                            "./screenshots-images-2/chapter_3/section_1/a37a2ad2-3fd6-4751-8dc7-e68c1de62b30.png",
                            "./screenshots-images-2/chapter_3/section_1/62534f3f-b812-4f6a-b7ce-4f0178340c14.png",
                            "./screenshots-images-2/chapter_3/section_1/a59376e2-f395-456e-b99f-582c911853a1.png",
                            "./screenshots-images-2/chapter_3/section_1/aeebfbc9-4038-47b3-827b-46af083d605e.png",
                            "./screenshots-images-2/chapter_3/section_1/3d9af10a-cf50-40a2-bd0c-6162d0efea35.png",
                            "./screenshots-images-2/chapter_3/section_1/d4f21a8e-da11-4865-874d-9e3236cc3a73.png",
                            "./screenshots-images-2/chapter_3/section_1/81e1f4da-3568-408c-8248-f735a07d0301.png",
                            "./screenshots-images-2/chapter_3/section_1/5097446c-6744-488f-8846-166a710131d3.png",
                            "./screenshots-images-2/chapter_3/section_1/e6530311-f51d-4db9-801e-09eddbc9c119.png",
                            "./screenshots-images-2/chapter_3/section_1/f5dbf0ba-73a0-4611-b271-cc8b3a2395d6.png",
                            "./screenshots-images-2/chapter_3/section_1/a12b07c1-62a4-4baf-8d09-4a212765cf60.png",
                            "./screenshots-images-2/chapter_3/section_1/ec9851cc-1eea-473a-bc2b-44064241b676.png",
                            "./screenshots-images-2/chapter_3/section_1/0d3af841-3657-436d-ac64-4320965a8293.png",
                            "./screenshots-images-2/chapter_3/section_1/28134d1a-ec86-46fc-a94e-ddbbfc0d0edf.png",
                            "./screenshots-images-2/chapter_3/section_1/e25b71ee-89a1-408f-bf8e-468b50bfcf31.png",
                            "./screenshots-images-2/chapter_3/section_1/0c78ac32-1252-4742-a862-07f31cdf659b.png",
                            "./screenshots-images-2/chapter_3/section_1/60cb72be-0ffb-43d4-95ae-b54f7cc7cb13.png",
                            "./screenshots-images-2/chapter_3/section_1/04014a14-f7c2-4f71-a8e2-e2ed77bef76e.png",
                            "./screenshots-images-2/chapter_3/section_1/575c035d-ff5f-4439-9aff-b085b962e8dc.png",
                            "./screenshots-images-2/chapter_3/section_1/69e68bc5-d347-476a-9d86-77c2df39a1e9.png",
                            "./screenshots-images-2/chapter_3/section_1/5ea9f79b-9eea-46ac-a114-4e6605fe3901.png",
                            "./screenshots-images-2/chapter_3/section_1/9c9077ac-e164-4fa5-b824-7e70e3bf0532.png",
                            "./screenshots-images-2/chapter_3/section_1/5ec7e7fc-8104-4ebe-9140-96adedac8cb2.png",
                            "./screenshots-images-2/chapter_3/section_1/990d2ac5-938a-4fcc-b078-0e68d4b92291.png",
                            "./screenshots-images-2/chapter_3/section_1/2c516c33-62ed-474b-bd88-6654f3fe443a.png",
                            "./screenshots-images-2/chapter_3/section_1/99e1fefe-4be2-4da8-bdcc-45c00c2c4ac0.png",
                            "./screenshots-images-2/chapter_3/section_1/b3028c9d-3b68-424e-af17-7c752b9ab1b7.png",
                            "./screenshots-images-2/chapter_3/section_1/02d9ec23-9923-49d6-ba16-ad80f611abd2.png",
                            "./screenshots-images-2/chapter_3/section_1/4bbf1a7e-932b-4893-b04b-04979c07cd87.png",
                            "./screenshots-images-2/chapter_3/section_1/73debecd-cea8-440e-a247-4165924a964c.png",
                            "./screenshots-images-2/chapter_3/section_1/481600ec-8278-4770-8f52-106843423176.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In the previous chapter, we discussed the general theory of creating trading\nsystems and talked about the modules that are present in such systems\nand their functionality. In this chapter, we will put this knowledge into\npractice and build our product. We will draw up a high-level plan of the\nsystem, describe the subsystems and their services, and also determine\nhow those parts will interact with each other.\n\nIn most cases, creating the architecture of our application consists of\nthe following steps:\n\n1. Identifying the requirements\n\nAt this stage, we must understand what the system\nshould be able to do. What behavior do we expect\nfrom our system? What technical expectations\n\nand limitations do we have of it? This step lays the\nfoundation of our application. The first diagram is\ndrawn. We understand how many users will interact\nwith our system and how they will do it. The result of\nthis stage should be a list of technical tasks.\n\n2. Making architectural decisions\n\nAt this stage, we decide how the assigned tasks will\nbe solved. For example, will we use a queue or create\nsome kind of service? What architectural patterns\nand templates will we use to solve the problem?\nHere we can superficially discuss whether we will\nuse databases and how our services will interact\nwith each other. The result of this stage is a list of\narchitectural solutions for each of the assigned tasks.\n\n3. Identifying subsystems\n\nAt this stage, we determine the list of subsystems\n\nof our future system. We briefly define its input and\noutput. The result of this stage should be a list of the\nsubsystems of our future system with a description\nof the functionality for which it is responsible.\n\n4. Identifying the services of all the subsystems\n\nAt this stage, we must clearly understand the\ncomposition of services. How will they scale? Will\nthey have their own databases? What will the API of\neach service look like? How will caching be carried\nout? Let\u2019s discuss what kind of applications will\n\nbe built on the basis of these services. How will\n\nour services scale and make decisions to optimize\nperformance? The result of this stage will be a\nservice diagram for each subsystem.\n\nThis sequence of actions is conditional and may include other steps. It\nis also worth keeping in mind that the process of building an architectural\nsolution is iterative. It often happens that even when describing a service,\nthe architect understands that their higher-level solution is not optimal\n\nand has to go back and redo the overall solution scheme. Sometimes\nthese shortcomings become visible after the prototyping stage, when a\nprototype of the future system or its individual components is quickly\ncreated to more accurately determine the weaknesses of the architectural\nsolution and check with the customer's expectations. It is much more\nunpleasant if the shortcomings of an architectural solution are revealed at\nthe development stage, when the cost of an error increases significantly.\nTherefore, creating an architectural solution is one of the key stages in the\ndevelopment of any system.\n\nAfter thoroughly going through all the stages of building an\narchitectural solution, we will create a comprehensive diagram of our\nfuture application. In this chapter, I will show how a general vision of the\nsystem is created and describe the processes that will occur. Of course, for\nthis it is necessary to identify the requirements.\n\nRequirements Elicitation\n\nThis is the first and perhaps most important stage of creating a system.\nAfter all, a mistake in identifying requirements has a high cost. Therefore,\nitis important to determine them as accurately as possible. At this stage,\nwe must not only identify the requirements for the functionality of our\napplication but also decide on specific numbers. For example, we need\nto understand how many users will work with the application. How many\nstrategies can the system support?\n\nLet's first define general concepts and make a list of entities that will\nbe used in our system. Entities are the main objects or concepts that\nthe system operates on to achieve its goals. They have their own set of\nproperties that we will manipulate.\n\nSignals\n\nHere I will show an example conversation between a customer and a\nsystem architect to help you understand this process as best as possible.\nFor the sake of brevity, this conversation has been simplified.\n\nArchitect: Why do you need a system? What purpose\ndoes it serve?\n\nCustomer: To make money. As much money as possible.\nArchitect: How will it make money?\n\nCustomer: It will generate profitable strategies and\nuse them in real trading. The more strategies and\nthe better they are, the more money your program\nwill bring me.\n\nArchitect: What does it mean to \u201cgenerate strategies\u201d?\nHow do you see the result of this generation?\n\nCustomer: Well, it must create new conditions based\non indicators, and the trading system, based on\nthese conditions, will understand when it is time to\nenter a position and when it is time to exit it.\n\nArchitect: How many new terms are there? Here\nwe have a strategy, position, indicators and some\nconditions. The concept of an indicator is familiar\nto me. Do I understand correctly that an indicator\nis a certain formula, for example a formula for\ncalculating the width of the Bollinger band or a\nfunction or anything, for example, the percentage\nof special words in a ChatGPT response, in general,\nsomething that gives us a number?\n\nCustomer: Yes, that\u2019s absolutely right.\n\nAt this stage, we have the first entity of our future system: an Indicator\n(Figure 3-1). The purpose of this entity is to calculate a certain number\naccording to its unique logic, based on the current situation on the market,\nfor example, the appearance of new candles, changes in the order book, or\n\nnews feed.\ntrading data ca numeric value\n\nFigure 3-1. Indicator entity\n\nArchitect: Fine. What do you mean by conditions?\nWhat is their purpose?\n\nCustomer: This is a set of conditions taking\nindicators, processing their values, and giving a\nsignal whether it\u2019s time to enter or exit a position or\nmaybe neither.\n\nArchitect: Do I understand correctly that, in fact, the\npurpose ofa set of conditions is simply to return a\nyes or no value to us when passing trading data such\nas candles or the order book as input?\n\nCustomer: Yes, that\u2019s right.\n\nArchitect: Could this set of conditions be different\nfor giving a signal to open and close a position?\n\nCustomer: Yes, maybe.\n\nArchitect: But in fact, are they the same thing? Are\nthe parameters or formulas just different?\n\nCustomer: Yes that\u2019s right.\n\nArchitect: Do you mind if we call the set of these\nconditions \u201cSignal\u201d and continue to operate with\nthis concept?\n\nCustomer: Yes, I like it.\n\nHere we have another entity: Signal. Its purpose is to give a\nyes/no answer in response to changes in trading data. To do this, the signal\noperates on indicator values. See Figure 3-2.\n\ntrading data yes/no answer\n\nSome magic with\n\nindicators\n\nFigure 3-2. Signal entity\n\nFirst View of the Process\n\nThe conversation continues:\n\nArchitect: Great. Now let's turn our attention to our\nstrategies. It turns out that a strategy is an entity\nthat combines signals about opening and closing a\nposition. That's all? How will the system understand\nhow much money needs to be opened?\n\nCustomer: Understanding position size is also\npart of the strategy. There are different methods of\nmoney management. One of the most primitive is\nto open a position for a certain percentage of the\nremaining capital; more advanced ones look at\nthe historical or test indicators of the strategy and,\nbased on them, decide on the size of the position.\n\nArchitect: What about risk management? Will there\nbe any protection in the case of unexpected market\nbehavior?\n\nCustomer: Undoubtedly! We must protect ourselves\nfrom sudden price drops and also be able to take\nprofits. Here, too, there are simple methods and\nmore complex ones. You can simply place a Stop\nLoss and Take Profit order, you can use a slightly\nsmarter system and use trailing orders, or you\n\ncan make a hybrid system with a trailing order, an\nadditional signal, and even a limit on the number\nof open positions. But this does not change the\nessence. Yes, we need something that will monitor\nthe current state of positions and close them in case\nof something unexpected or the need to take profits.\n\nAt this stage, we have one of the central entities of our system: a strategy.\nBy strategy we understand that an entity combines the following:\n\n\u00a2 Signal to open a position\n\n\u00ab Signal to close a position\n\n\u00ab Capital management method\n\n\u00ab  Riskcontrol method\nThe purpose of the strategy is to give a signal to open or close a\n\nposition with the size of that position. The strategy also manages risks,\nnamely, placing an order.\n\nArchitect: What about indicator parameters? For\nexample, Bollinger Bands Width (BBW) has several\nparameters, and one of them is the number of\nstandard deviations. Are these parameters included\nin the strategy? Anything else?\n\nCustomer: Yes, the specific values of these\nparameters are part of the strategy. Also, please keep\nin mind that some theories use indicator values\n\nnot only of the last candles, but also of the previous\nones. For example, this is a simple condition: the\nclosing prices of the last three candles must be\ngreater than their opening prices.\n\nArchitect: I understood about the use of indicator\nvalues not only of the last candles. But what about\nthe theory? What is it, and how does it differ from\nstrategy? Better yet, tell us the process of your\nmanual search for a strategy.\n\nCustomer: First, I come up with or read a theory on\nforums or from other sources. A theory is an idea\nfor a future strategy. It does not contain specific\nparameter values for indicators. The theory is a\ndescription of the conditions of the signals, that\n\nis, the logic by which the signals will process the\nindicator values.\n\nFor example:\n\nWe open a position when the closing price crosses\nthe WMA from bottom to top. We close when the\nclosing price crosses the WMA from top to bottom.\nThis strategy will work only if there is a strong trend,\nwhich we will check using the ADX indicator; that is,\nit must be greater than a certain value.\n\nWe open a position when the closing price breaks\nthe upper Bolinger band and trading volumes\nincrease. Exit a position at Stop Loss or Take Profit.\n\nNext I test my theory. I take several variations\n\nof indicator parameter values, choose a capital\nmanagement method, and test these strategies\non historical data. If I understand that there is\nsomething in this theory, then I look for the most\nstable and profitable strategy for my instrument\nbased on it. And after that I start trading on it.\n\nHere we have a new entity: Theory. It consists of signals for opening\nand closing a position without indicator parameters, and it is on its basis\nthat strategies are generated. The strategy includes data from the theory\nand specific values of the parameters that are necessary for the functioning\nof its components. See Figure 3-3.\n\nStrategy\n\nfrom Theory\n+ Open signal\n+ Close signal\n\n+ Risk control\n+ Capital management\n\nFigure 3-3. Strategy entity\n\nNow it becomes clear what the whole process will look like:\n\n1.\n\nThe user creates theories in the system using a\ngenerator or independently.\n\nBased on some algorithm, the performance of the\ntheory is checked.\n\n3. If, according to some criteria, the system\nunderstands that the theory is workable, then the\nprocess of searching for the optimal strategy begins.\n\n4. Ifastrategy is found that meets the user\u2019s criteria,\nthen it begins to participate in real trading. See\n\nFigure 3-4,\nStrategy |\nStrategy |\nStrategy |\n\nTheory\n\nGenerator\nStrategy |\n\nFigure 3-4. First view of the process\n\nTheory Generator\n\nWe have identified the main stages of the strategy life cycle, from the\nmoment of theory generation to the moment of using the strategy in\nreal trading. Now let's look deeper and think about how each of these\nstages will work. The result of our discussions should be a complete\nunderstanding of the functionality of our system, as well as a list of tasks\nthat need to be solved.\n\nLet's start with generating theories.\n\nFirst, theories can be created in two modes by the user: manually or\nusing a generator.\n\nHere we have two requirements for the system:\n\n\u00a2  Itshould provide the user with a tool for creating\ntheories.\n\n\u00a2  Itmust implementa mechanism for generating\ntheories.\n\nIf everything is clear with the first requirement, we implement it using\na special form on the front end, and we understand that a user can create\ndozens of theories manually. Then, with the requirement about the theory\ngeneration mechanism, we need to work and understand how this process\noccurs and what data it requires.\n\nObviously, to generate a theory, we need to generate signals. To\nunderstand how to do this, we need to delve deeper into this concept. So,\nwe know that the signal includes a set of indicators and, receiving trading\ndata as input, returns a yes/no response using them. But how does this\nmagic of working with indicators happen?\n\nBasically, the signals look like this:\n\nIf\n\nIndicator_1 > Indicator_2\nAND\nIndicator_3 < Indicator_4 on the last three candles\n\nwe should buy.\n\nFor example, here\u2019s the theory: the entry signal will be carried out by\ncrossing the regression line (LRC) of the weighted moving average (WMA)\nfrom bottom to top and, accordingly, to the exit when LRC crosses the\nWMA from top to bottom. RSI is used as a confirmation factor for the\ntransaction. That is, when we receive a crossover signal, we look to see if\nthis candle or several previous ones have a corresponding RSI value. For\nexample, if there is a buy signal, then the RSI value should be less than 30,\nand a sell signal should be greater than 70. We will also add an additional\n\ncondition to the input for the width of the Bollinger Band (BBW). If this\nbecomes more than 0.04, then check the value of the ADX indicator; it\nshould be more than 30.\n\nIn my presentation, this theory looks like this:\n\nSignal to open a position:\n\nAND group:\nLRC > WMA on the current candle\nRSI < Const on the previous three candles\nBBW > Const on the current candle\nBBW on the previous candle < Const\nADX > Const\nSignal to close a position:\nAND group:\nLRC < WMA on the current candle\nRSI > Const on the previous three candles\n\nHere we have the concept of condition and condition group. The\ncondition contains left and right indicators and a comparison condition.\nTime intervals, candle intervals at which it is necessary to check the\ncondition, become additional parameters in the strategy along with\nindicator parameters. The result of a condition being met is a yes/no\nresponse, but often we need to group these conditions.\n\nFor example, the following:\n\nCondition_1 AND (Condition_2 OR Condition_3)\ncan be expressed using groups like this:\n\nGroup_1 = Condition_2 OR Condition_3\n\nGroup_2 = Condition_1 AND Group_1\n\nAs a result, the root group of the signal will be Group_2. This is what\nwill give us the long-awaited yes/no answer. See Figure 3-5.\n\nCondition_1\nCondition_2\n\nCondition_3\nCondition_4\n\nFigure 3-5. Conditions\n\nLet's return to the theory generator. Somehow it must generate\nsignals. From the logic of signal construction, it is clear that the number\nof combinations of conditions and their groupings can be infinite. This\nmeans we need to somehow limit this amount. I propose to do this by\nusing signal templates, which will initially have condition layouts with\ngroups, and the generator, substituting indicators in them, will create new\nsignals.\n\nIt is worth noting here that this is not the only possible approach to\ncreating signals. Conditions can also be created programmatically using\nthe brute-force method with restrictions on possible options, for example,\nwith a limit on the depth of nesting of groups and a number of conditions\nin each of them. Or you can use an optimization algorithm rather than a\nbrute-force method, which will speed up the process of finding a profitable\nstrategy.\n\nNow imagine the beginning of the process of setting up the theory\ngenerator. The user first creates signal templates and then selects\nindicators. The generator, using the selected signal templates and\nsubstituting different combinations of indicators into them, will generate\nnew signals.\n\nAt this stage, I will remind you what the theory consists of. These are\nsignals for opening and closing a position, a capital management method,\nand a risk control method. We have closed the question of how signals\nwill be generated, so now let's think about what to do with capital and risk\nmanagement methods. In fact, there is nothing to invent here. We have a\nlist of these methods, which is not large, so the user can simply specify a\nlist of these methods when setting up the generator, and the generator will\ncreate theories where it will try each of them.\n\nStrategies Searching\n\nTheories are generated or created manually by the user. But one of the\nkey requirements for our system is the search for profitable strategies\nand not the generation of theories. But how to look for them? And what\ndoes \u201csearching for profitable strategies\u201d even mean? The search process\nincludes two important concepts: the search method and the criterion\nby which we understand that the search process is completed. We have\na theory. We need to understand how to search for profitable strategies\nbased on it and how we will carry out this search.\n\nOne-Step Approach\n\nLet's start with the parameters that distinguish theory from strategy. They\ninclude indicator parameters and condition parameters, such as the depth\nof the candles at which the check takes place and time intervals. This\nmeans that to find a profitable strategy, we need to generate strategies by\nvarying these parameters.\n\nFirst, you need to understand that these parameters are limited. The\ndepth of candles must clearly be greater than 0; for example, perhaps\nit cannot be greater than 50 and must always be an integer. And time\nintervals are generally limited to a finite list of values: 1 minute, 2 minutes,\n3 minutes, 5 minutes, 10 minutes, 15 minutes, 30 minutes, 1 hour, 4 hours,\n\nFirst, we need to take into account the parameter of the\nLookbackPeriod indicator itself, which is how many candles this indicator\nwill be calculated on. Second, we need to understand at what time\ninterval (TimeInterval) this indicator will work. Third, what candle depth\n(CandlesDeep) wil] the signal use to calculate conditions? As a result, we\nget that the first INDICATOR_1 (LRC) from GROUP_1 CONDITION_1 and\nSIGNAL_1 has the following parameters:\n\nGROUP_1\nCONDITION 1\nINDICATOR_1\nLookbackPeriod\nTimeInterval\nCandlesDeep\n\nRemember when we talked about parameter limitations? Let's add\nthem to our parameters:\n\nGROUP_1\nCONDITION 1\nINDICATOR_1\nLookbackPeriod from 2 to 300 step 1\nTimeInterval limited to list of\n12 values\nCandlesDeep from 0 to 0 step 1\n\nWe can calculate how many strategy variations INDICATOR_1 from\nCONDITION_1 of the group GROUP_1 will cost us.\n\nLookbackPeriod (300 - 2 + 1) * 1 = 299\nTimeInterval 12\nCandlesDeep 1\n\nTatal 700 * 19 * 4 = BERR\n\nFirst, we need to take into account the parameter of the\nLookbackPeriod indicator itself, which is how many candles this indicator\nwill be calculated on. Second, we need to understand at what time\ninterval (TimeInterval) this indicator will work. Third, what candle depth\n(CandlesDeep) wil] the signal use to calculate conditions? As a result, we\nget that the first INDICATOR_1 (LRC) from GROUP_1 CONDITION_1 and\nSIGNAL_1 has the following parameters:\n\nGROUP_1\nCONDITION 1\nINDICATOR_1\nLookbackPeriod\nTimeInterval\nCandlesDeep\n\nRemember when we talked about parameter limitations? Let's add\nthem to our parameters:\n\nGROUP_1\nCONDITION 1\nINDICATOR_1\nLookbackPeriod from 2 to 300 step 1\nTimeInterval limited to list of\n12 values\nCandlesDeep from 0 to 0 step 1\n\nWe can calculate how many strategy variations INDICATOR_1 from\nCONDITION_1 of the group GROUP_1 will cost us.\n\nLookbackPeriod (300 - 2+ 1) * 1 = 299\nTimeInterval 12\nCandlesDeep 1\n\nTotal 299 * 12 * 1 = 3588\n\nNow let\u2019s do the same calculations with the remaining signal indicators\n\nfor opening a position, SIGNAL_1.\n\nGROUP_1\nCONDITION 1\nINDICATOR_1 (LRC)\nLookbackPeriod\nTimeInterval\nCandlesDeep\nINDICATOR_2 (WMA)\nLookbackPeriod\nTimeInterval\nCandlesDeep\nCONDITION_2\nINDICATOR_1 (RSI)\nLookbackPeriod\nTimeInterval\nCandlesDeep\nINDICATOR_2 (Const)\nValue\nCONDITION_3\nINDICATOR_1 (BBW)\nLookbackPeriod\n\nStandardDeviations\n\nTimeInterval\nCandlesDeep\nINDICATOR_2 (Const)\nValue\nCONDITION_4\nINDICATOR_1 (BBW)\nLookbackPeriod\n\nStandardDeviations\n\nfrom 2 to 300 step 1\nlimited to list of 12 values\nfrom 0 to 0 step 1\n\nfrom 2 to 300 step 1\nlimited to list of 12 values\nfrom 0 to 0 step 1\n\nfrom 2 to 300 step 1\nlimited to list of 12 values\nfrom 0 to 10 step 1\n\nfrom 0 to 100 step 0.1\n\nfrom 2 to 300 step 1\n\nfrom 1 to 20 step 1\n\nlimited to list of 12 values\nfrom 0 to 0 step 1\n\nfrom 0 to 0.6 step 0.001\n\nfrom 2 to 300 step 1\nfrom 1 to 20 step 1\n\nTimeInterval limited to list of 12 values\n\nCandlesDeep from 0 to 10 step 1\nINDICATOR 2 (Const)\n\nValue from 0 to 0.6 step 0.001\n\nCONDITION_5\n\nINDICATOR_1 (ADX)\n\nLookbackPeriod from 2 to 300 step 1\n\nTimeInterval limited to list of 12 values\n\nCandlesDeep from 0 to 0 step 1\nINDICATOR_2 (Const)\n\nValue from 0 to 100 step 0.1\n\nIf we count all the possible variations of strategies, we get the following:\n\nSIGNAL_1=\nCONDITION. 1 (299 * 12 * 1 * 299 * 12 * 1)\n\n* CONDITION 2 (299 * 12 * 10 * 1000)\n\n* CONDITION 3 (299 * 20* 12 * 1 * 600)\n\n* CONDITION 4 (299 * 20 * 12 * 10 * 600)\n\n* CONDITION_5 (299 * 12 * 1 * 1000)\n\n= 12,873,744 * 35,880,000 * 43,056,000 * 430,560,000 *\n3,588,000\n\n= 3.072395344219699e+35.\n\nThis is the number of variations based only on the signal to open a\nposition! This is an incredibly large number.\n\nIf we use even a very powerful server cluster and ignore the fact that\nworking with such large numbers in any programming language is difficult,\nthen it will still take millennia to run such a large number of strategies\non historical data. For example, if our cluster calculates thousands of\nstrategies per second, then it will take 9.742501725709345*10\u2122 years to\ncalculate all the options. This is completely unacceptable for us.\n\nThis means we need algorithms that are smarter than simply searching\nthrough all the possible options for parameters.\n\nSimply distributing strategies evenly across the space of all possible\noptions is not a bad idea, but it is not enough, because there may be a\nstrategy with much more impressive results very close by. See Figure 3-6.\n\nFigure 3-6. Local extremes\n\nFortunately, we are not the only ones faced with the task of finding\nthe optimal solution in a vast space of possible variations. There is a\nspecial section of engineering that deals with this problem, and we can\ntake advantage of the results of the work of a large number of scientists\nwho have devoted many years to this branch of science. Optimization\nalgorithms are the central part of this area. We'll talk about them in more\ndetail in Chapter 6, but for now it\u2019s important to understand the general\nlogic of how they work.\n\nThe task of optimization algorithms is to maximize the value of a\nfunction by selecting its parameters.\n\nmax f(X) = f(X*) = f\u00b0\n\nIn this formula,\n\nX is a vector of our variable parameters, in other words, a set of values\nfor the strategy parameters.\n\n|X| is the set of permissible parameter values and is precisely the\nrestrictions imposed on our parameters.\n\nfis the objective function or optimization criterion. In relation to a\nstrategy, this criterion may be equal, for example, to the average monthly\nprofitability of the strategy. It is usually calculated using the formula\n(ending balance - opening balance) / opening balance. In other words,\nthis is how much percent of the initial capital the strategy earned.\n\nX* is a vector of variable values at which the objective function reaches\nits optimal, in our case maximum, value. These are just the specific values\nof the constant LookbackPeriod or TimelInterval for each indicator.\n\nfris the optimal value of the objective function.\n\nItis also worth noting that most modern optimization algorithms have\nnot been proven to have absolute convergence. This means they have not\nbeen proven to find the most optimal result, but they do find a fairly good\nvalue of the objective function in a more acceptable time than millennia.\n\nThe following algorithm for finding the optimal strategy is obtained as\nshown here:\n\n1. We pass a set of parameters with their constraints\nto the optimization algorithm. In response to this,\nthey generate for us sets of parameter values, based\non which we can create a strategy. That is, the\nalgorithm will give us what the LookbackPeriod\nshould be equal to, for example, for a specific\nopening signal indicator.\n\n2. Our system simulates real trading with this strategy\nusing historical data and, based on the results,\ncalculates the optimization criterion for each set of\nparameters.\n\n3. Again, we go to step 1; that is, we transfer the sets of\nparameters with the calculated criterion for each of\nthem again to the optimization algorithm and, based\non this data, it again generates a set of values for us.\nThis loop continues until the stopping condition\noccurs. Such a condition can be the number of\niterations or the fact that we have gone through\nall possible variations, or, for example, search\ndegradation. This is when new sets of values don\u2019t\ndiffer very much from each other. See Figure 3-7.\n\nSet of params [Values 1\nSet of params | Values 2\n\n[ tony | \u201cwee\n\nSet of params | Values N\n\nSetofparams | Vahues} | Criterion?\nSetof params | Vakues2 | Crerton 2\n\nSetofparams | ValuesN | Criterion\n\nFigure 3-7. One-step process\n\nTwo-Step Approach\n\nI showed how to implement a one-step system to search for a strategy,\nbut I was not impressed with the results of its work. The fact is that\noptimization algorithms are evaluated by two criteria: the accuracy of\n\ndetermining the optimal value and the coverage of all possible variations\nof parameters in their space. In practice, this means that if the algorithm\nis more tuned to coverage, then it will not find the most optimal solution,\nbut the options that it will consider will be as varied as possible. And in the\ncase of a bias toward optimization, the algorithm will find an extremum,\nbut with a high degree of probability it will be local and not global.\n\nSo, I tried different optimization algorithms with a wide variation in\ntheir settings and was disappointed every time. Breadth-tuned algorithms\ndid not find the best strategies because they did not include a local search\nalgorithm, and the value space can be huge. Algorithms tuned in depth\naccurately found local maxima but often missed global ones. Also, the\ncalculations took a long time and often had negative results when the\ntheory turned out to be unviable.\n\nAsa result, I decided to complicate my system for finding profitable\nstrategies. First, | wanted to quickly cut off bad theories; for this I used\nan algorithm configured in breadth and increased the step of parameter\nvalues. That is, for example, at the first step for GROUP_1 CONDITION_1\nINDICATOR _1, I passed the following to the algorithm:\n\nGROUP_1\nCONDITION 1\nINDICATOR_1\nLookbackPeriod from 2 to 300 step 10\nTimeInterval limited to list of 12 values\nCandlesDeep from 0 to 0 step 1\n\nIincreased the step for LookbackPeriod by 10 times, which\nautomatically reduced the number of variations by the same value.\n\nAn urgent question arose in the automatic determination of viable\ntheories. I didn\u2019t like the strategy of simply selecting the best strategies\nsorted by the value of the optimization criterion, because the sample, for\nexample, included strategies with 10 trades over five years or with a large\n\nnumber of losing positions and only a few, but large, winning ones.\nI consider such strategies unstable and do not work with them. Our task is\nto look for stable, albeit not very profitable, strategies.\n\nTherefore, I came up with and developed another essence of my\nsystem, the quality condition. Its task is to analyze the calculated\nstrategies and give a yes/no answer, that is, whether our theory is suitable\nfor further research or not. Obviously, there is no point in analyzing all\nstrategies, since they are already ranked according to the optimality\ncriterion. This means that in the suitability condition it is necessary to\nspecify a certain number or percentage of strategies that we are ready to\nconsider. Next, we need to indicate the selection conditions by which the\nstrategy can be classified as suitable. If at least one of the pool of strategies\nturns out to be suitable, then the entire theory is considered suitable, and\nwe will continue to work with it. See Figure 3-8.\n\nQuality condition\n\n.\npool of strategies yes/no answer\n\n+ amount of deals > 100\n+ percentage of profitable trades > 60%\n+ maxDrawdowen < 2%\n\n+ avg performance per month > 0.3%\n+ recovery factor > 6\n\nFigure 3-8. Quality condition entity\n\nIt is worth noting here that all these conditions can be included in\nthe optimization criterion. For example, if maxDrawdown becomes more\nthan 2%, then make it negative, and then the optimization algorithm will\nstop considering this strategy to generate the next set of variable values.\nHowever, I refused this because such strategies may be promising, but they\njust need to be optimized, which means they cannot be discarded from the\nfield of view of the optimization algorithm.\n\nSince in our sequence of searching for a profitable strategy, another\noperation appeared to vary the intervals and steps of parameters, there was\nalso a need for another entity that contains data on these changes. I called\nit SubTheory. While the theory contains settings on the basis of which we\nwill search for strategies, SubTheory will contain a specific optimization\nalgorithm, rules for generating and calculating strategies. It is also obvious\nthat SubTheories are generated based on theory. See Figure 3-9.\n\n+ Open signal + Open signal \u00a9 SubTheory\n+ Close signal + Close signal\n\n+ Risk control + Risk control\n\n+ Capital management + Capital management\n\nSet of params with default Set of params with individual\nintervals and steps intervals and steps\nSearch settings Optimization algorithm\n\nFigure 3-9. SubTheory entity\n\nBased on theories, a set of SubTheory will be formed. And each\nSubTheory will generate strategies. That is, strategies are not built on\nthe basis of theory. To test the theory, we created one SubTheory. See\nFigure 3-10.\n\nFigure 3-10. Relationship between Theory and SubTheories\n\nLet's assume that one of our theories turns out to be suitable. That\nis, with a high degree of probability, one or even several good strategies\ncan be obtained from our theory. All that remains is to find them. When\ndetermining suitability, we reduced the number of variations by increasing\nthe parameter step. When searching for a profitable strategy, this approach\nwill not suit us, because our task is to find the most optimal strategy\npossible and not one close to it. This means that the search accuracy\nshould be as high as possible, and therefore the parameter step should\nbe minimal. But let me remind you that in practice I realized that this\napproach does not work. Therefore, I decided to act iteratively. That is,\nreduce the step gradually while simultaneously narrowing the ranges of\nparameter values. In practice, this means that at each search step anew\nSubTheory will be created. Now the strategy search scheme looks like\nFigure 3-11 and Figure 3-12.\n\nFirst step: Quality checking\n\n(eam\nnn | Ea Ea \u2014an\n\u2014\u2014\u2014s\n\nFigure 3-12. Second step\n\nLet's look at the second step in more detail.\nTo simplify, let's imagine that our theory is characterized by only two\nparameters (Table 3-1).\n\nTable 3-1. Set of Params with Default Intervals and Steps\n\nParam from to step\nLookbackPeriod 1 300 1\nValue 1 100 0.1\n\nIt is easy to calculate that this theory can have 300,000 strategies.\n\nThis is not an impressive number that can simply be sorted out, but let\nme remind you that this is a simplified example and in real theories this\nnumber will be approximately 3.072395344219699* 10\u00b0.\n\nSo let's get started. Before creating SubTheory, we need to decide on\nthe step and interval of each parameter. For the first time, we will take the\ndefault intervals from theory and increase the step so that the number of\nparameter values is limited by the user settings. For example, let\u2019s take 20.\nWe get the set shown in Table 3-2.\n\nTable 3-2. Set of Params with Individual Intervals and Steps\n\nParam from to step\nLookbackPeriod 1 300 300/20 = 15\nValue 1 100 100/20 = 5\n\nSo, the first SubTheory has been created. Let\u2019s imagine that 20\nstrategies were generated and calculated on its basis. I understand that this\nnumber is lower than the number of all variations of strategies that can be\ngenerated based on this SubTheory, but I remind you that the optimization\nalgorithm is not a brute-force method. The goal of these algorithms is to\nfind the maximum value of the objective function in the least number of\ncalculations.\n\nNow, based on the results of these 20 strategies, you need to generate\ncustom intervals and steps for the next SubTheory. The logic for defining\nthe steps is clear, but what about the intervals? How to reduce them? Let's\nlook at the LookbackPeriod parameter as an example. Let\u2019s take the values\nof this parameter from the five best strategies of this SubTheory. How\nmany strategies do we take? And what rule (percentage or quantity) should\nbe specified by the user at the stage of theory formation in the Search\nsettings block? See Table 3-3.\n\nTable 3-3. Calculated Strategies\n\nStrategy Value of LookbackPeriod\n\nStrategy1 91\nStrategy2 16\nStrategy3 196\nStrategy4 166\nStrategy5 16\n\nFrom these values it is clear that the optimal value is in the interval\n16 - 196. But since this is not the final solution, we will add one step in each\ndirection. As a result, we will get an interval from 1 to 211. Next we need to\nreduce the step. And again we take 20 intervals. The step will then be equal\nto 211/20 = 10.55, but we know that the minimum possible step for this\nparameter is 1, which means it is necessary to round 10.55 to units. As a\nresult, we get 11. We do the same with the second parameter.\n\nThis strategy for calculating new intervals and steps is not the only one.\nBetter solutions can be devised, such as exploring multiple subintervals to\nmore accurately probe these local extrema. You can also change the step\nsize depending on the number of our iteration and/or the total number of\nstrategies. Here I showed an example of the simplest implementation.\n\nNow we need to discuss the conditions for exiting this cycle. I'm using\na double condition. The first is the number of iterations. But it happens\nthat the intervals narrow so much that the system has the opportunity to\ngo through all possible strategy options in an acceptable time. Therefore,\nI also set the number of strategies after which the system could switch to\nthe brute-force method. And after searching through all possible values, it\nstopped.\n\nSelection and Forward Testing\n\nThe second step is complete, so now we'll select strategies for forward\ntesting. I acted according to the following logic: I set the number of\nstrategies I needed and the condition of suitability. My system followed a\nlist of strategies sorted in descending order of the value of the optimization\ncriterion; if any of them fulfilled the suitability condition, then the system\nallowed it to proceed to the next step. This should continue until either the\nrequired number of strategies is collected or the pool, the settings of which\nare specified in the suitability criteria, is exhausted.\n\nWe now need to test suitable strategies on stocks that were not\nincluded in the search process. This is necessary to make sure that the\nchosen strategies are truly profitable and not tailored to specific stocks.\nThis test will also give us information about the operation of strategies,\nwhich can be applied in real trading in the risk control module. What\nis forward testing in relation to our system? This is simply modeling\nthe operation of a strategy based on historical data and preselected\ninstruments. Next, all results are checked according to the suitability\ncondition, and if they all meet the condition, then the strategy is\nconsidered profitable and can be used in real trading. See Figure 3-13.\n\nconnecting a new instrument. Second, we need to take care of a real-time\nmonitoring system that will turn on or off strategies on instruments when\nthe market situation changes.\n\nSo, charts or instruments are divided into types, which means that\nthe system must check, search, conduct forward analysis, and conduct\nreal trading on instruments of the same type. This is important, because a\nprofitable strategy will cease to be profitable in completely new conditions.\nThis approach looks like tweaking a strategy, but it\u2019s not at all because the\ntypes of tools can be broad rather than limited to one or two instances.\nOf course, if you set the conditions for a group that only one or two\ninstruments fall under, then yes, this will be an adjustment. In this matter,\nitis important to maintain a balance between the breadth of coverage of\ntools or types of charts and understanding the specifics of how each of\nyour theories works.\n\nSetting Up a Search for a Profitable Strategy\n\nIn the previous steps, we talked a lot about the fact that the user must set\nsome parameters to generate theories and find profitable strategies. Let's\ncollect all this information in one place.\n\nObviously, the entire search process is governed by theory, which\nmeans that search settings should be stored in it. And since the theory can\nbe created not only manually, the user must select these settings in the\ngenerator.\n\nAlso, the search settings should contain all the necessary information\nabout the search parameters in all three steps and include a list of tools or\nsegments of historical data on which strategy indicators will be calculated\n(see Figure 3-14 and Figure 3-15).\n\nconnecting a new instrument. Second, we need to take care of a real-time\nmonitoring system that will turn on or off strategies on instruments when\nthe market situation changes.\n\nSo, charts or instruments are divided into types, which means that\nthe system must check, search, conduct forward analysis, and conduct\nreal trading on instruments of the same type. This is important, because a\nprofitable strategy will cease to be profitable in completely new conditions.\nThis approach looks like tweaking a strategy, but it\u2019s not at all because the\ntypes of tools can be broad rather than limited to one or two instances.\nOf course, if you set the conditions for a group that only one or two\ninstruments fall under, then yes, this will be an adjustment. In this matter,\nitis important to maintain a balance between the breadth of coverage of\ntools or types of charts and understanding the specifics of how each of\nyour theories works.\n\nSetting Up a Search for a Profitable Strategy\n\nIn the previous steps, we talked a lot about the fact that the user must set\nsome parameters to generate theories and find profitable strategies. Let's\ncollect all this information in one place.\n\nObviously, the entire search process is governed by theory, which\nmeans that search settings should be stored in it. And since the theory can\nbe created not only manually, the user must select these settings in the\ngenerator.\n\nAlso, the search settings should contain all the necessary information\nabout the search parameters in all three steps and include a list of tools or\nsegments of historical data on which strategy indicators will be calculated\n(see Figure 3-14 and Figure 3-15).\n\n+ Open signal\n+ Close signal\n+ Risk control\n+ Capital management\n\nSet of params with default\nintervals and steps\nSearch settings\n\nTheory Generator\n\n+ Risk control\n+ Capital management\n\nIndicators\n\nSignal templates\n\nSearch settings\n\nFigure 3-14. Theory generation process\n\nSearch settings\n\nFirst step Second step Final step\n\nInstruments Instruments. Quality condition\n\nOptimization algorichm ] Optimization algorithm Forward tests instruments\n\nquatrycenaion | ut condition Final quality condition\n\nFigure 3-15. Search settings at every step\n\nThe Logic of Searching for Profitable Strategies\n\nLet\u2019s summarize and describe the general vision of the algorithm for\nfinding profitable strategies:\n\n1. The user creates a theory manually or using a theory\ngenerator. The user must make all the necessary\nsettings to find a profitable setup, as well as signal\ntemplates and a list of indicators to generate\nstrategies.\n\n2. An initial check of the quality of the theory is carried\nout on a reduced field of possible parameter values\nusing an optimization algorithm configured to cover\na wide range of possible parameter values.\n\n3. Ifthe previous step is completed successfully and\nthe theory is considered to be of high quality,\nthen the optimal strategy is searched by iteratively\nnarrowing the possible options for parameters with\na gradual increase in their accuracy.\n\n4. The required number of strategies is selected from\nthe entire pool of counted strategies in step 3 using\nthe quality criterion specified in the search settings.\n\n5. Selected strategies undergo forward testing. Using\nthe final quality condition, the required number of\nfinal strategies that are suitable for real trading are\nselected from them.\n\nReal Trading\n\nAt the previous step, several promising strategies were found that\nperformed well in forward testing. We also know what types of instruments\nor chart types each of these strategies can use.\n\nThis means that in a real trading system there should always be a\nrobot running that monitors all available instruments and in real time\ndetermines their type or the type of their charts. As I said earlier, there are\n\nmany options. To keep things simple, I will use tool types in this book. For\nexample, if a tool has increased in price from $15 to $50, then the robot\nmust record this and change its type.\n\nAnother robot is also needed that constantly checks the strategies and\ntypes of tools. If one of the tools has changed its type, then you need to turn\noff the strategies that no longer correspond to it. Here it is necessary to pay\nspecial attention to the mechanism for disconnecting the strategy from\nthe tool. Imagine a situation where a tool changes its type frequently. So,\nshould the system constantly turn the strategy on and off? No, of course,\nthis problem can be approached from two sides. First, correctly configure\nthe definition of the tool type so that it has a reserve and the change of\nthese types does not occur frequently. Second, do not turn off the strategy\nimmediately, but wait for a certain time.\n\nAlso, this robot must include strategies on tools of the appropriate\ntype. For example, if the tool has changed type or a new strategy has\nappeared, then it needs to be put into operation.\n\nOur system works with money, which means that an external,\nadditional audit of the strategy\u2019s operation is necessary. In practice, this\nmeans that not only the strategy itself, with the help of risk control, will\nmonitor its work, but also an external robot will monitor its performance\nand, in case of any discrepancies, turn off the strategy. For example, if the\nbalance of a strategy has dropped sharply, or vice versa, if the strategy\nhas earned an amount of money that is not standard for it, then this robot\nshould turn it off.\n\nIn real work, system stability is extremely important. This means\nwe must have prepared scenarios for actions in case of unforeseen\ncircumstances\u2014a sudden shutdown of the exchange for some time,\n\na planned system update when we are forced to stop all or part of the\nstrategies, an unplanned lack of electricity or Internet.\n\nIt is necessary to understand that this system will trade on more than\none exchange using dozens of instruments. This will be a large, full-scale\nprogram, integrated with dozens of exchanges, using hundreds of tools\nand thousands of strategies. This point will be critical at the design stage.\n\nImportant Questions\n\nPreviously, we defined the main essence of our future system and also\ndescribed the main processes associated with the search and operation\nof profitable strategies. But there are still some points that should be\nexamined in more detail.\n\nLife Cycle of a Position\n\nEach profitable strategy contains signals for opening and closing a\nposition. But what is the position? What are its stages of existence?\n\nFirst, I want to separate the concept of a position from the concept of\na system (internal) order and an order placed directly at the broker. Let's\nstart with the latter. This is exactly the order on the basis of which deals are\nexecuted and the broker notifies us about the change in status.\n\nMany brokers provide functionality for placing not only market and\nlimit orders but also such interesting types as stop loss or take profit, etc.\nBut it is important to understand that not all brokers support all types of\norders; therefore, we must implement them in our system. This is where\nthe concept of a system order originates. This is the essence of our system,\nwhich \u201cmonitors\u201d the state of the market, and if specific conditions are\nmet, then it creates an order with the broker and monitors its execution\n(see Figure 3-16).\n\nsystem order\n\nTraiding data th \u2018cot\n1e magic of\nsolving\n\nFigure 3-16. System order process\n\nPosition is one of the central entities of the system. It is this entity that\ninitiates the creation of system orders. Each position can generate several\nsystem orders.\n\nFor example, one of the ways to control risk is to place take profit and\nstop loss orders. This means that when opening a position, we need to\ncreate three system orders: buy, take profit, and stop loss. However, not\nevery one of them will generate an exchange order. See Figure 3-17.\n\nFigure 3-17. Relationship between strategy and orders\n\nLet\u2019s describe the life cycle of a position. Here I will introduce one of\nthe simplest position management processes. But I do not exclude the\npossibility of much more complex options. So let\u2019s get started.\n\nA signal to open a position came from the strategy. This means we\nneed to buy a certain amount of tools. We create a simple system buy\norder, which generates a market order.\n\nEach order can have each of these statuses:\n\n\u00a2 New: Initial status. This means that the broker has\nsuccessfully registered your request in the system.\n\n\u00a2 PartiallyFill: The order is partially filled. This is not the\nfinal status of the order; it only shows that one or more\ndeals were made within the order, which do not cover\nthe entire needs of the order.\n\n\u00a2 Fill: Final order status. This means that the order was\nsuccessfully executed.\n\n\u00a2 Canceled: Final status. This status is set if you cancel\nyour order yourself. It may come after PartiallyFill. It is\nnormal when you cancel a partially filled order.\n\n\u00a2 Rejected: Final status. This status is set if the broker\ncancels the order for any reason.\n\nExecuting an order at a broker is not a synchronous process. There\nis also a time delay due to the mechanics of receiving order statuses. We\nmust provide the correct logic for the position to take into account all these\nnuances. For example, a situation may arise when a market order switches\nto the Rejected status immediately after it is created or when the system\nsends a request to create an order and the broker returns an error.\n\nThis means we must provide a position-processing mechanism in the\nplatform that will allow us to correctly process all these situations.\n\nCapital Management\n\nIn the previous chapter, I described several ways to manage capital. Each\nmethod has its own characteristics, advantages, and disadvantages. But all\nthese methods have one thing in common: at the input they must receive\ndata about the operation of the strategy, and at the output they must say\nthe maximum amount for the purchase of an asset and set a strategy for\npurchasing additional assets. See Figure 3-18.\n\n+ Strategy indicators + Maximum purchase amount\n+ Balance history Capital + Repurchase strategy\nmanagement\n\nFigure 3-18. Capital management entity\n\nThis means the system will refer to the capital management method\nevery time the price of an asset changes to obtain information about\nthe need to repurchase or partially sell the purchased asset. That is, the\npurpose of this block is to answer the question, is it necessary to buy or sell\npart of the assets and for what amount?\n\nTo focus on the main thing, implementing a system for the mass search\nfor profitable strategies, we will implement in this book only one method\nof money management, but we will focus on creating a mechanism that\nwill make it easy to add more complex methods to the system.\n\nOur first method will be the fixed interest method. This is perhaps\none of the easiest methods to implement, as it has only one variable and\nsome elementary logic. It was discussed in detail in the previous chapter,\nbut I will remind you what it is. It specifies the percentage of the balance\non the basis of which the maximum purchase amount of the asset will be\ncalculated when opening a position. It is also worth noting that with this\nmethod, only one buy order is created for one position; that is, there is no\nprovision for the additional purchase of an asset into the position.\n\nRisk Control\n\nThere are many approaches to managing your risks, all of which come\ndown to one goal: to prevent the system from losing or gaining too much.\n\nI chose three options for myself that can easily be combined with each\nother. This is the creation of a take profit, stop loss, or trailing system order.\n\nTake Profit and Stop Loss\n\nThis system order does not immediately create an order with the broker.\nAnd it sets it only if the closing price of the candle exceeds the price\nspecified during creation. To simplify, I introduced a parameter equal to\nthe percentage of discrepancy in the average price of transactions when\nexecuting a system order during the opening of a position. Thatis, if the\nprice exceeds this percentage, then an order is placed with the broker.\n\nFor example, the strategy gave a signal to open a position. According\nto the logic of position processing, a simple market system order to buy\nan asset was first opened. During its execution, the deals in Table 3-4\nwere made.\n\nTable 3-4. List of Deals\n\nCount price total\n\n10 45.4 454\n2 45.3 90.6\n\nAs a result, we get the average purchase price equal to (454 + 90.6) /\n12 = 45.38. If the strategy settings indicate that it is necessary to create a\nsystem take profit order with execution when the price exceeds the 4%\nthreshold, then the system order will give a command to open an order\nwith the broker when the closing price of the candle exceeds the threshold\nprice equal to 45.38 * 104% = 47.2.\n\nStop loss system orders act exactly the opposite. They create an order\nwith the broker if the closing price of a candle falls below a certain level.\nRegarding the example given earlier, if you set a threshold of 3%, then such\na system order will command the broker to sell if the asset price falls below\n45.38 * 97% = 44.01.\n\nTrailing System Order\n\nA trailing system order is a dynamically changing order designed to\nmaximize profits. In this section, I will present my version of the idea of\nimplementing this type of order.\n\nThe components of a trailing system order are three lines: decision\nborder, profit border, and stop border. The stop border and profit border\ndepend on the trailing price, the change of which is controlled by the\ndecision border. As in the case of take profit and stop loss, if the closing\nprice of the current candle is higher than the profit border or lower than\nthe stop border, then the system initiates the procedure for closing the\nposition, but there is a significant difference: in a trailing order, these\nborders are dynamic since the trailing price on which they depend\nmay change.\n\nWhen creating a system order, the trailing price is equal to the average\nprice of asset purchase transactions. The decision border is a price that is\nhigher than the trailing price by a certain percentage. If the current price\nis above the decision border, then a special trailing signal is checked.\nThis signal analyzes the current state of the market and shows whether\nwe should expect the asset price to continue moving in the direction we\nneed. If the signal returns \u201cyes,\u201d then the trailing price becomes equal to\nthe current one. This in turn entails a shift in the stop border and profit\nborder prices. I have slightly modified the algorithm for determining\nthe stop border and profit border. For me, they are not calculated using\na simple formula that changes the price of the decision border by a\ncertain, predetermined percentage. This formula also includes a factor for\n\nnarrowing the acceptable price tunnel. When the stop border and profit\nborder with each change the trailing prices become closer to each other.\nSee Figure 3-19.\n\nStep 1\n\n~------------fi------ Profit border\nnnn DECISION DOFCer\nTrailing price\n\nStop border\n\nFigure 3-19. An example of how trolling order works\n\nLet's look at the algorithm in more detail.\nThe following variables are necessary for a trailing system order\nto work:\n\n\u00a2  TrailingPrice: The price relative to which the\nboundaries are located. When creating a trailing system\norder, the trailing price is equal to the average price of\ntransactions when purchasing assets.\n\n\u00a2 ProfitBorderCoeff: What percentage of TrailingPrice is\nthe upper price border.\n\n\u00ab StopBorderCoeff: What percentage of TrailingPrice is\nthe lower price border.\n\n\u00a2 BorderChangeCoeff: What percentage the distance\nbetween the profit border and the stop border\ndecreases by with each shift of the Trailing price.\n\n\u00a2 DecisionCoeff: What percentage of TrailingPrice is the\ndecision line located at.\n\n\u00a2 DecisionSignal: The signal on the basis of which a\ndecision is made to change the TrailingPrice.\n\n\u00a2 DecisionCount: The number of changes TrailingPrice.\nThe algorithm for processing changes in the asset price will look\nlike this:\n1. We check the penetration of the profit border. If we\nbreak through, then close the position.\n\n2. We check whether the stop border has been broken.\nIf we break through, then close the position.\n\n3. We check the penetration of the decision border.\nIf they hit, then we check the signal. If the signal\nreturns \u201cyes,\u2019 then TrailingPrice becomes equal to\nthe current price of the asset.\n\nFor example, if the price of an asset changed as shown in Table 3-5.\n\nTable 3-5. Change in the Price of a Financial Instrument\n\nDate Price\n2021/10/01 11:00 97\n2021/10/01 11:05 95\n2021/10/01 11:10 105\n2021/10/01 11:15 107\n\n2021/10/01 11:20 107.5\n\nAnd the variables in the strategy are equal to the values in Table 3-6.\n\nTable 3-6. Strategy Parameter Values\n\nProfitBorderCoeff 0.1\nStopBorderCoeff 0.05\nBorderChangeCoeff 0.3\nDecisionCoeff 0.02\nTrailingPrice 90\nDecisionCount 0\n\nThen our algorithm will work as follows:\n1. 2021/10/01 11:00 CurrentPrice = 97\n\na. Checking the penetration of the profit border.\nTo do this, you need to calculate ProtectedPrice,\nwhich is the profit border price.\n\nProtectedPrice = TrailingPrice * (1 +\nProfitBorderCoeff * ((1 - BorderChangeCoeff )\npow DecisionCount)) = 90 * (1 + 0.1 * ((1 -\n0.3) pow 0) = 90 * (1 + 0.1 * 1)= 99\n\nThe current price of 97 is less than the\nProtectedPrice of 99. This means there is no\nneed to close the position.\n\nb. Checking the penetration of the stop border. To\ndo this, you need to calculate ProtectedPrice\nminus the stop border price.\n\nProtectedPrice = TrailingPrice * (1 -\nStopBorderCoeff * ((1 - BorderChangeCoeff )\npow DecisionCount)) = 90 * (1 - 0.05 * ((1 -\n0.3) pow 0) = 90 * (1 - 0.05 * 1) = 85.5\n\nThe current price of 97 is more than the\nProtectedPrice of 85.5. There is no need to close\nsuch a position.\n\nc. Checking the penetration of the decision border.\nTo do this, let's calculate DecisionPrice.\n\nDecisionPrice = TrailingPrice * (1 +\nDecisionCoeff) = 90 * (1 + 0.02) = 91.8.\n\nThe current price of 97 is greater than the\nDecisionPrice of 91.8, which means we check\nthe signal. For example, the signal gave the\nanswer \u201cyes.\u201d It turns out that TrailingPrice\nbecomes equal to 97, DecisionCount 1.\n\nResults of the step: We do not close the position.\nTrailingPrice = 97, DecisionCount = 1.\n2. 2021/10/01 11:05 CurrentPrice = 95\na. Checking the penetration of the profit border.\n\nProtectedPrice = TrailingPrice * (1 +\nProfitBorderCoeff * ((1 - BorderChangeCoeff )\npow DecisionCount)) = 97 * (1 + 0.1 * ((1 -\n0.3) pow 1) = 97 * (1 + 0.1 * 0.7)= 103.79\n\nThe current price is 95 less than the\nProtectedPrice of 103.79. This means there is\nno need to close the position. Please note that\n\nnot only has the upper price limit changed from\n103.79 to 99, but also the distance between the\nupper and lower limits has decreased.\n\nb. Checking the penetration of the stop border.\n\nProtectedPrice = TrailingPrice * (1 -\nStopBorderCoeff * ((1 - BorderChangeCoeff )\npow DecisionCount)) = 97 * (1 - 0.05 * ((1 -\n0.3) pow 1) = 97 * (1 - 0.05 * 0.7) =93.65\n\nThe current price is 95 more than the\nProtectedPrice of 93.65. This means there is no\nneed to close the position.\n\nc. Checking the penetration of the decision border.\nTo do this, let's calculate DecisionPrice.\n\nDecisionPrice = TrailingPrice * (1 +\nDecisionCoeff) = 97 * (1 + 0.02) = 98.94.\nThe current price 97 is greater than\nDecisionPrice 98.94, which means we check\nthe signal. For example, the signal gave the\n\nanswer \u201cno.\u201d It turns out that TrailingPrice does\nnot change.\n\nResults of the step: We do not close the position.\nTrailingPrice = 97, DecisionCount = 1\n\n3. 2021/10/01 11:10 CurrentPrice = 105\na. Checking the penetration of the profit border.\n\nProtectedPrice = TrailingPrice * (1 +\nProfitBorderCoeff * ((1 - BorderChangeCoeff )\n\npow DecisionCount)) = 97 * (1 + 0.1 * ((1 -\n0.3) pow 1) = 97 * (1 + 0.1 * 0.7)= 103.79.\nObviously it has not changed since the\nprevious step, because TrailingPrice has\nnot changed\n\nThe current price is 105 more than the\nProtectedPrice of 103.79. This means we give a\nsignal to close the position.\n\nResults of the step: Closing a position.\n\nA trailing system order is a very powerful risk control mechanism\nbecause it changes its parameters depending on the market situation.\n\nScalability of Indicators\n\nThere is one big problem that I encountered almost immediately after the\nfirst attempt to implement this system: different scales of indicator charts\nthat are compared in signals.\n\nImagine a situation where you need to compare ADX and the closing\nprice of a candle, in some signal condition (see Figure 3-20).\n\na\n\nFigure 3-20. Scalability of indicators\n\nI propose solving this problem in a way that is standard for many\ntrading platforms: scaling the indicators and bringing them to a single\ncoordinate system. To do this, it is necessary to take the maximum and\nminimum values on the last segment of historical data for each indicator\nand equate them to 0 and 100%. As a result, each indicator value can be\nscaled from 0 to 100 using the following formula:\n\n(currentValue - minValue) / ((maxValue - minValue) * 100)\n\nIt is worth noting here that as the strategy works, the values of\nminValue and maxValue should change as new data arrives. That is, the\nstart of calculations will occur only after processing a given length of\nhistorical data.\n\nLet's look at an example. As a result of analyzing historical data, the\nmaximum value of the indicator was 20, and the minimum was 9. See\nTable 3-7.\n\nTable 3-7. Scaled Value Changes over Time\n\nDate Indicator Maximum Minimum Scaled Value\nValue Value Value\n\n2018/10/2 08:05 11 20 9 (11 - 9)/(20 - 9) *\n\n100 = 18.18\n\n2018/10/2 08:10 8 20 8 0\n\n2018/10/2 08:15 25 25 8 100\n\n2018/10/2 08:20 20 25 8 70.59\n\n2018/10/2 08:25 27 27 8 100\n\n2018/10/2 08:30 19 27 8 57.89\n\nThus, you can easily scale any indicator values to a single coordinate\nsystem and compare them with each other.\n\nI propose solving this problem in a way that is standard for many\ntrading platforms: scaling the indicators and bringing them to a single\ncoordinate system. To do this, it is necessary to take the maximum and\nminimum values on the last segment of historical data for each indicator\nand equate them to 0 and 100%. As a result, each indicator value can be\nscaled from 0 to 100 using the following formula:\n\n(currentValue - minValue) / ((maxValue - minValue) * 100)\n\nIt is worth noting here that as the strategy works, the values of\nminValue and maxValue should change as new data arrives. That is, the\nstart of calculations will occur only after processing a given length of\nhistorical data.\n\nLet's look at an example. As a result of analyzing historical data, the\nmaximum value of the indicator was 20, and the minimum was 9. See\nTable 3-7.\n\nTable 3-7. Scaled Value Changes over Time\n\nDate Indicator Maximum Minimum Scaled Value\nValue Value Value\n\n2018/10/2 08:05 11 20 9 (11 - 9)/(20 - 9) *\n\n100 = 18.18\n\n2018/10/2 08:10 8 20 8 0\n\n2018/10/2 08:15 25 25 8 100\n\n2018/10/2 08:20 20 25 8 70.59\n\n2018/10/2 08:25 27 27 8 100\n\n2018/10/2 08:30 19 27 8 57.89\n\nThus, you can easily scale any indicator values to a single coordinate\nsystem and compare them with each other.\n\nSummary\n\nIn this chapter, we went through the first stage of creating an architectural\nsolution, namely, identifying requirements.\n\nWe identified the main entities of the system, as well as their\nrelationships.\n\nWe decided to use optimization algorithms and also realized that the\nsearch for profitable strategies should be done in two stages.\n\nWe also discussed how our system should look in a production\nenvironment.\n\nIn the next chapter, we will pay more attention to the technical details.\nLet\u2019s discuss what subsystems and services should be in our system, as\nwell as how they should interact with each other.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 4,
                "chapter_name": "CHAPTER 4",
                "chapter_path": "./screenshots-images-2/chapter_4",
                "sections": [
                    {
                        "section_id": 4.1,
                        "section_name": "Architectural Solution\nPart 2: Services and\nSubsystems",
                        "section_path": "./screenshots-images-2/chapter_4/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_4/section_1/4a12f3d3-46ae-4020-876d-9779f734174f.png",
                            "./screenshots-images-2/chapter_4/section_1/7e81ba41-adb7-4022-adaa-72e74812a1f8.png",
                            "./screenshots-images-2/chapter_4/section_1/31e2c9a0-744a-45d9-bf8f-ce7d9bb6002d.png",
                            "./screenshots-images-2/chapter_4/section_1/fbab2577-530e-4e86-8527-cb95b8d33512.png",
                            "./screenshots-images-2/chapter_4/section_1/b240f52b-ec7e-462a-b081-de30b201f5a8.png",
                            "./screenshots-images-2/chapter_4/section_1/0e3a438f-5e99-4ca1-adf9-a742b6d32df9.png",
                            "./screenshots-images-2/chapter_4/section_1/659f4893-078b-4d50-ba81-867b08d42420.png",
                            "./screenshots-images-2/chapter_4/section_1/47ab8ca0-721a-4c3c-a6ee-98c1aeca2e5f.png",
                            "./screenshots-images-2/chapter_4/section_1/84cd0cf7-78fb-4a60-ad45-bb4abfad9c7b.png",
                            "./screenshots-images-2/chapter_4/section_1/00caf85e-e3d4-4dda-a594-49ed798b2f89.png",
                            "./screenshots-images-2/chapter_4/section_1/c925e890-c482-4464-9ab2-1537d521da90.png",
                            "./screenshots-images-2/chapter_4/section_1/1ec124a8-bc64-4e55-bfc8-7f90ffc0437f.png",
                            "./screenshots-images-2/chapter_4/section_1/61c93968-5871-4f7a-81fe-b9c2cb510b29.png",
                            "./screenshots-images-2/chapter_4/section_1/ebae1f05-3db9-46e8-89a6-cf8d087f436e.png",
                            "./screenshots-images-2/chapter_4/section_1/4583aeae-dc7d-45b9-a776-067b226037d5.png",
                            "./screenshots-images-2/chapter_4/section_1/28d99405-7716-4789-b5b3-d7cabb8b0b20.png",
                            "./screenshots-images-2/chapter_4/section_1/01c364f8-23d2-443f-845d-f7d1ee40a67e.png",
                            "./screenshots-images-2/chapter_4/section_1/42f4b1af-5005-45d1-8ea5-a769757b7f86.png",
                            "./screenshots-images-2/chapter_4/section_1/fa3f6829-2376-44f1-b8b5-30ced6b7ca10.png",
                            "./screenshots-images-2/chapter_4/section_1/486f9b12-3de1-47db-ad23-3304a68043df.png",
                            "./screenshots-images-2/chapter_4/section_1/29a8c96a-8f47-4d25-b08b-498f9f3857ce.png",
                            "./screenshots-images-2/chapter_4/section_1/7c64a9e5-09eb-4ff4-828d-2ad14f8c6e59.png",
                            "./screenshots-images-2/chapter_4/section_1/858ddc78-b772-4939-800f-0dfc8a6c5d7a.png",
                            "./screenshots-images-2/chapter_4/section_1/58381131-fbfe-4e7e-921b-6efe41978204.png",
                            "./screenshots-images-2/chapter_4/section_1/9bc7d417-f6ce-4df4-a545-a51d05bcd091.png",
                            "./screenshots-images-2/chapter_4/section_1/8c8204d0-7792-40f9-ba64-a3f9d1576946.png",
                            "./screenshots-images-2/chapter_4/section_1/faea9794-5191-4aa1-b7b4-9ea26d681837.png",
                            "./screenshots-images-2/chapter_4/section_1/335008d1-141d-437e-b117-2fec1ebcbbaa.png",
                            "./screenshots-images-2/chapter_4/section_1/af833c11-6daa-4c98-9549-2c704b74d52f.png",
                            "./screenshots-images-2/chapter_4/section_1/3231e24b-ff66-4063-affc-daf500f1b9a4.png",
                            "./screenshots-images-2/chapter_4/section_1/184b010e-5e5e-4144-a3af-f24f8a6796b9.png",
                            "./screenshots-images-2/chapter_4/section_1/efa915c7-6906-4fed-9033-a01550375b16.png",
                            "./screenshots-images-2/chapter_4/section_1/6bd5f0fb-5f20-4a1e-8480-1e85a734af64.png",
                            "./screenshots-images-2/chapter_4/section_1/69654644-8a48-4a1d-ac2c-0c7e19bb244c.png",
                            "./screenshots-images-2/chapter_4/section_1/be7c8bf0-a492-41b7-847f-1d7e670a2445.png",
                            "./screenshots-images-2/chapter_4/section_1/318c37b1-0dcc-45e5-9d7e-add70f37e9f3.png",
                            "./screenshots-images-2/chapter_4/section_1/d97a5dea-9ec4-4f67-922e-af31bcea1ebc.png",
                            "./screenshots-images-2/chapter_4/section_1/cefc42ed-9405-4ef0-b7c7-ed055c3bda14.png",
                            "./screenshots-images-2/chapter_4/section_1/97980fc5-8b98-479a-b2cf-1122599077c6.png",
                            "./screenshots-images-2/chapter_4/section_1/024b9125-fe90-46cc-bf0d-74825a1e6562.png",
                            "./screenshots-images-2/chapter_4/section_1/aecaef46-9a94-4119-bb38-f8ed43f8c405.png",
                            "./screenshots-images-2/chapter_4/section_1/358dedfa-4782-4fbc-aaf1-02dc79bd541a.png",
                            "./screenshots-images-2/chapter_4/section_1/857fa024-a3c1-400e-9c1d-a42f25876798.png",
                            "./screenshots-images-2/chapter_4/section_1/ee0b9afc-7e40-45a1-b47e-d961e68968c7.png",
                            "./screenshots-images-2/chapter_4/section_1/7802bac2-bc38-4b56-b371-14111c6c15cd.png",
                            "./screenshots-images-2/chapter_4/section_1/5424a0ee-5823-42ee-807e-0a7a23437270.png",
                            "./screenshots-images-2/chapter_4/section_1/bfaf8ac1-7d9a-42c6-b746-b925379c5682.png",
                            "./screenshots-images-2/chapter_4/section_1/9b1119de-a75c-414f-8ebf-8570a8599286.png",
                            "./screenshots-images-2/chapter_4/section_1/01c143d0-0303-43b1-b21a-7feb6b7f2767.png",
                            "./screenshots-images-2/chapter_4/section_1/8aea332d-c72c-4dc0-89c2-de297e136852.png",
                            "./screenshots-images-2/chapter_4/section_1/d8c6102e-0c90-4a99-81b4-1042354be404.png",
                            "./screenshots-images-2/chapter_4/section_1/da77af46-8201-409d-a13a-0d2e37623ca2.png",
                            "./screenshots-images-2/chapter_4/section_1/67cce6c0-f363-4090-b4d2-55e0fee754da.png",
                            "./screenshots-images-2/chapter_4/section_1/c2ae64a4-06a1-4213-b3c9-785c339dba55.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In the previous chapter, we described the logic of our system and compiled\na list of requirements and entities. That is, we decided on what our system\nshould do, and in this chapter we will talk about how it will do it. The goal\nof this chapter is to list the services and describe their functionality and\ndependencies.\n\nI propose the following plan:\n\n\u00ab We decide on the architecture. Before compiling a list\nof services, you need to decide what they will look like.\nWill it be one large application that can do everything\nor many small, conditionally independent services?\n\n\u00ab We identify a list of subsystems. Any complex problem\nis easier and better solved by decomposing a large\nproblem into smaller ones. This approach also works\ngreat when creating a system architecture. The first\nstep is to identify a list of subsystems and a list of their\nfunctionality and dependencies.\n\n\u00ab We identify a list of services. A subsystem is only an\nenlarged representation of the system. It does not\ncontain information about the list of applications or\ntheir external contracts. That is, each subsystem must\n\nbe divided into a list of services.\n\n\u00ab Wewill create a short description for each service.\nYou will get a detailed description of services in the\nfollowing chapters. Here I want to focus only on\ndescribing the functionality, defining dependencies,\n\nand describing the general logic of work.\n\nMicroservice Architecture\n\nTo begin with, I will talk about ways to build systems (Figure 4-1).\n\nFigure 4-1 shows two types of application architecture.\n\nmicroservices\nservice 1\n\nComponent 2\n\n\u2014__>\n\nComponent 1\n\n\u2014_>\nservice 3 [ 8 |\n\nComponent 1\n\nFigure 4-1. Two common methods: microsevices and monoliths\n\nThere are two common methods.\n\nAmonolithic architecture is an architectural style\nbased on one large application that is responsible for\nall the functionality of the system.\n\nMicroservice application architecture is a\n\ndesign approach centered around the concept\n\nof microservices, which are small, independent,\n\nand loosely coupled software components. These\nmicroservices are self-contained and focused on\nspecific business functionalities, making them highly\nmodular and scalable. While individual microservices\nmay not address user problems in isolation, they\n\nplay a crucial role in collectively delivering complex\nfunctionalities within a larger system.\n\nSome time ago, all systems were monolithic; this was primarily due\nto the lack of developed application life-cycle management mechanisms.\nOver time, these mechanisms have improved and become so simple that\nnow almost all new systems are built on a microservice architecture.\n\nMicroservices have the following advantages:\n\nIndependence. This is perhaps one of the main\nadvantages of microservices. Each microservice can\nbe updated independently of other services. First, this\nallows you to release releases more often, and second,\nyou can localize errors faster.\n\nThis is a very critical moment for our system. For\nexample, if we talk about our system, it is unacceptable\nthat the release of a new version of some component\nrelated to the search for profitable strategies will affect or\neven destroy the functionality of the real trading block.\n\nScaling. Imagine that the number of users in the system\nhas increased, but all of them use only one function of\nyour application. If you used a monolithic architecture,\nthen you would have to scale not only the services that\nimplement the desired functionality but also all other\nservices, and this is a waste of a lot of resources. This is\nalso an important advantage for our system. It allows\nus to independently scale the obviously necessary\nblocks for finding strategies and real trading. Perhaps\nat first, only after the system has started, it makes\nsense to direct most of the resources to the search\n\nand optimization block, because a small number of\nprofitable strategies will participate in real trading.\n\nContextual constraint. Each microservice has its\nown strictly limited list of implemented functionality,\nwhich the microservice should not go beyond. This\nhelps avoid tightly coupled services. Each service is\nessentially a separate program, with its own source\ncode and interfaces. Thanks to this, you physically\ncannot use the internal classes of one service in the\ncode of another service. All you have at your disposal\nare their interfaces; you don\u2019t need to know about the\ninternal features.\n\nDistributed architecture. This has a valuable quality:\nyour microservices can be deployed on different servers.\nFor example, I use a cluster of several home computers\nto search and optimize strategies, and for real trading\n\nI rent servers because they guarantee uninterrupted\noperation. This approach allows me to save money,\nsince home computers are cheaper and the requirement\nfor uninterrupted operation is not so high.\n\nMicroservice architecture also has its disadvantages. The main one is the\nincreasing complexity of system development. If in a monolithic architecture\neverything is synchronous and consistent, then in a microservices architecture\nthis is not the case. It is necessary to start thinking asynchronously and\nabout events. But this drawback for me was easily offset by the possibility\nof independent scaling and updating. For me, it is critically important to\nbe able to quickly change the code of the components responsible for the\nsearch strategy and at the same time not break the strategies that work in real\ntrading. It was also important that I could conduct testing on relatively cheap\nequipment at home and rent servers only for real trading. Then, to be honest,\nat first my real trading system worked on a separate computer at home. It was\ncheap, and I was also sure that if something went completely wrong, I could\nsimply turn off the power to the computer.\n\nBefore we go any further, I would like to cover a few important\nconcepts related to microservices so that there is no misunderstanding.\n\n\u00ab Asubsystem is a set of services related in meaning.\nFor example, within our system I see two main large\nsubsystems: the strategy search subsystem and the real\ntrading subsystem.\n\n\u00a2 Aservice is what is called a microservice in a\nmicroservice architecture. This is an independent\nunit that serves one purpose and provides limited\nfunctionality.\n\n\u00ab The application is what makes up the components\nof the service. Usually there are no more than two.\nOne of them provides API functionality, and the other\nis responsible for executing possibly lengthy and\nresource-intensive asynchronous background tasks,\nsuch as periodically receiving or updating data from\nother systems or periodically taking a long time to\ncalculate something.\n\n\u00ab Alibrary is a collection of software functions or classes\nintended for use in different applications. For example,\nit makes sense to use the same library for logging,\nrather than writing your own for each service.\n\nKubernetes\n\nIn this section, I'll talk about an important topic: Kubernetes. I'll tell\n\nyou more about how to install it on a server, manage it, and deliver\n\nyour applications to it in Chapter 9. But in this chapter I will cover a few\nimportant concepts so you can better understand some of my architectural\ndecisions.\n\nIn the past few decades, a large number of approaches to software\ndevelopment have accumulated in the software field. Dozens of\nprogramming languages have become popular, each of which has its own\ncompilation and execution mechanism. This means that in addition to the\ncomplexity of writing a program, there is also the complexity of running\nit on the server, because the system administrator has to understand the\nintricacies of how programs work in a particular language. Adding to this\ncomplexity is the different dependencies between applications. Often your\nprogram cannot run without other pre-installed applications. Sometimes\nwhen you create a service, it will fine on your personal computer, but when\nitis deployed to another server for testing, something goes wrong. It might\nbe that your application requires one version of a pre-installed helper\napplication, and the server has another installed. This problem was solved\nwith the arrival of containers.\n\nAcontainer is a standardized and portable package that includes\neverything you need to run your application. This allows you to separate\nyour application from the infrastructure, which includes the operating\nsystem and pre-installed applications.\n\nIt doesn\u2019t matter what environment your application will run in, what\nlanguage it is written in, and what dependencies it has. The developer\njust needs to create a program and pack it into a container, and the\nadministrator can work with the container, which is ready to run. Of\ncourse, you can launch it manually. If the developers have released a new\nversion of the application, you will also have to update the entire system\nmanually. You must not forget about the uninterrupted operation of the\nsystem, which means you first need to launch a new version, transfer the\nload to the environment with the new version, and only then stop the\napplication on the old environment. Figure 4-2 shows how this process\nlooks schematically.\n\n1\n\n'\n2 '\n\n:\n\n:\n\napp H H\n'\n\nversion 0.1 '\n:\n\n:\n\n:\n\n'\n\n:\n\n:\n\nFigure 4-2. Application update process\n\n4\n\nThere is a high chance of error in this entire procedure, which can be\nsolved with orchestrators.\n\nAn orchestrator is a system that helps manage the launch and\noperation of containers. The most popular of them is Kubernetes. The\norchestrator not only provides the functionality to deploy your containers\nbut also allows you to easily scale, update, and monitor the performance of\nyour entire system. In this chapter, it is important for me to tell you about\nscaling. One of the central concepts of Kubernetes is the pod. This is the\nbasic building block of this orchestrator, and it is also the only object in\nKubernetes that causes the container to run. Roughly speaking, a pod is a\nsmall computer on which your application runs. Kubernetes allows you to\ncreate multiple pods for one application. It is this feature that provides the\n\nability to horizontally scale your system. Since one application can have\nseveral pods, it is important when designing an application to remember\nthat any of your applications may not be launched in a single copy. For\nexample, if your application processes theories, it is important when\ndesigning it to consider that two different pods could start working in\nparallel on the same theory, which could lead to data corruption.\n\nNow that you have the minimum knowledge required to design a\nsystem built on a microservices architecture, let's get started.\n\nSubsystems\n\nLet's first determine the list of subsystems and their functionality. I see\nonly two subsystems in our system. This is a subsystem for searching for\nprofitable strategies and a subsystem for real trading. We talked about\nthem a lot in the previous chapter; I see no reason to complicate our\nsystem at the current design stage.\n\nThe task of the search subsystem is to find a profitable strategy and\nreport this to the real trading subsystem. The real trading subsystem must\nstart trading based on the found strategy and pass the strategy indicators\nto the search subsystem to optimize the strategy. As a result, the enlarged\ndiagram of our system will look like Figure 4-3.\n\nprofitable strategies\n\nstrategy search real trading\n\nsubsystem subsystem\n\ninformation about real trading\n\nFigure 4-3. Subsystem interaction diagram\n\nStrategy Search Subsystem\n\nThe purpose of the subsystem is to search for profitable strategies. Let me\nremind you that for this the user themselves or with the help of a generator\nmust generate theories. This means that the search subsystem must\nprovide the user with an interface that allows this to be done. This entails\nthe creation of a separate front-end service.\n\nWhenever it comes to users, it is very important to raise the issue\nof roles. What are the user roles in the system? How are these users\nauthorized? Is there a need to store user actions? I decided not to add this\nfunctionality to my system. The main reason is that most likely the system\nwill be used by a limited circle of people with the same full rights. I prefer\nto focus on the strategy search functionality and can add an authorization\nsystem and normal accounting of user actions later if necessary.\n\nSince our system will not have users as entities, there is no need for a\nsingle API service to provide uniform functionality to the front end. It will\nbe redundant and turn into a simple and nonfunctional layer. Therefore, at\nthe current stage, the subsystem will look like diagram 2 in Figure 4-4.\n\nSchema 1 Schema 2\n\nFigure 4-4. Options for interaction with the front end\n\nProcessing Generators\n\nLet's go in order. The user, using our front-end service, should be able\nto control the generator to generate theories. So, the user went to\nthe generator settings page, filled out the required fields, and clicked\nthe generate button. The front end sends a request to the back end\nfor generation, and theories are generated. They can be generated\nsynchronously, when the user waits until the system generates all the\ntheories, or asynchronously, when the user is notified that the process\nhas started, and the result can be viewed in a special tab or in the\nsame window.\n\nI chose the asynchronous option for a number of reasons.\n\n\u00a2 Generating theories may take some time because there\nmay be many of them. It\u2019s not a good idea to make the\nuser wait all this time.\n\n\u00a2  Itis not clear what to do if an error occurs during\nthe generation process, when some of the theories\nhave already been generated. Should I delete the old\nones? Also, how do I understand which of them relate\nspecifically to this request? It turns out that in the case\nof an error, the user will wait not only for the theories to\nbe generated but also for them to be deleted.\n\n\u00ab Howwill the user know the result if the session is\nsuddenly interrupted such as when the Internet\ngoes off?\n\nSince the generation of theories will be asynchronous, it is necessary to\nsomehow display information about the progress of the generator, as well\nas the generation status, on the front end. Since the generator has a state\nin the form ofa status, it means it becomes an entity. That is, the user will\nbe able to see a list of previously created generators with their statuses and\nsettings.\n\nThere are several more arguments in favor of the generator as an entity.\n\n\u00a2 The generator as an entity allows the user to fill in only\npart of the required fields, save their work, and return\nto it later.\n\n\u00a2 The generator as an entity allows the user to create\ngenerators by copying. This means that if the user\nwants to change, for example, only the list of indicators,\nthey will not have to enter the remaining fields again.\n\n\u00a2 The user will be able to see a summary of the generated\ntheories in one place because they will be linked to a\nspecific generator.\n\nAs a result, I see the generator settings page as shown in Figure 4-5.\n\nCapital management: recent _[\u00a5]\nIndicators: Twa} |]\nSignal templates: I]\n\nsearch etn:\n\nTheories:\n\u2018Second step 14729\nTheory 79 First step 134 0.0845\nTheory 80 3489 0.0035\n\nFigure 4-5. Generator settings display option\n\nLet\u2019s move on. Here the user clicked the Generate button. The front\nend sent a signal to the back end to start generation. And we agreed that\nthe generation of theories is an asynchronous process. This means the\nback end must somewhere note the fact that this generator needs to be\nprocessed and send a response to the front stating that the user\u2019s request\nhas been processed.\n\nOf course, the program must change the status of the generator to\nwaiting. In principle, this status can be used as a flag for the generator\nprocessing process, and then some background job will pick up this\ngenerator and begin processing it. By background job, I mean a special\nprocess that runs on a schedule, for example once a minute, and does a\nspecific job.\n\nThis solution has one big drawback: the degradation of the search\nspeed for active generators. This happens because the total number of\ngenerators will grow, which means that a request to search for generators\nin a certain status will work slower and slower. An alternative to working\nwith statuses is working with a queue. You can put a generator in a queue,\nand background jobs will see it, process it, and remove it from the queue.\nThis way, only active generators will be stored in the queue and it will not\ngrow. There are several options for implementing queues, for example\nbased on a database. Many cloud platforms have great queuing and\nprocessing solutions. There are also several mechanisms for managing\nqueues; one of the most popular is Kafka. However, cloud solutions\ndoes not suit me, because I want my system to be independent of the\ncloud platform so I can deploy it on my home computer. I also think that\nusing Kafka to solve this issue is too cumbersome, because you need to\nunderstand it and also be able to administer it.\n\nTo make a decision about how this process will be implemented, it is\nnecessary to take into account that the theory generators will be created by\nthe user, which means that there will be few of them, and the degradation\nwill be insignificant. Therefore, I propose taking the simplest route.\n\nWhen calling the back-end method, the waiting status is set, which\nwill serve as a flag that the generator needs to be processed. Then some\njob should hire him. What this job will do is run periodically, check if there\nare generators for processing, and, if any, process them. At this stage, it is\nimportant to discuss whether these jobs will run in the same application as\nthe API or whether it will be a separate application.\n\nI believe that this should be a separate application, and there is one\nimportant reason for this. The process of generating theories can be\nlengthy and costly. During this time, the user should be able to continue\nworking without interruption or slowdown in performance. If an\napplication is busy generating theories, then it will not be able to process\nuser requests with the same efficiency as before. In addition, this approach\nwill allow these two applications to scale independently of each other.\nAfter all, we understand that the API App load will most likely be lower\nthan on the Background Jobs App. Therefore, at this stage, the strategy\nsearch service looks like Figure 4-6.\n\nStrategy Search Service\n\nFigure 4-6. Strategy Search Service application structure\n\nAs a result, the process of automatic theory generation will look\nlike this:\n\u00ab The user enters the required data in the front-end\nservice and clicks the Generate button.\n\n\u00ab The API App of the Strategy Search Service accepts a\nrequest from the front end and sets the generator to\nWaiting status in the database.\n\n\u00ab The Background Jobs App of the Strategy Search\nService periodically queries the database table with\ngenerators, and if it finds a generator in the Waiting\nstatus, it begins to generate theories.\n\n\u00ab After generating theories, Background Jobs App sets the\ngenerator status to Done and starts looking for the next\ngenerator in the Waiting status.\n\nQueue\n\nWe have decided how theories will be generated. But after generation, the\nsystem must take these theories to work. Each of these theories must go\nthrough the three steps described in the previous chapter, and if the first\nstep is unsuccessful, the process of searching for strategies according to\nthis theory must be stopped.\n\nTo process theories, you can, of course, use statuses as in the case of\ngenerators, but I don\u2019t like this option because, unlike generators, there\nwill be many theories, which means that the request to search for theories\nwith the required status will degrade. There is also another problem\nthat we will encounter: when two pods simultaneously take on the same\ntheory. And this means only one thing: a queue is needed. I have already\nsaid that I do not want to use a queue built on the mechanisms of cloud\nplatforms, since I do not want to tie my system to any solution provider, so\nwe will build a queue at home.\n\nIhave several queue requirements.\n\u00a2  Itshould be preserved even if the pod is stopped.\n\n\u00abThe ability to horizontally scale queue handlers is\nrequired.\n\nThere are several popular solutions for this task: RabitMQ, Kafka, or a\nPostgres-based queue.\n\nI discard RabitMQ right away, since it does not guarantee message\ndelivery, and for me this is an important point, because I do not want any\nof the theories to be processed.\n\nKafka is a great mechanism, but it requires quite a lot of server\nresources, so I will consider it as a growth point for my application. If it\ngrows to such an extent that the Postgres-based mechanism becomes\nineffective, then Kafka can be implemented.\n\nThe Postgres-based queue is perhaps not the most common solution,\nbut it has one big advantage: it is cheap in terms of the resources required,\nand besides, our application will already use Postgres to store data.\n\nSo, our queue should provide the following functionality:\n\n\u00ab Only those entities that need to be processed should\nbe in the queue. This means that after processing,\nit is necessary to remove the processed entity from\nthe queue.\n\n\u00ab Ensure that entities are quickly added to the\nprocessing queue.\n\n\u00ab Ensure that parallel processing of one entity by two\npods is prohibited.\n\nLet's immediately design the tables in the database that we will need to\norganize the queue. Of course, we will have a queue table with an entity_id\ncolumn. It will contain entries with new theories. In order to prevent two\npods from using the same theory, it is necessary to somehow mark the\ntheories that are already being processed by the system.\n\nNote Table locking in a database is a mechanism that allows you to\nlock an entire table or its individual records, for example, for reading\nor writing for another database user. I'll talk more about it in the next\nchapter, but for now the main thing to understand is that when a pod\nstarts working on theories, it can lock a table or rows in it, and then a\nrequest from another pod will wait for the lock to end.\n\nIf we lock the queue table, then it will not be possible to add new\nrecords with theories to it. An additional table will help us get around this\npoint, called active_queue, with an entity_id column. When the next pod\nwants to process the queue of theories, it will do the following:\n\n\u00ab Lock the active_queue table\n\n\u00a2 Select an unoccupied theory, that is, a theory that\nis in the process_queue table and not in the active_\nqueue table\n\n\u00a2 Record that it is active in the active_queue table\n\u00ab Release the lock from active_queue\n\nBut what would you do if the pod started working on a theory and\nsuddenly ceased to exist? How do other pods find out that no one is working\nwith this theory anymore? To solve this problem, let's add a timestamp\ncolumn to the active_queue table. When the next pod starts working, it\nwill take over the theory even from the active queue if more than a certain\namount of time has passed from the timestamp, for example several\nminutes. As a result, the tables providing the queue will look like Figure 4-7.\n\ntheories | me\nid\n\nentity_id\n\ntimestamp\n\nFigure 4-7. Database table schema\n\nLet's also solve the scaling issue. There will be tasks for processing the\nlaunch queue of the BackgroundJobs application, which have already been\ngenerating theories, or it is worth moving them into a separate application,\nor a service.\n\nI don\u2019t yet see any reason to move the theory processing process into\na separate service, because this will add more work for us in the form\nof needing to transfer data about created theories to a new service. This\nis a large amount of data, and we will also have to solve the problem of\ntransferring information about created indicators and methods and money\nmanagement between the two services and ensure their consistency.\n\nYes, perhaps our service is becoming like some kind of hybrid between\n\na monolith and a microservice, but I am trying to strike a balance\n\nbetween the ability to quickly scale the system and the complexity of its\ndevelopment. If a team of developers, or even several teams, were working\non it, then of course it would make sense to move work with theories into a\nseparate service. But since I work alone and a temporary stop in processing\nthe queue of active theories in the event of an unsuccessful update of the\nBackgroundJobs application is not critical for me, I believe that there is no\nneed for a new service.\n\nI propose solving the issue with easy horizontal scaling by increasing\nthe number of applications for this service. Now there will be three of them\nwith one common database, where the Theory Processing App will process\nthe queue and guide the theories in three steps (see Figure 4-8).\n\nStrategy Search Service\n\nTheory\n\nProcessing App\n\n\u2014\n\nFigure 4-8. Structure of Strategy Search Service with three applications\n\nFinite State Machine\n\nWe came up with a horizontally scalable solution for theory processing.\nBut what will this processing look like? A simple movement from status\n\nto status does not suit us, if only because after the first step we can either\nrecognize the theory as unsuitable or move on to the second step, which\nmeans that the process of processing the theory has branches. And when\nyou are faced with the task of moving some entity through a business\nprocess, with branches, it makes sense to think about implementing a state\nmachine. A state machine is one of the ways to process an entity according\nto a business process. The idea of a state machine or finite state machine\nis that your entity can be in only one state at any given time. The number\nof these states is finite, and the state machine also contains rules for\ntransitions between states.\n\nTransitions between states occur under the influence of external\nsignals. For example, transitioning the state \u201cProcessing the first step\u201d to\n\u201cChecking the suitability of the theory\u201d means calculating all strategies\nthat were generated using the optimization algorithm. Figure 4-9 shows a\nsimplified diagram of the movement of the theory through states.\n\nFirst Step\nProcessing,\n\nSecond Step Third Step\nProcessing Processing\n\nFigure 4-9. Enlarged theory processing process\n\nConcept of Theory Processing Steps\n\nAt this stage, we decided how the theory would move through the process.\nLet\u2019s discuss how this process will occur. In the previous chapter we found\nout that the processing of the theory will be carried out in three steps.\n\nThe first step is a quick test of the theory. In this\n\nstep, a subtheory is created with a limited number\n\nof parameter variations by increasing the step of\nvalues for each of them. After this, an optimization\nalgorithm configured in breadth is launched. Thanks\nto this, strategies are generated and calculated. This\nprocess is iterative because the optimization algorithm\ncreates a new set of strategy parameters based on\n\nthe performance of the strategies created in the\nprevious iteration. After the optimization algorithm\nis completed, the strategies are checked against\nquality conditions. If at least one strategy meets these\nconditions, then the theory is considered to be of\nquality.\n\nIf, as a result of the first step, the theory is recognized\nas qualitative, then the iterative creation of subtheories\noccurs with a decrease in the step of parameters and a\nnarrowing of the range of their values. Next, all created\nstrategies are checked for the second quality condition.\n\n\u00ab Inthe third step, the suitable strategies of the second\nstep are calculated again, but using tools not used in\nthe first and second steps. After that, they are checked\nfor final quality status and sent to the real trading\nsubsystem.\n\nWhen I described all three steps, the first thing I thought of was\ncreating step entities because they have a lot in common. They take\ninput settings in the form of an optimization algorithm and financial\ninstruments, and as an output you get a set of strategies. See Figure 4-10.\n\nOptimization algorithm\n\nQuality condition\nInstruments\n\nStrategies\n\nFigure 4-10. Step entity\n\nBut when I thought about what should happen in each step, I\nabandoned this idea because all three steps are significantly different\nfrom each other. In the first step, only one subtheory is created. There is\nabsolutely no logic in narrowing the range of values and iterative search\nfor strategies. In the third step, there is no work with the optimization\nalgorithm; in this step, only the calculation of already created strategies\nand their selection occurs. As a result, I came to the conclusion that\nI would not be able to delegate the authority to create subtheories to\nanother entity to facilitate the logic of passage through the theory process.\n\nAs a result, it turned out that the theory moves through the process\nwithin the first step, as shown on the state machine state map in\nFigure 4-11.\n\nCreate fast check\nSubTheory_1\n\nEvent: SubTheory_1\ncompleted\nCheck First Quality\nCondition\n\nSet status \u2018Worthless\u2019\n\nFigure 4-11. Logic of the first step of the theory process\n\nIn this process, special attention should be paid to the event of\ncompletion of subtheory calculations. Calculating a subtheory is an\niterative process that can take a long time, and I may even decide to\noutsource this work to a separate application or service, which is why,\ninstead of taking the \u201cCalculation of a subtheory\u201d step, I chose a scheme\nwith asynchronous calculation. This means that the theory will wait and\ndo nothing until a signal arrives that the subtheory has been completely\ncalculated. I would also like to point out that in this diagram, the status is\njust a marking that will be needed to show the user the progress of work on\nthe theory, nothing more. That is, this status has absolutely no effect on the\nprocess.\n\nFigure 4-12 shows the second step of the processing process.\n\nSet status \u2018Second step\u2019\nCreate SubTheory\n\nEvent: SubTheory\ncompleted\n\nFigure 4-12. Logic of the second step of the theory process\n\nIn this diagram, it is worth paying attention to the fact that subtheories\nare created iteratively. Let me remind you that the calculation of\nparameters for a new subtheory is based on the calculation results of the\nprevious subtheory, but the very first system will be created based on the\nsettings of the theory.\n\nFigure 4-13 shows the third step of the processing process.\n\nSet status \u2018Third step\u2019\nRun strategies\ncalculating\n\nEvent: Strategy\nCalculated\n\nSet status\n\u2018FinishWorthless*\n\nCheck final quality\ncondition\n\nFigure 4-13. Logic of the third step of the theory process\n\nThere are several things that are notable about this scheme.\n\nThe first of them is the asynchronous calculation of strategies. We'll\ntalk about this a little later, but I\u2019ll say right away that it will be parallel and\nhorizontally scalable. The theory can move to the next state only after\ncalculating all strategies, which means we need to check the fact that all\nstrategies have been calculated every time we complete the calculation of\nthe next strategy. It is also important that our state machine be able to work\nwith the parallel arrival of events. Imagine a situation where the two last\nstrategies were calculated at the same time. When checking, the service will\n\u201csee\u201d that there is another uncalculated strategy and will not change the state\nof the theory. As a result, the theory will forever remain at the \u201cWait\u201d step.\n\nPlease also note that if the final check fails, I set the status to\nFinishWorthless, not Worthless. This is done so that the user can see the\ndifference between a worthless theory after the first quick test and after the\nfinal one. It is quite possible that they will use ideas from this theory when\ngenerating the next batch of theories.\n\nCalculation of Subtheories\n\nLet\u2019s think about how the subtheory will work. Obviously, this has a\ncertain process. At a minimum, it should have several statuses such as\nCreated, In Progress, and Completed. The question is whether this process\nis complicated enough to start using a finite state machine. I see the\nsubtheory process taking place as shown in Figure 4-14.\n\nGet templates from\noptimization algorithm\n\nEvent: Strategy\nCalculated\n\nGet templates from\noptimization algorithm\n\nIs the number of\ntemplates greater than\nzero?\n\n\u2018Set status Completed\u2019\n\nFigure 4-14. Subtheory processing\n\nIt\u2019s easy to imagine what this process would look like using a finite state\nmachine. The main thing to remember is that a subtheory must have a\nseparate state map.\n\nProcess Review for Generators\n\nSo at this stage we already have two entities that use the state machine.\nAnd you know what I really don\u2019t like at this stage in the system diagram?\nGenerators have begun to deviate from the uniform pattern of entity\nprocessing. Even worse, the service will have a separate Background Jobs\nApp exclusively for them. I suggest reconsidering this point.\n\nNote The fact that | periodically change my solution can be\nconfusing, but let me remind you that creating an architectural\nsolution is an iterative process. Revising architectural decisions is a\nnormal phenomenon. It is better to reconsider your decisions now,\nbefore development begins, than to realize that something needs to\nbe changed at a later time.\n\nAt this stage, the state map for the generators looks very simple (see\nFigure 4-15).\n\nSet status \u2018Pending\u2019\n\nGenerate Theories\n\nSet status \u2018Completed\u2019\n\nFigure 4-15. State map for theory generation process\n\nThe process of generating theories is iterative. Still, it\u2019s a slow process.\nIteration will provide the user with the opportunity to interrupt the process\nof generating theories if the user understands that all the theories created\nin the previous iterations are worthless. Better yet, this check should be\nperformed automatically, as shown in Figure 4-16.\n\nThat is, we will stop using Background Jobs to process generators and\nstart using pods of the Theory Processing App for these purposes. This\nmeans that when the user clicks the Generate button, the API App will\nmake a new entry in the processign_queue table.\n\nAlso, since the state machine will begin to process not only theories\nbut also subtheories with generators, it makes sense to rename the\nTheory Processing App to the Processing App. I will talk in detail about\nthe operation of my state machine in future chapters. Figure 4-17\nshows the updated service diagram, without a separate application for\nbackground jobs.\n\nStrategy Search Service\n\nProcessing App\n\nFigure 4-17. Final Strategy Search Service application structure\n\nOptimization Algorithms\n\nI would like to abstract the work with optimization algorithms into a\nseparate module, which will have its own separate versions and which\nwill not know anything about the fact that it works with strategies or\nsubtheories. This is necessary to separate responsibilities between\nmodules. Imagine that you want to make changes to the subtheory in such\n\nThat is, we will stop using Background Jobs to process generators and\nstart using pods of the Theory Processing App for these purposes. This\nmeans that when the user clicks the Generate button, the API App will\nmake a new entry in the processign_queue table.\n\nAlso, since the state machine will begin to process not only theories\nbut also subtheories with generators, it makes sense to rename the\nTheory Processing App to the Processing App. I will talk in detail about\nthe operation of my state machine in future chapters. Figure 4-17\nshows the updated service diagram, without a separate application for\nbackground jobs.\n\nStrategy Search Service\n\nProcessing App\n\nFigure 4-17. Final Strategy Search Service application structure\n\nOptimization Algorithms\n\nI would like to abstract the work with optimization algorithms into a\nseparate module, which will have its own separate versions and which\n\nwill not know anything about the fact that it works with strategies or\nsubtheories. This is necessary to separate responsibilities between\nmodules. Imagine that you want to make changes to the subtheory in such\n\na way that the logic for generating variables for optimization algorithms\nwill change. For example, you will add the ability to use not only indicator\nvalues in your signals but also their slope angles, or even switch to\nformulas instead of pure indicator values. If optimization algorithms are\nnot abstracted and work directly with strategies, then you will have to\nchange this block; otherwise, you will only need to change the class that\nis responsible for converting strategy data into a set of variables for the\nalgorithm.\n\nMoving optimization algorithms into a separate module provides\nanother important advantage: you can test their work on much faster\nmathematical functions, such as the Kearfott or Rastigin function. I will\ndiscuss in detail how to test the optimization algorithm in Chapter 7. Now\nthe main thing to understand is that complex optimization algorithms\nare not a constant, but a kind of constructor of methods and parameters.\nYou can create an infinite number of variations of the genetic algorithm or\nother algorithms derived from it. Therefore, the functionality for quickly\nchecking the operation of your algorithm is vital.\n\nIn Figure 4-18, I clearly demonstrated working with the future library of\noptimization algorithms.\n\nSet of params Values 1 | Criterion 1 Setof params Values t\nSet of params Values 2 | Criterion 1 Set of params Values 2\n\nStrategies Data Set of params Values N | CritertonN [Opnmizaton] Set of params Values N Strategies\nstrategy strategy >\nSevianer OG isa Deserializer\n\nFigure 4-18. An example of using the optimization\nalgorithms module\n\nThe fact that the user will have to independently create optimization\nalgorithms based on some templates suggests that the optimization\nalgorithm also becomes an entity.\n\nTasks\n\nWe have decided how strategies will be created. But how will they be\ncalculated? To calculate a strategy, two components are required: the\nstrategy itself and a certain period of historical data for the instrument.\n\nI placed the historical data period into a simple entity called\nTestCandleInterval. This entity accumulates all the information necessary\nto obtain a set of candles.\n\nNamely:\n\n\u00ab Exchange Id. It is no secret that the same instrument\ncan be traded on several exchanges, which means its\nprices can be different.\n\n\u00a2 Financial instrument Id.\n\n\u00ab StartDate. All candles with an opening date greater\nthan this value will be included in the selection for\nTestCandleInterval.\n\n\u00ab StopDate. The second border is for the opening date of\nthe candles.\n\nIn this book, I implement a relatively simple system. Therefore, the\nuser will create the TestCandleInterval independently. But there is room\nfor growth here. For example, you can create a TestCandleInterval while\nloading historical data. Remember in the previous chapter we talked about\nwhat tools should be used to launch a ready-made strategy. And one of\nthe options was to separate them not by types of instruments but by types\nof charts. The new entity is perfect for both implementations because\nit contains a StartDate and a StopDate. This allows you to divide the\nhistorical data of one instrument into several test intervals.\n\nIn connection with the introduction of the new TestCandleInterval\nentity, it turns out that to calculate the strategy, only two components\nare needed: the strategy itself and TestCandleInterval. I combined these\n\nparameters into a separate entity and called it Task. It also makes sense to\nadd a status to the task to understand whether it has been counted or is\nstill being counted or maybe just waiting in queue for calculation. Tasks\nwill not have a complex process. This is a small elementary unit that will\nhave only four states with elementary logic for transitioning from each\nother: Created, Pending, Done, Error. There will be many tasks\u2014hundreds\nof thousands. Putting them in the same queue as generators and theories\nis not a good idea. We will then lose flexibility in scaling the system.\nTherefore, I decided to put the tasks in a separate queue and even allocate\na separate application for them.\n\nThis is how it will work:\n\n\u00a2 The subtheory will generate tasks and place them in\na queue.\n\n\u00ab Aseparate application with a large number of pods will\ntake a task from the queue, mark it as active, and after\ncalculation, remove it from the queue.\n\n\u00abIfthe user decides that the theory is bad even before\ncompleting all the steps, then when the theory\ncalculation is cancelled, their subtheories will be\ncancelled, and their tasks will simply be removed from\nthe queue.\n\nFigure 4-19 shows the task queue processing process. It can receive\ntasks from several sources. For example, the user can create a task through\nthe front end and set it to be calculated via the API App. Or the Processing\nApp, while working on a subtheory, will set tasks for calculation.\n\nTasks Queue\n\nTask 1\nTask 2\n\nTask N\n\nFigure 4-19. Task queue processing process\n\nIt is extremely important that the calculation of tasks is as fast as\npossible. This process needs to be optimized down to the millisecond. At\nthis point, I ran into a problem. I must have a mechanism by which I can\nverify that my system is working correctly. To do this, I needed not only the\nfinal indicators of the effectiveness of the strategy but also the intermediate\nresults, such as the calculated values of the indicators on each of the\ncandles, as well as all created positions with system orders and deals. I\nwould like to take a separate task and see how the strategy behaved, when,\nand why it opened positions. Obviously, to implement this functionality,\nit is necessary to save data on the progress of the strategy into a database,\nand this is not a quick procedure. I also knew that the automated parts of\nthe system did not need this data; the final results were enough for it. In\nconnection with all of this, I added three calculation modes to the task:\n\n\u00a2 With only the final information about the calculation\nsaved. In this mode, the database will store information\nabout the final results of the calculation, the minimum\nnecessary for the operation of the automated parts of\nthe system\n\n\u00a2 With saving data on positions. In this mode, in\naddition to the final results, the database stores\ninformation about open positions with status history,\nwith all orders and transactions\n\n148\n\n\u00a2 With saving indicator values. In this mode, not only\nall data from the previous two modes is saved, but also\ninformation about signal calculations, which includes\nthe values of indicators and groups of conditions on\neach candle.\n\nCore\n\nIn our entire scheme of dividing the system into two subsystems, I am\nconfused by the fact that testing and verification of the trading strategy\nwill take place in one subsystem, and the strategy will work in another. It\nis necessary to build the architecture in such a way that the system nodes\nresponsible for making decisions about opening or closing positions,\n\nthe logic of the system orders, and all the components of the strategy are\ncommon to the search and real trading subsystems.\n\nThis is reasonable, because we will test not only the strategies but also\nthe code that implements them, which means this code should be the\nsame. For this I created a separate library called Core. It is in Core that the\nlogic of the strategy and all its components will be concentrated.\n\nAs input, Core will receive information about changes in the market,\nas well as signals about changes in the status of exchange orders, and as\noutput, it will send signals about the need to place or close an order with a\nbroker. See Figure 4-20.\n\n+ Trading data\n+ Deals events\n\n+ Command to place an order\n+ Command to cancel order\n\nFigure 4-20. Top-level view of the Core module\n\nObviously, Core will store entities such as Strategy, Signal, Instrument,\nand so on. This means it must contain all the necessary components to\nwork with the database. I thought about separating Core into a separate\nmicroservice but quickly abandoned this idea, mainly because when\ncalculating tasks, a lot of time would be spent on network interaction\nbetween the task calculation service and Core, and we cannot afford this.\n\nI would also like to include in Core the functionality for calculating\nindicators of the effectiveness of the strategies; it would be strange if the\nreal trading system calculated indicators using one formula while the\nsearch subsystem used another.\n\nSandbox Exchange\n\nAt this stage, we need to know what will process signals and how we\nwill process them. This means we will need to create a small Sandbox\nExchange module that will store orders, respond to signals for placing\nor cancelling an order, and make a decision about closing an order as\ncandles arrive.\n\nAs a result, I see the big-picture process of calculating the task as\nfollows:\n\n\u00ab We get candles by setting TestCandlelInterval (all of it or\nin batches).\n\n+ Ina loop we go through all the candles, doing the\nfollowing:\n\na. We notify Sandbox Exchange about the\nappearance of new candles.\n\nb. We notify Core about the appearance of new\ncandles.\n\nSuch a system does not ideally correspond to what will happen in real\ntrading because Sandbox Exchange in our version does not know anything\nabout the order book. This means it will not be able to correctly simulate\norder execution because it doesn\u2019t know whether there were enough offers\nat that moment in time and at what prices they were offered.\n\nBut we still have no choice. There is no way we can wait several years\nuntil we collect the required amount of information, because it is almost\nimpossible to find historical data with order books. Therefore, I will\nsimply try to implement Sandbox Exchange as similar as possible to a real\nexchange.\n\nReal Trading Subsystem\n\nThis subsystem has the following goals:\n\u00ab Ensuring smooth operation of profitable strategies\n\n\u00a2 Ensuring the strategies work with the right types of\nfinancial instruments\n\n\u00a2 Constant determination of the type of financial\ninstruments\n\n\u00a2 Providing the user with the ability to manage the\ntrading process such as the ability to enable or disable\na strategy\n\nAgain, since it\u2019s an interface, a separate front-end service is needed.\nAs in the case of the search subsystem, I propose we abandon the system\nof roles and solving issues of access levels, because at the beginning the\nsystem will have a limited list of trusted users with the same full rights to\nall actions in the system.\n\nIntegration with Exchanges\n\nIn a real trading system, there is a big problem that we have to face: the\nlarge amount of information coming from exchanges. Imagine that the\ncandle update information for an instrument such as the Bitcoin-Dollar\npair could be received via websockets from the exchange at least once\nevery 50 ms. And we will have many such financial instruments.\n\nFirst, it is necessary to separate the work with exchanges from other\nservices of the subsystem into a separate service that provides a single\ninterface. I don\u2019t want other services to know anything about the internal\nimplementation of integration with each of the exchanges. But is this\nenough? Imagine that you discovered a bug or decided to add integration\nwith another exchange. If all the code for working with exchanges is\nlocated in one service, then when updating the code associated with one\nexchange, you will have to stop working with the others. This means that\norders will not be placed and data on changes in candlesticks will not\nbe received, which entails a loss of money. Therefore, it makes sense to\nmake each of the adapters (the module responsible for converting specific\ninformation from the exchange into our single standard) a separate\nservice.\n\nLet's imagine a scenario where a certain service of our subsystem\nwants to place an order with a broker. To do this, the service will have to\ntake the URL of the required adapter, which is responsible for integration\nwith a specific broker. It turns out that each back-end service that\nneeds to use adapters will have to contain the logic for determining this\nURL. What happens if the broker switches to a new version of the API and\nwe have to change the adapter interfaces? This is the first problem. The\nsecond problem is that somewhere we need to store a mapping between\nour instrument names and the broker names. This means that we will\nneed a database. And what? We have to create a separate database for\neach broker? To solve these problems, we can create a proxy service,\nan exchange gateway. This will take on the functionality of knowing\n\nwhich of the adapters needs to be addressed, and it will also store name\ncomparisons in its database and monitor the uniformity of adapter\ninterfaces.\n\nFigure 4-21 demonstrates both approaches.\n\nFigure 4-21. Possible exchange gateway architectural solutions\n\nNow let\u2019s define the approximate functionality of the subsystem for\nworking with exchanges. Since to work with exchanges it is necessary\nto create several services (and even this will be a relatively independent\nunit that can be used in other systems), I will separate it into a separate\nsubsystem.\n\nSo, what functionality will be included in the subsystem for working\nwith exchanges?\n\n\u00a2 Ability to place orders using a common interface for all\nexchanges.\n\n\u00a2 Possibility of order cancellation.\n\n\u00a2 Providing information on updating order statuses and\ncompleting deals.\n\n\u00a2 Providing trade data. In our case, this will only be\ndata on updating candles, but in the future it can be\nexpanded with information about changes in the\norder book.\n\nFigure 4-22 shows what the first and second steps will look.\n\nFigure 4-22. Sequence of service calls when creating an order\n\nThis looks bulky. Time will be wasted on networking, but I decided to\ncompromise on this issue. | initially defined my system not as a system\nfor scalping trading, since I understood that I most likely would not be\nable to compete with traders who rent their servers in close proximity\nto the exchange servers. I will purposefully look for strategies in which\nthe average lifetime of open positions is measured in minutes or hours,\nnot in seconds, and I believe it is worthwhile to compromise on ease of\ndevelopment and maintenance, at the expense of speed.\n\nWe have decided on placing and cancelling orders. Providing\ninformation about updating order statuses and trading data will be more\ndifficult. Let's imagine that the exchange sent a message about a candle\nchange. How will the information reach consumers? And there will be\nseveral of them, because it is normal for several strategies to work with\none financial instrument, and both strategies should receive the same\ninformation. So, the adapter will have to know about all the strategies that\nneed this information. That doesn\u2019t sound very good. In addition, the\nadapter may not have time to notify all information consumers before the\narrival of a new message from the exchange.\n\nI think there is only one solution that meets our needs to send\nmessages to multiple consumers, even with high throughput: the use of\nmessage brokers. Message brokers were created to solve this problem. The\nsource of information (in our case, the adapter) simply sends a message\nto the message broker, and that\u2019s it. That\u2019s where its work ends. It doesn\u2019t\nknow anything about the number of consumers or whether they exist at\nall. Its task is simply to send the message to the message broker, and this\n\nis very fast operation. Then the broker ensures the transfer of data to all\ninformation consumers. So, the most suitable solution for the system is a\nsolution based on the Kafka message queue system because we need high\nthroughput and Kafka is capable of passing up to millions of messages per\nsecond. Of course, like any queue built not on pushing messages but on\nreading them by consumers, this does not guarantee real-time delivery\n\nof messages, especially if the consumer takes a long time to process the\nmessages. But our architecture is based on distributing the load between\npods, which will provide the ability to scale the system.\n\nNote Kafka is a distributed message broker that works on a\npublisher-subscriber basis. Data in Kafka is represented as key-value\npairs. Kafka guarantees that all messages will be ordered in the exact\norder in which they were received. Kafka stores read messages for a\nperiod of time.\n\nThe next question is, will the adapter itself send messages to the\nqueue? Or will they also go through the exchange gateway? On the one\nhand, it makes sense for them to go through the exchange gateway; this\nway we will hide Kafka and leave working with it in one place. We also\nguarantee that Kafka topics will contain messages of the same type; that is,\nwe will remove the problem when one adapter sends messages to the old\nversion, and another to the new one.\n\nOn the other hand, the exchange gateway will become a bottleneck. If\nwe need to update it or we find an error in it, it will affect information flows\nfrom all adapters.\n\nAs a result, I am more inclined to the second option, where we give the\nadapters some freedom and they themselves will write messages to the\nKafka topic, because I am afraid that in the future there will be problems\nwith the performance of the exchange gateway. Yes, perhaps here I am\n\n3. Itneeds to subscribe to the desired trading\ninformation topic. For each exchange-instrument\npair, a separate topic will be created in Kafka so\nthat strategies can receive information only on the\nfinancial instrument they need.\n\n4. After this, it needs to load historical trading data,\nbecause many indicators require information about\nprevious candles to work correctly. This is especially\nimportant if we have to scale several indicators to\nthe same scale.\n\n5. Only after this can we consider that the strategy has\nbegun to work.\n\nThe strategy operation block must be isolated so that data on the\noperation of one strategy does not affect the operation of another. The\nquestion is how do we do this? At what level should this insulation be\nensured? In software, when a certain instance of a class is conditionally\ncreated for each strategy (which ensures the operation of the strategy,\nwhen will there be a separate pod in Kubernetes for each strategy-\ninstrument pair? Or maybe some kind of hybrid solution, when, according\nto some logic, the number of working strategies on one pod will be set?\n\nOn the one hand, the strategies will work both in weakly volatile\nmarkets and in highly volatile ones. If changes in trading information\noccur rarely, then it may make sense to have one pod ensure the operation\nof several such strategies. On the other hand, such a small unit as a pod\nmay not have time to process frequently received signals from highly\nvolatile markets for several strategies. Therefore, it is important to maintain\na balance.\n\nThere is one more important detail: a weakly volatile market can at\nsome point become highly volatile, and then what? Redistribute strategies\nbetween pods? Provide yourself with periodic downtime at work? I don\u2019t\n\n3. Itneeds to subscribe to the desired trading\ninformation topic. For each exchange-instrument\npair, a separate topic will be created in Kafka so\nthat strategies can receive information only on the\nfinancial instrument they need.\n\n4. After this, it needs to load historical trading data,\nbecause many indicators require information about\nprevious candles to work correctly. This is especially\nimportant if we have to scale several indicators to\nthe same scale.\n\n5. Only after this can we consider that the strategy has\nbegun to work.\n\nThe strategy operation block must be isolated so that data on the\noperation of one strategy does not affect the operation of another. The\nquestion is how do we do this? At what level should this insulation be\nensured? In software, when a certain instance of a class is conditionally\ncreated for each strategy (which ensures the operation of the strategy,\nwhen will there be a separate pod in Kubernetes for each strategy-\ninstrument pair? Or maybe some kind of hybrid solution, when, according\nto some logic, the number of working strategies on one pod will be set?\n\nOn the one hand, the strategies will work both in weakly volatile\nmarkets and in highly volatile ones. If changes in trading information\noccur rarely, then it may make sense to have one pod ensure the operation\nof several such strategies. On the other hand, such a small unit as a pod\nmay not have time to process frequently received signals from highly\nvolatile markets for several strategies. Therefore, it is important to maintain\na balance.\n\nThere is one more important detail: a weakly volatile market can at\nsome point become highly volatile, and then what? Redistribute strategies\nbetween pods? Provide yourself with periodic downtime at work? I don\u2019t\n\nlike this option. I think that in this matter a good solution would be the\nlogic of one pair of strategy/instrument and one pod. I also like this\napproach because we will know for sure that only one strategy works in\nthis instance of the program, and we will certainly avoid trouble in the\ncode associated with the influence of data from one strategy on another.\n\nEnabling and Disabling Strategies\n\nWe have decided that each strategy will have a separate pod. But how will\nthis work? Let's imagine that information came from the strategy search\nsubsystem with a list of strategies with the types of instruments on which\nthey can work. Let's first put them in the table with profitable strategies\ncalled profitable_strategies, where there will be two columns: strategy_id\nand instrument_type. But to launch a strategy, we need an instrument, not\na type of it. It turns out that we need another instrument table where there\nis a type. At the start it will take an unoccupied strategy, so somehow we\nneed to mark that it is already occupied and start working with it.\n\nHow will it understand that the strategy is not busy? It is possible, of\ncourse, for everyone to select a list of strategies from profitable_strategies,\nconnect it with instruments, and then take an unused strategy-instrument\npair to work. But what if we want to change this logic? For example, add an\nis_enabled checkbox for an instrument so that the user can independently\nenable or disable the instrument. Because the program code for\ndetermining working strategies will change, you will have to update it,\nwhich means you will have to restart the pods working with the strategies,\nwhich you would like to avoid. This means the logic for determining\nworking strategies should be placed in a separate application with separate\npods. That is, we will have one application (let\u2019s call it tasks), which will\ndetermine which strategies are working, and another application (let's call\nit worker), which launches these strategies and ensures their operation.\n\nAs a result, I see tables like these in the database, as shown in\nFigure 4-24.\n\noes active strates\n\u2014 | | De\n7 instrument_id\na\nid |\ntype\n\nFigure 4-24. Relationship between database tables\n\nThis is how it will work:\n\n1. The strategy search subsystem notifies the real\ntrading subsystem about the emergence of new\nprofitable strategies. They are written to the\nprofitable_strategies table.\n\n2. Aspecial background job from the tasks application,\nwhich monitors the state of working strategies,\n\u201csees\u201d that a new strategy has appeared that is\nnot in the working_strategies table. It checks all\nrequired is_enabled conditions and makes an entry\nin working strategies with the new strategy and the\ntools it can run on.\n\n3. A free pod, on which a separate application for\nworking worker strategies is running, \u201csees\u201d that an\nentry has appeared in working strategies, which is\nnot in active_strategies, and takes it to work.\n\nIf the opposite situation occurs, when for some reason the user turns\noff a financial instrument or the type of the instrument changes, or maybe\nthe strategy itself is turned off, then the job will delete records from the\nworking_strategies table, and the worker under that works with it will\ndetect this during the next check. This will delete the entry from active_\nstrategies and try to use the next free strategy.\n\nThere is one more important point to consider. There is a probability\nthat a certain worker will suddenly cease to exist. What we get is that in\nactive_strategies there is a record that the strategy-instrument pair is\nbusy, but in fact it does not work. I solved this problem simply. Every time\nthe worker pod checks the working strategies and nothing has changed,\nit updates the value in the timestamp column. If the date in this column\nlags behind the current one by a certain time interval, this will mean that\nthe worker pod has stopped working with the strategy and it can be taken\nby another pod. At the current stage, I see the strategy service shown in\nFigure 4-25.\n\nStrategy Service\n\nWorker App\n\nFigure 4-25. Strategy Service structure\n\nChecking the Type of Financial Instrument\n\nIn the previous chapter, I mentioned the importance of determining the type\nof financial instrument. The type of instrument or chart greatly influences\nthe profitability of the strategy. Often, a profitable strategy becomes\nunprofitable if it works on the wrong instrument. Perhaps the simplest way\nto determine the type of instrument is to use the logic already inherent in the\nsignal. I think using a signal is a great option for these reasons:\n\n\u00ab Often, determining the type of chart is based on\nindicator values. For example, a trend can be\ndetermined by analyzing the values of such indicators\nas Moving Average (MA), Moving Average Convergence\nDivergence (MACD), the Bollinger Band (BB), and\nParabolic SAR. All conditions can be perfectly applied\nto the logic of the signal, and if the functionality is\ninsufficient, it can be easily expanded by adding a\nspecific indicator.\n\n\u00a2 The very purpose of the Signal entity helps us in solving\nthe problem of determining the type of instrument.\nAfter all, the purpose of the signal is to provide us with\na yes/no answer. That is, it helps us figure out whether\nthe financial instrument corresponds to the type or not.\n\n\u00a2 This mechanism will already be implemented in the\nCore library, and we will not need to invent or create\nanything new.\n\nIt turns out that in the table with types of instruments, we will need\nacolumn with a signal, with the help of which the system will be able\nto determine the type of instrument in real time for the real trading\nsubsystem and when loading historical data in the strategy search\nsubsystem.\n\nAs is the case with ensuring the continuous operation of strategies,\nwhen determining the type of instrument, the system will need to analyze\na large flow of trading data. Therefore, it makes sense, as in the case\nof strategy, to allocate its own pod for each instrument, which will be\nsubscribed to the desired Kafka topic from which the trading data comes.\n\nWhy is that and not, for example, a pool of topics that process message\nqueues? Well, to calculate most indicators, it is necessary to take into\naccount candles in the previous n segments. And if the pod does not have\n\nthis information in its memory, then it will have to be taken, for example,\nfrom a database or directly from the exchange, and these requests are\nquite slow.\n\nAs a result, the strategy service has a fourth application: Instruments\nApp. At this stage, I am starting to worry about the number of tasks that the\nstrategy service is responsible for.\n\n\u00ab API for the front end\n\n\u00a2 Background tasks such as managing the working_\nstrategies table\n\n+ Aseparate application for ensuring the strategies work\n\n\u00ab Separate application for determining the type of\nfinancial instruments\n\nIt looks like the strategy service needs to be divided into three\nindependent services, with separate databases and applications.\n\n\u00ab Strategy Service. This service will ensure the operation\nof strategies. It will have two applications: the API\nApp for receiving a command to enable or disable a\nstrategy-instrument pair and of course the Worker App,\nan application that will ensure the strategies work. It\nwill have many pods, one for each strategy-instrument\npair. I really like separating this logic into a separate\nservice. It allows us to truly isolate the operation of\nstrategies from other parts of the application.\n\n\u00ab Instruments Service. This service will determine\nthe types of financial instruments. It will also have\ntwo applications: the API App for information about\nchanges in the instruments and a Worker App to define\ninstrument types. There will be one pod for each\ninstrument.\n\n\u00ab Strategy Manager Service. Judging by the name,\nthis service is a prime candidate for division into\nseveral smaller services because it will be responsible\nfor solving several problems. However, since they\nare small, I don\u2019t see the point of making it too\ncomplicated for now. So, this service will also have\ntwo applications. The API App will provide the front\nend with the necessary methods. This application will\nalso receive information from the search subsystem\nabout the emergence of new strategies. You also need\nan application to manage the working strategies table;\nlet's call it the Tasks App.\n\nAs a result, at the current stage, the real trading subsystem looks like\nFigure 4-26.\n\nExchange Gateways Service\n\nKafka\n\nFigure 4-26. General architectural diagram of the trading system\n\nLet's look at several scenarios for the real trading subsystem.\nHere is how new strategies arrive from the search subsystem:\n\n1. Some service from the strategy search subsystem\nmakes an HTTP request to the API App of the\nStrategy Manager Service, sending it information\nabout profitable strategies and types of instruments.\n\n2. The API App of the Strategy Manager Service\nrecords this information in the database without\ncalculating anything.\n\nThe Tasks App of the Strategy Manager Service\n\u201csees\u201d that new strategies have appeared and sends\nan HTTP request to the API App of the Strategy\nService with a signal about the need to take on new\nstrategies.\n\nThe API App of the Strategy Service writes to the\ndatabase new working strategies.\n\nOne of the free Workers App pods of the Strategy\nService \u201csees\u201d that a new, unactivated strategy has\nappeared and takes it to work.\n\nHere is how the Workers App of the Strategy Service works:\n\n1.\n\nEvery pod of the Workers App of the Strategy Service\nis subscribed to a specific Kafka topic, through\nwhich information about changes in candles for the\nfinancial instrument they need is broadcast. The\nWorkers App responds to these changes, calculates\nsignal values, and monitors the logic of system order\nexecution. At some point, a signal to place an order\nwith a broker may be triggered.\n\nThe Workers App of the Strategy Service sends\nan HTTP request to the API App of the Exchange\nGateway Service to place an order with the broker.\n\nThe API App of the Exchange Gateway Service\nredirects the request to the desired Adapter App of\nthe Exchange Gateway Service. The adapter places\nan order with the broker with which it is integrated.\n\nAfter some time, the Adapter App of the Exchange\nGateway Service \u201clearns\u201d that the status of this order\nhas changed. The way to obtain order statuses can\n\nbe different; it all depends on the broker and its\nAPI. Maybe the adapter will periodically poll the\nbroker about changes in information about orders,\nor maybe the broker provides a webSocket interface\nand itself will notify the adapter about these\nchanges. It doesn\u2019t matter. The important thing is\nthat the adapter somehow learned that the order\nstatus had changed.\n\nThe Adapter App sends messages about changes in\norder status to the desired Kafka topic.\n\nThe Workers App of the Strategy Service is\nsubscribed to the topic from the previous step. This\nmeans it receives this message, and it acts according\nto the logic embedded within it.\n\nThis is how the Instrument Service works:\n\n1.\n\nWhen creating a new financial instrument, the\nfront end makes an HTTP request to the API App of\nthe Strategy Manager Service, passing information\nabout the new instrument to it.\n\nThe API App of the Strategy Manager Service makes\nan HTTP request to the API App of the Instruments\nService with a message about the availability of a\nnew financial instrument.\n\nThe API App of the Instruments Service writes\ninformation to the database.\n\nA free one pod of the Tasks App of the Instruments\nService \u201csees\u201d that a new free tool has appeared,\ntakes it to work, and subscribes to the desired Kafka\ntopic with information about changing candles.\n\n5. Ifthe logic of changing the type of an instrument\nis triggered in the Tasks App of the Instruments\nService, the application writes this information\nto the database and makes an HTTP request to\nthe API App of the Strategy Manager Service with\ninformation about changing the type of the financial\ninstrument.\n\n6. The Strategy Manager Service Tasks App \u201csees\u201d\nthat the type of financial instrument has changed\nand gives the necessary commands to the Strategy\nService to enable or disable strategies.\n\nMaster Data\n\nI have one big question about this scheme. Which service is a source of\nreference information? Here a new signal is created, no matter whether it\ncame from the search subsystem or the user. Where will it be created, and\nhow will other services know that a new signal or strategy has appeared?\nBased on Figure 4-26, the central system for storing this information will\nbe the Strategy Manager Service. It turns out that this service will have\nanother task of storing reference information. I think this is too much.\nTypically, for such purposes, a separate Master Data Service is used, which\nstores general information used, for example, a list of signals, strategies,\ninstruments, exchanges, etc.\n\nAlso, taking into account the fact that we have such a system, it may\nalready make sense to add an API Service to hide information from the\nfront end about which service it turns to for certain data.\n\nWith the advent of the Master Data Service, the real trading subsystem\ndiagram will look like Figure 4-27.\n\nKafka\n\nFigure 4-27. General architectural diagram of the trading system\nwith Master Data Service\n\nFigure 4-27 shows that all requests now go through the API Service,\nwhich decides which microservice to contact. The API Service will have\nonly one application, which is the API App.\n\nThe script for creating reference information, such as a financial\ninstrument, now looks like this:\n\n1. The front end makes an HTTP request to the API\nService to create a new tool.\n\n2. The API Service makes an HTTP request to the\nMaster Data Service.\n\n3. The Master Data Service saves the new financial\ninstrument in the database and sends a message\nto Kafka indicating that a new instrument has\nappeared.\n\n4. Allsubscribers to this event will receive this\nmessage and save the information they need in their\ndatabase.\n\nSummary\n\nThis chapter did not describe everything that is necessary for a well-\ndescribed architectural solution. In it, we only touched on tables in\ndatabases and did not touch upon signatures of API methods at all. Also,\nthe functional diagrams were only superficially described. I plan to go\ndeeper into these issues in future chapters dedicated to the subsystems.\n\nIn this chapter, I did the most important thing, which was to divide\nour system into independent parts, describe the tasks of each of them, and\ndescribe how they would solve them.\n\nThe scheme of the real trading subsystem turned out to be more\ncomplicated than the scheme of the strategy search subsystem, and it\nwas also obvious that the architectures of these subsystems use different\napproaches. This is understandable, because in the strategy search\nsubsystem, it was necessary to pay special attention to the speed of\ncalculating strategies, which means that it is necessary to minimize\n\ninterservice interaction and, as a consequence, the number of services.\nOn the other hand, in the real trading subsystem, it was necessary to pay\nmore attention to independence. I consider the fact that it is possible\nto independently update and scale in this subsystem to be very critical.\nTherefore, it has more independent services.\n\nNow we understand what our system will look like and the parts it will\nconsist of.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 5,
                "chapter_name": "CHAPTER 5",
                "chapter_path": "./screenshots-images-2/chapter_5",
                "sections": [
                    {
                        "section_id": 5.1,
                        "section_name": "Technology Stack\nand Libraries",
                        "section_path": "./screenshots-images-2/chapter_5/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_5/section_1/edb2e31d-a5ab-4de6-b0c1-e7c6dde21a32.png",
                            "./screenshots-images-2/chapter_5/section_1/29577c20-9ac4-421b-8fa8-30bf7519f9e7.png",
                            "./screenshots-images-2/chapter_5/section_1/4ac1138b-7afa-4780-82f9-bd2bc62c527f.png",
                            "./screenshots-images-2/chapter_5/section_1/d2070217-4063-4616-97c4-4680303a9b6e.png",
                            "./screenshots-images-2/chapter_5/section_1/5e34289f-034b-4654-a4b3-978242d6e5d5.png",
                            "./screenshots-images-2/chapter_5/section_1/1bcb4f2b-be69-416a-9bb6-67d52e8386ea.png",
                            "./screenshots-images-2/chapter_5/section_1/7a7f3435-0c87-407b-b9b1-9f215e2962e5.png",
                            "./screenshots-images-2/chapter_5/section_1/af661d6b-b922-4511-bfc4-fa47e664347f.png",
                            "./screenshots-images-2/chapter_5/section_1/14a55fca-10d0-469d-9601-8e91a4961700.png",
                            "./screenshots-images-2/chapter_5/section_1/edc3847c-39b2-4279-8762-f850dd5367f2.png",
                            "./screenshots-images-2/chapter_5/section_1/c7d2025d-0fb0-423d-82ae-8a8997a7fddc.png",
                            "./screenshots-images-2/chapter_5/section_1/7c7acc36-b67d-4cfe-bab4-f203f74ea9bc.png",
                            "./screenshots-images-2/chapter_5/section_1/bee50489-a826-4075-9b75-7916d625111f.png",
                            "./screenshots-images-2/chapter_5/section_1/0f6f1754-3303-4290-b57d-548e51d3930a.png",
                            "./screenshots-images-2/chapter_5/section_1/59921c58-1b7c-4435-9230-bcbfe0b78349.png",
                            "./screenshots-images-2/chapter_5/section_1/8a759e30-5655-4310-9bf9-6da86949d312.png",
                            "./screenshots-images-2/chapter_5/section_1/4094545e-0852-459c-b7a4-0e91dfb1b97c.png",
                            "./screenshots-images-2/chapter_5/section_1/5fc19631-e9a6-4268-80a7-b980ca02c643.png",
                            "./screenshots-images-2/chapter_5/section_1/a2f2c9d7-e1c4-4442-947a-19c8150a2efc.png",
                            "./screenshots-images-2/chapter_5/section_1/bed7fad9-6b9f-4d37-92bf-ec7ef14d36bd.png",
                            "./screenshots-images-2/chapter_5/section_1/1b604123-ec43-4160-9a9b-7fdbed3b688a.png",
                            "./screenshots-images-2/chapter_5/section_1/eb981471-db4a-4914-a056-a582d6861819.png",
                            "./screenshots-images-2/chapter_5/section_1/7dfbc8d4-7866-40b6-96cb-a55080595a7d.png",
                            "./screenshots-images-2/chapter_5/section_1/47a83318-4c37-4802-8803-a6a1811ed88d.png",
                            "./screenshots-images-2/chapter_5/section_1/ee0969c4-e982-4e55-9784-58d95bb12688.png",
                            "./screenshots-images-2/chapter_5/section_1/1f9eb461-f5ea-47fb-becd-00eba6b8e5e5.png",
                            "./screenshots-images-2/chapter_5/section_1/35ec2146-de55-4554-96e5-2994068abdb0.png",
                            "./screenshots-images-2/chapter_5/section_1/ca490f7e-35c4-4c88-94a3-f722239bbdaa.png",
                            "./screenshots-images-2/chapter_5/section_1/c51a19e5-9dd6-46f0-b097-3482566a8b56.png",
                            "./screenshots-images-2/chapter_5/section_1/148c5ae5-2f86-4c10-bcae-5e2c91139e00.png",
                            "./screenshots-images-2/chapter_5/section_1/d6d29240-62a8-4856-8751-a1763d1c7cac.png",
                            "./screenshots-images-2/chapter_5/section_1/c7693bfe-e0fe-458f-b84e-23fa6d0c7eb3.png",
                            "./screenshots-images-2/chapter_5/section_1/8d4dfaaf-5cf2-40bd-b848-b38e7771a775.png",
                            "./screenshots-images-2/chapter_5/section_1/0eebc8a8-ab1b-4642-95ad-7f696e1ed09a.png",
                            "./screenshots-images-2/chapter_5/section_1/172a9dd5-9169-419a-9fde-19b9c16afe46.png",
                            "./screenshots-images-2/chapter_5/section_1/11ec8751-a906-4c41-b217-d2ca0f3de361.png",
                            "./screenshots-images-2/chapter_5/section_1/fc4131ce-fdda-4d48-8cf3-6b5a605f7bbb.png",
                            "./screenshots-images-2/chapter_5/section_1/c5445709-070a-4094-8de5-2b59f3e66122.png",
                            "./screenshots-images-2/chapter_5/section_1/6b6a7480-8e6f-4032-a64c-1261f0e0853a.png",
                            "./screenshots-images-2/chapter_5/section_1/59719cdf-f33d-4a22-a02d-6f1c3e6e792c.png",
                            "./screenshots-images-2/chapter_5/section_1/d11b7d63-bf39-4859-a5c5-57dc91210331.png",
                            "./screenshots-images-2/chapter_5/section_1/f27135f5-a91c-4c92-86bc-c0f4e9da3753.png",
                            "./screenshots-images-2/chapter_5/section_1/1f441a05-aab0-4c0f-a7bb-80223ac9be94.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In previous chapters, we discussed the architectural solution of our system,\nlearned what services it would consist of, and saw how they are connected\nto each other. In this chapter, we will discuss exactly how the services will be\ncreated, what technology stack we will use, what architecture we will use to\nbuild our services, and what logic we will use to create our classes and use\nthem in the future. We will also discuss modern libraries for solving common\nproblems, such as working with databases. Also in this chapter I will show\nhow to implement the libraries that will be used in both subsystems, such as\nthe state machine and the operation of background jobs.\n\nNote that in this book we will pay more attention to the back end,\nand I will talk about the front end only in passing. This is because the\nfront end of our system will not be complicated, so you can choose any\nframework to implement it. We will have no complex states or websocket\nconnections. In fact, when creating the first version of my system, I did\nnot create a front end for it at all. All I needed was a database tool such as\npgAdmin or DataGrip to view and change my data, as well as Postman to\nrun queries. Only much later, when the system began to generate income\nand trusted people joined me, did I implement the front end. Then, to\nbuild the front end, I used React, which I was familiar with, with a free\nlibrary of components so as not to spend too much time on the part of the\napplication that was not essential for me.\n\nChoosing a Framework\n\nLet\u2019s start with choosing a language and framework. I think it makes sense\nto be pragmatic in this matter. This means I don\u2019t want to dive headfirst\ninto learning a new technology and language just because it has some\nadvantages over the languages I already know. My goal is not to learn a\nnew technology but to build a trading system. For example, the leading\nlanguage for developing serious trading robots right now is C++. But I\ndon\u2019t know this well enough, and it\u2019s not as convenient as the C# I\u2019m used\nto. Perhaps in the future, when I reach the C# ceiling in data processing\nspeed, I will transfer some services to C++, but this definitely should not\nbe done before the system is launched. It doesn\u2019t matter what language\nyou write your first system in; the main thing is that you are comfortable\nand that your framework has reliable libraries for building an API, working\nwith a database, and working with a distributed event streaming platform\nlike Kafka.\n\nAt the time of writing this book, my stack, for example, included two\npopular frameworks: .NET.NET and NestJs. I wrote highly loaded systems\non both, and both worked perfectly. But to build this system, I chose .NET.\nNET because it is much more convenient to work with arrays than in\nTypeScript. Also, .NET.NET works better with asynchronous code, unlike\nTypeScript, and is more productive. Also in .NET.NET it is much more\nconvenient and easier to write autotests. And I will repeat once again that\nwhen choosing a framework, I advise you to be pragmatic and inclined to\nchoose a framework that is familiar to you.\n\nApplication Architecture\n\nProbably the first questions that any developer who creates a service from\nscratch asks is about naming and arranging your application projects.\nHow many should there be? In what directories should they be located?\n\nHow should classes be structured, and what should each be responsible\nfor? If you look for the answer to these questions on the Internet, such\ndesignations as service layer, clean and onion architecture, DDD, CQRS,\nrepositories, and much more pop up. Let\u2019s understand what types of\narchitecture there are and what each of them has to offer. I will show how\ndifferent approaches were created and evolved.\n\nSpaghetti Code\n\nLet's start with the very first approach to writing an application that is\nfamiliar to all developers: spaghetti code.\nThe following are distinctive features of this approach:\n\n\u00a2 Lack of architecture. Each developer writes code as\nthey see fit.\n\n\u00a2 Terrible connection. Everything is connected to\neverything. If someone changes something in one part\nof the system, then something may break in another\npart of it.\n\n\u00ab Development time. It takes a very long time for new\ndevelopers to immerse themselves in the system code,\nbecause generally accepted patterns are not used.\n\nWhen developers just started creating the first applications, most of\nthe patterns had not yet been created and fixed. Therefore, programmers\ncoped as best they could. They simply had no choice, because the\ndeveloper community had not yet agreed on how applications would be\nbuilt, and more modern approaches had not been developed.\n\nBut despite that spaghetti code, to put it mildly, is not suitable for\nwriting applications in the modern world, it still continues to be used, and\nperhaps all of us have written and are still writing applications based on\nthis approach. Spaghetti code is great for quickly writing code that will live\nin a matter of hours, or even minutes.\n\nClean Architecture\n\nObviously, developers quickly realized that spaghetti code is not the best\narchitecture for applications. Figure 5-1 shows what it looks like when we\ndifferentiate even slightly between levels in the code.\n\nae\nBusiness Logic\nee\n\nData Access\n\nFigure 5-1. Layers\n\nThe code was still like spaghetti, but that spaghetti was strictly\nlimited to the boundaries of its layer. The UI layer was responsible for\nrepresentations, for example the data transfer objects (DTOs) for the\nAPI. The business logic layer in which the domain model, a certain layout\nof the real world, and all the logic associated with it are concentrated.\nThe data access layer contains the logic for working with a database, for\nexample. The code has definitely improved. Controllers and repositories\nappeared, which made the code much easier to understand.\n\nBut after the SOLID principles were formed, developers realized\nthat the abstract domain code from the business logic layer depends on\nthe implementation of the data access layer, which greatly violates these\nprinciples. Therefore, it was decided to expand the data access layer and\nmake the business logic completely independent of the data access layer.\nThe result was the so-called clean architecture, which is demonstrated in\nFigure 5-2.\n\nFigure 5-2. Clean architecture\n\nI will briefly explain the SOLID principles here:\n\nS - Single responsibility. Your program unit should\nhave only one responsibility. By unit I mean not only\na class but also a library, part of your program or\nservice.\n\nO - Open/closed principle. Software objects must\nbe open for extension and closed for modification.\n\nL- Liskov substitution principle. The inheriting\nclass should complement, not replace, the base\nclass. In practice, this means that functions that\nuse a base type should be able to use its subtypes\nwithout knowing it.\n\nI - Interface segregation principle. Interfaces that\nare too thick should be split into smaller ones so that\nclients of small interfaces are aware of the methods\nthey need to do their work.\n\nD - Dependency inversion principle. Top-\nlevel modules should not depend on lower-level\nmodules.\n\nIn a clean architecture, the domain layer, the former business logic\nlayer, is placed at the center and accessed through services. Perhaps at the\nmoment this is the most popular approach to building applications. This\napproach is justified until you start writing more complex applications,\nwhen you have many services. As a result, the map of their interaction\nbecomes precisely the spaghetti they tried to get rid of. I know projects\nwhere you open a controller or service and there are dozens of imported\nclasses and dependencies. I understand that such multitasking services\nneed to be refactored and separated, but this did not solve the problem of\nstrong connectivity of services.\n\nThat\u2019s when experts came onto the scene and proposed a different\napproach to building architecture. They showed that it might make sense\nto build applications based not on layers but on use cases. For this they\nsuggested using the mediator pattern, namely, creating commands with\nhandlers, as shown in Figure 5-3.\n\n= tener | \u2014\n\nFigure 5-3. Command handler\n\nNote A few words about the mediator pattern. This pattern belongs\nto a group of behavioral patterns. It helps reduce the interconnection\nof objects by moving these relationships into a separate mediator\nclass. The mediator pattern causes classes to communicate not\ndirectly with each other but through an intermediary. Regarding\ncommands, this means you will not issue commands to a specific\nhandler or service but to an intermediary, who will decide who will\nprocess this command.\n\n\nIn this approach, what is inside the handler becomes unimportant.\nWhether it\u2019s working with the domain model or maybe some legacy code\nthat you isolate, it doesn\u2019t matter. The important thing is that now in your\ncode you don\u2019t think about which service to place this or that function\nin or which layer is responsible for providing this or that functionality.\nEverything has become easier. You have a specific command and its\nhandler. See Figure 5-4.\n\nDomain Model\nCommand Read Model Oto\n\nDapper\nLegacy Code\nApi Client\n\nFigure 5-4. Possible functionality of handlers\n\nWhether to use a service layer approach or use commands depends on\nthe developer and their preferences. There is no universal solution. I prefer\nto use a mediator and commands. Then it's easier for me to divide the\napplication into independent parts and understand how it all works.\n\nDomain-Driven Design vs. Anemic Model\n\nAnother question that periodically arises when creating systems is what\ntype of model to use.\n\nDomain-driven design (DDD) tells us to build a rich domain layer with\na thin service layer when data structure and behavior are combined. In\nfact, this means that the classes that implement your domain model will be\nlarge, and they will contain most of the logic responsible for the behavior.\n\nIn the anemic model, everything is different. Data structure and\nbehavior are divided between classes such as entity and service.\n\nSome people think that the anemic model is an anti-pattern. And if a\ndeveloper uses this approach, it means they have a poor understanding\nof the subject area and, because of this, are unable to competently build a\ndomain model.\n\nBut if you look at many projects on GitHub, you will see that most\nof them are built on an anemic model. Why? It\u2019s because building an\napplication based on DDD is not just expensive, but very expensive.\nWhen designing a system with a rich domain model, it is necessary not\nonly that the developers have excellent knowledge of the domain but that\nthe domain itself is well-established and consistent. Unfortunately, this\nis often not the case, especially when you are writing a completely new\napplication.\n\nIf we take our system as an example, I\u2019m not sure that I identified the\nentities correctly, which means I\u2019m not at all sure that my rich domain\nmodel will be correct. Therefore, I propose to take the evolutionary path.\nIn other words, first build applications using the anemic model, and then\ngradually migrate the established code to the domain model.\n\nObject Relational Mapper\n\nLet's talk about what object relational mapper (ORM) we will use. What\nis an ORM? It is a library that helps us work with the database. There are\nseveral popular ORMs in .NET, and the most commonly used one is, of\ncourse, the Entity Framework (EF). But I propose we consider another\npopular ORM, or rather a mini-ORM: Dapper. And there is one reason for\nthis, namely, speed.\n\nIf you look at the speed reports on the official Dapper page (https: //\ngithub.com/DapperLib/Dapper), Dapper is the most productive\nORM. This is understandable. It simply does not have a lot of functionality\nthat EF has. There is practically nothing in it except mapping.\n\nIt turns out that I will have to independently implement some of the\nfunctionality available in EF. But am I willing to sacrifice my development\ntime for the sake of productivity? Of course! We built the entire system,\ntrying to make it the fastest and most productive.\n\nSince most developers use EF, I would like to pay a little attention to\nthe functionality of Dapper here so that later in the book we can focus on\nmore interesting things. I will do this using the example of creating one of\nour entities: ExchangeOrder.\n\nHow to Use Dapper\n\nFirst, you need to create the entity classes ExchangeOrder and\nExchangeDeal. ExchangeDeal is not an entity in the general sense of the\nword, but we agreed that first we will make the system cheaper, which\nmeans we use an anemic model. I could put the models that we work\nwith in the business logic layer into separate classes and make my own\nclasses for the ORM, but then I would have to write a lot of code to map\nthese classes into each other, and this is a long and not very interesting\ntask. Perhaps when the system becomes more complex, it will be possible\nto switch to rich models, but now we are not doing this. Therefore,\nExchangeDeal is an entity and also a class that maps a database table.\nListing 5-1 I shows what my classes look like.\n\nListing 5-1. Implementation of Entity Classes\n\n[Table(\"\\\"ExchangeOrders\\\"\") ]\n\npublic class ExchangeOrder\n\n{\npublic int id { get; set; }\npublic int ExchangelId { get; set; }\npublic int InstrumentId { get; set; }\npublic decimal Amount { get; set; }\n\npublic IEnumerable<ExchangeDeal> Deals;\n\n}\n\n[Table(\"\\\"ExchangeDeals\\\"\") ]\npublic class ExchangeDeal\n\n{\npublic int ExchangeOrderId { get; set; }\npublic decimal Amount { get; set; }\npublic decimal Price { get; set; }\n\n}\n\nI use PostgreSq| in my projects because it is free, well-supported,\npopular, and used in many projects. I will also use this to build a\ntrading system.\n\nPay attention to the Table attributes. They use double quotes to\nindicate the table name. The fact is that in PostgreSql, if the names of\ncolumns or tables are not in snake_case, then in queries they must be\nframed in double quotes. I could follow the PostgreSql conversion and\nname columns and tables in snake_case, but I won\u2019t, because according\nto the C# conversion, public fields and classes should be named in\nPascalCase.\n\nAs I said earlier, ExchangeDeal is not an entity, because deals cannot\nexist without orders, so ExchangeDeal does not have an id column or\nproperty.\n\nAfter we have written our entities, we need to implement a repository.\nBut first I would like to implement a special class that is responsible for\nworking with connections to the database. In EF, working with connections\nis hidden from us. Many developers don\u2019t even think about the fact\nthat their number of connections and how exactly they are created and\ndestroyed. Since Dapper is not such a high-level library, we will have\nto create connections ourselves. Listing 5-2 presents a rudimentary\nimplementation of the class that is responsible for working with them.\n\nListing 5-2. DbConnector Implementation\n\npublic class DbConnector\n{\nprivate NpgsqlConnection dbConnection =>\nnew (Environment\n-GetEnvironmentVariable(\"POSTGRES CONNECTION_\nSTRING\"));\n\npublic async Task<T> PerformDbActionAsync<T>(\nFunc<DbConnection,\nTask<T>> dbAction)\n\ntry\n\n{\nawait using var connection = dbConnection;\nawait connection.OpenAsync();\n\nawait using var dbTransaction =\nawait connection. BeginTransactionAsync();\ntry\n{\nT actionResult = await dbAction.\nInvoke(connection) ;\nawait dbTransaction.CommitAsync();\nreturn actionResult;\n\n}\n\ncatch (Exception)\n\n{\nawait dbTransaction.RollbackAsync();\nthrow;\n\n}\n\nfinally\n{\n\ndbConnection.Dispose();\n\nSeveral things are notable about Listing 5-2. First, for each action with\nthe database, its own connection will be created. Of course, this logic can\nbe implemented in a more complex way, but at this stage I believe that\nthis is enough. The second is that the actions will occur in one isolated\ntransaction, we will need this when saving entities that use several tables\nin the database.\n\nNowit\u2019s time to implement the repository. Listing 5-3 shows the\ninterface of this repository, which has the minimum required functionality.\n\nListing 5-3. TExchangeOrderRepository Interface\n\npublic interface IExchangeOrderRepository\n\n{\nTask<int> InsertOrderAsync(ExchangeOrder exchangeOrder) ;\nTask InsertExchangeDealAsync(ExchangeDeal exchangeDeal) ;\nTask<ExchangeOrder> GetOrderAsync(int id);\n\n}\n\nOf course, all methods are asynchronous. Also note that although\ndeals are part of the order, the method for saving it is separate. This is done\nbecause deals for orders will arrive separately, which means they can be\nsaved separately from the order.\n\nThe implementation of the order creation method is very simple,\nthanks to the Dapper.Contrib package. In a pure Dapper package, we\nwould have to write the Insert SQL code ourselves, but it\u2019s enough to use\nthe InsertAsync function.\n\nListing 5-4. InsertOrderAsync Function\n\npublic Task<int> InsertOrderAsync(ExchangeOrder exchangeOrder)\n{\nreturn _dbConnector.PerformDbActionAsync(connection =>\nconnection. InsertAsync(exchangeOrder) ) ;\n\n}\n\nThe code for receiving an order is interesting. In it we need to execute\ntwo queries to the database. They queries receive orders and deal with\ndata. See Listing 5-5.\n\nListing 5-5. GetOrderAsync Function\n\npublic Task<ExchangeOrder> GetOrderAsync(int id)\n{\nstring sqlOrders = \"select * from \\\"ExchangeOrders\\\"\nwhere id = @id\";\nstring sqlDeals = \"select * from \\\"ExchangeDeals\\\"\nwhere \\\"ExchangeOrderId\\\" = @id\";\n\nreturn _dbConnector.PerformDbActionAsync(async\nconnection =>\n{\nvar multipleResult = await connection.QueryMultiple\nAsync($\"{sqlOrders};{sqlDeals}\", new {id});\nExchangeOrder exchangeOrder = await multipleResult.\nReadFirstOrDefaultAsync<ExchangeOrder>() ;\nif (exchangeOrder == null)\nreturn null;\n\nIEnumerable<ExchangeDeal> deals = await\nmultipleResult .ReadAsync<ExchangeDeal>() ;\nexchangeOrder.Deals = deals;\n\nreturn exchangeOrder;\n\n})5\n\nMigrations\n\nAnother point worth covering when working with Dapper is migrations.\nOne of the most common libraries for these purposes is FluentMigrator.\nIt\u2019s very easy to work with and well-documented. Perhaps its biggest\ninconvenience is the need to write migrations yourself, but I understood\nwhat I was getting into when I agreed to use a micro ORM. Listing 5-6\nshows an example migration for our two tables.\n\nListing 5-6. Migration\n\n[Migration(202312171002) ]\npublic class Migration_202312171002: Migration\n{\n\npublic override void Up()\n\n{\n\nCreate. Table(\"ExchangeOrders\")\n-WithColumn(\"id\").AsInt32().PrimaryKey().Identity()\n-WithColumn(\"\u201cExchangeId\") .AsInt32() .NotNullable()\n\u00abWithColumn(\"InstrumentId\") .AsInt32().NotNullable()\n-WithColumn(\"Amount\").AsDecimal(20, 10).\nNotNullable();\n\nCreate. Table(\"ExchangeDeals\")\n-WithColumn(\"ExchangeOrderId\") .AsInt32().\nNotNullable()\n\u00abWithColumn(\"Amount\").AsDecimal(20, 10).\nNotNullable()\n\n-WithColumn(\"Price\").AsDecimal(20, 10).\n\nNotNullable();\n}\npublic override void Down()\n{\nDelete. Table(\"ExchangeOrders\") ;\nDelete. Table(\"ExchangeDeals\") ;\n}\n\nListing 5-6 demonstrates the implementation of the migration class,\nwhich is used to create tables in the database. In this I create two tables,\nTable(\u201cExchangeOrders\u201d ) and Table(\u201cExchangeDeals\u201d), and then create\ncolumns of the types I need in them.\n\nIhave covered the minimum required to start working with Dapper. If\nyou want to dive deeper into it, there is a lot of useful information on the\nInternet.\n\nFinite State Machine\n\nIn the previous chapter, we talked about what a finite state machine is and\nbriefly discussed the principle of its operation. In this chapter, let's dive\ndeeper and talk about its implementation.\n\nIhave seen all sorts of options for the implementation of finite state\nmachines. On GitHub you can find many options for ready-made solutions\nbuilt on various technologies. Let's look at one of the simplest ones, which\nwe used in one of the online stores where I once worked.\n\nBefore we begin, let me first remind you of the main points related\nto the finite state machine. A finite state machine is a way for an entity to\nmove through a process.\n\nHere are the basic principles:\n\u00ab Anentity can be in only one state at any given time.\n\u00ab The number of these states is finite.\n\n\u00a2 There are precise rules for transitions between states.\n\nPrinciple\n\nThe center of the state machine that we will implement is ProcessMap. There\n\ncan be only ProcessMap for the entire application, and it contains entity\n\ntransition rules between process map nodes. All entities move along it from\n\ntop to bottom. The system also provides events that \u201crip\u201d an entity from the\n\ncurrent node, and it immediately \u201cfalls\u201d onto the node that reacts to the event.\nThere are five types of nodes:\n\n\u00a2 Act. This node performs some action. For example,\nsend a letter to a user or calculate something and write\nthe result to a database.\n\n\u00a2 Waiting. Such nodes are necessary to wait for some\nevent that will \u201crip\u201d the entity from this node. When\ncreating a node of this type, be sure to specify a\ntimeout. If the entity has waited on this node for the\nspecified time, then it will move to the next node.\n\n\u00a2 Terminal node. It means that the entity must be\nremoved from the process queue and stop processing.\n\n\u00a2 Trigger. The node on which the entity will fall when\nan event with the type specified in the node settings\n\narrives.\n\n\u00a2 Description. Nothing happens in nodes of this type.\nBut they are necessary as reference points for moving\nfrom other nodes.\n\nLet me give an example of how this works, using the example of\nprocessing theory. We'll take a small part of the process, because now my\ngoal is to explain to you how it works. Figure 5-5 shows part of the theory\nprocessing flow in the second step.\n\n\u2014__\n\nCreate SubTheory\n\nEvent: SubTheory\ncompleted\n\nCheck exit condition\nCheck Second Quality\nCondition\n\nThird Step\n\nFigure 5-5. Second step of theory flow\n\nLet's transfer this process to the process map of our state machine, as\nshown in Table 5-1.\n\nTable 5-1. List of Nodes\n\nN Node Name Node Type Params\n\n1 Set status \u2018Second step\u2019 Act Status Id\n\n2 Create SubTheory Act\n\n3 Wait Waiting 1 day\n\n4 Stop and report\n\n5 SubTheory completed event Trigger Event id\n\n6 Check exit condition Act Node id = 2\n7\n\n8 Finish Terminal\n\nNode 1. Set status \u2018Second step\u2019 This is a node of type Act, which\nsets the status of a theory somewhere in the database. I have specified the\nstatus ID that we want to set in the parameters of this node. This will help\nus write code to set the status only once and use Act with this type when\nwe go to set the status Worthless, for example. That's why I wrote down the\nStatus Id in the Params column of Table 5-1.\n\nNode 2. Create SubTheory. At this step, some kind of SubTheory is\ngenerated and launched. There is probably nothing more to say about\nthis step. It is unique and cannot be reused in any way, so the parameters\nare empty.\n\nNode 3. Wait. Our theory will be at this step, the period specified in\nthe parameter is 1 day. And if during this time the \u201cSubTheory completed\u201d\nevent does not occur, then the entity will move on to Node 4.\n\nNode 4. Stop and report. Obviously, if a subtheory has not been\nconsidered within a reasonable time, then something needs to be done\nwith it. Alternatively, stay on this node and periodically write in the logs\nthat something went wrong, in the hope that the user will notice it and\nsomehow solve the situation.\n\nNode 5. SubTheory completed event. This is the trigger node; it is\nwhere the theory will \u201cfall\u201d if the \u201cSubTheory completed\u201d event arrives. Of\ncourse, in the parameters of this node, you must specify the identifier of\nthe event to which this trigger will react.\n\nNode 6. Check exit condition. This is an act, but not a simple one.\n\nIt specifies the identifier of the node to which the theory will move if the\ncheck of the condition from the \u201cCheck exit condition\u201d is unsuccessful.\n\nThis is how we implemented the loop. If the \u201cCheck exit condition\u201d\nfails, then the theory returns to node 2; otherwise, it moves to the node\nlocated below, that is, 7.\n\nHosted Service\n\nSo, the basic principle is more or less clear. Let's implement such a straight\nmachine using .NET. First, our application must be of the ASP.NET type\nbecause we must not forget that our service will be run as a microservice,\nwhich means that the orchestrator must periodically check that our\napplication continues to work. For this purpose, Kubernetes uses a liveness\nprobe. That is, Kubernetes periodically executes an HTTP request to a\nspecial endpoint, waiting for a successful response.\n\nSo we have an ASP.NET.NET application. To run background tasks\nbased on it, Microsoft provided us with a hosted services mechanism.\nAdding a new service is very simple; it is done with just one line of code.\n\nservices .AddHostedService<ProcessBotHostedService>();\n\nBut is this reasonable? Should we tie our bot process (a task that moves\nentities along the ProcessMap) to one specific application? Yes, when\nyou can make it as a library and use it in many applications. After all, ina\nbot\u2019s process, it doesn\u2019t matter at all what kind of entity moves through the\nprocess. The main thing is that it has a unique identifier. But how do we\nsolve the problem that Act nodes will contain unique, application-specific\nlogic? Interfaces will help us with this. The process bot library will provide\n\nthe IProcessingAct interface, and the implementation of each such action\nwill be located in the application that uses the library. Of course, when\ninitializing the process bot, we also need a factory that will create the Act\nnode we need based on its identifier.\n\nTo register the processing bot to the application, we will create an\nextension for IServiceCollection, as shown in Listing 5-7.\n\nListing 5-7. IServiceCollection\n\npublic static IServiceCollection AddProcessBot(\nthis IServiceCollection services,\nAction<ProcessBotOptions> setupAction,\nType actFactoryType,\nparams Assembly[] actAssemblies)\n\nservices.AddOptions() ;\nservices .Configure(setupAction) ;\n\nservices. AddSingleton<ProcessBot>();\n\nservices .AddSingleton(typeof(IProcessActFactory) ,\nactFactoryType) ;\n\nAddTasksImplementations(services, actAssemblies) ;\nservices .AddHostedService<ProcessBotHostedService>();\n\nreturn services;\n\n}\n\nYou have no idea how much I love .NET! Listing 5-7 embodies a lot of\nwhat I love about it. First, we implemented the extension, and we did it\nsimply and beautifully. Pay attention to the first parameter of the function\nthis IServiceCollection services; it will contain an instance of the\nclass whose function we are calling. Thanks to the extension, it is now very\neasy to register the process bot.\n\nservices .AddProcessBot().\n\nWhat's even more interesting is that in the next\nAction<ProcessBotOptions> setupAction parameter, the user of\nour library will have to pass a procedure that will build an instance of\nthe options class, which will be available for connection in any class\nconstructor used in the IServiceCollection instance. For now, only the\ndatabase connection string will be stored in the options.\n\nThe next parameter type, actFactoryType, passes the type of the\nclass that implements the IProcessActFactory interface. The idea is that\nthe process bot should not depend on the specific implementation of the\nact creation factory. The interface is enough for this.\n\nAnd the very last parameter is params Assembly[] actAssemblies, in\nwhich the user must pass assemblies that contain all implementations of\nthe IProcessAct interface. And again, in the process bot we do not need\nthe actual implementation of the acts. It is enough to know that they have\nall the methods we need. We will just add all these implementations to the\ncollection of services for their easy accessibility. | understand that now\nyou may not understand much, but wait a little, and everything will fall\ninto place.\n\nPay attention to the line services .AddHostedService<Proces\nsBotHostedService>() ; in fact, it will be the exact launcher of the\nprocess bot. As required by the AddHostedService function, our\nProcessBotHostedService class must be an implementation of the\nIHostedService interface, which has two methods: StartAsync and\nStopAsync. And itis in StartAsync that I will make an infinite loop, in\nwhich I will periodically launch the entities handler. Listing 5-8 shows how\nIimplemented this.\n\nListing 5-8. StartAsync Function\n\npublic async Task StartAsync(CancellationToken\ncancellationToken)\n{\n_logger.LogInformation(\"ProcessBot start\");\n_stop = false;\n\nStopwatch stopwatch = Stopwatch. StartNew();\nwhile (!_stop && !cancellationToken.\nIsCancellationRequested)\n\n{\ntry\n{\nstopwatch.Restart();\nawait _processBot.RunAsync(cancellationToken) ;\nstopwatch. Stop();\nvar sleepTime = 1000 - (int)stopwatch.\nElapsedMilliseconds;\nif (sleepTime > 0 && ! stop)\nawait Task.Delay(sleepTime,\ncancellationToken) ;\n}\ncatch (Exception e)\n{\n_logger.LogError(e, \u201cunknown error\");\nawait Task.Delay(5000, cancellationToken) ;\n}\n}\n\n_logger.LogInformation(\"ProcessBot stop\");\n\nThere are a few notable things about this code. The first is the\ncondition for stopping the while loop (!_stop && !cancellationToken.\nIsCancellationRequested). Of course, here I use the cancel lationToken\npassed to the function, as well as the private variable _stop, which I set to\nfalse when calling the StopAsync method.\n\nSecond, I use stopwatch. I need it so that the bot does not start too\noften. Imagine that there will be no entity in the queue for processing.\nThen the bot can work in tens of milliseconds, and if you do not set a delay,\nit will start immediately after processing is completed. Third, I also set a\ndelay in the catch section; it is necessary so that the bot does not try to\nstart working immediately after an exception occurs.\n\nOf course, all these magic numbers could be included in the options,\nor it would be better to abandon the infinite loop altogether and use\nsome more interesting external mechanism, but I remind you that this is\none of the simplest implementations that will withstand relatively heavy\nloads. And this is just an example; of course you can create your own\nimplementation or use one of the existing ones.\n\nSo, we started running our bot periodically. But what will it do? Of\ncourse, process the processing queue. In one of the previous chapters we\ndiscussed this mechanism and even started designing database tables\nfor it. Let me update this information. We discussed that to support\nthe processing queue, two tables would be created in the database:\nProcessingQueue and ActiveQueue, as shown in Figure 5-6.\n\n|\n\nEntityid Entityid\nNodeld [ Timestamp\nProcessingTime\nTimestamp\n\nFigure 5-6. Database table schema\n\nawait _processingQueueRepository.UnlockEntitiesAsync\n(queueElements.ConvertAll(e => e.EntityId));\n}\n\nWhat's interesting about this code is that I decided to process not one\nentity per robot pass but several at once. This is because when getting\na process map, getting and blocking an entity are not free procedures. I\nexpect each step of the process map to be a lightweight operation that is\ncompleted quickly, so I don\u2019t see the point in spending so many resources\nto perform a small step on just one entity.\n\nAlso pay attention to the GetAndLockEntitiesAsync function. Yes,\nit violates the SOLID principle, because the logic about which entities\ncan be taken into work has moved from the business logic layer to the\nrepository layer. How could one get out of this situation? Get a separate\ndatabase transaction, call the ActiveQueue table locking method, get the\nnecessary data from the repositories, write the necessary data using the\nrepository methods, and commit the transaction. I understand this, but\nI won't do this for now, because I will have to create classes for creating\ntransactions and split IProcessingQueueRepository into two repositories\nIProcessingQueueRepository and IActiveQueueRepository, and all\nthis for the sake of one place in the code. Am I right? I don\u2019t know. But we\nlive in the real world where it is possible to move away from patterns if\nyour code is ultimately clearer. After all, in the end, patterns were created\nprecisely for a simpler understanding of the code.\n\nNext in this code, I want to pay attention to the ProcessMap class,\nwhich will be responsible for such functionality as whether we move\nfurther along the process map. If we had a rich model, then ProcessMap\nwould definitely be an entity, but now it is just a class that is close to\nservices. Perhaps we could even rename it ProcessMapService.\n\nListing 5-10 shows an implementation of the HandleEntitiesAsync\nfunction.\n\nawait _processingQueueRepository.UnlockEntitiesAsync\n(queueElements.ConvertAll(e => e.EntityId));\n}\n\nWhat's interesting about this code is that I decided to process not one\nentity per robot pass but several at once. This is because when getting\na process map, getting and blocking an entity are not free procedures. I\nexpect each step of the process map to be a lightweight operation that is\ncompleted quickly, so I don\u2019t see the point in spending so many resources\nto perform a small step on just one entity.\n\nAlso pay attention to the GetAndLockEntitiesAsync function. Yes,\nit violates the SOLID principle, because the logic about which entities\ncan be taken into work has moved from the business logic layer to the\nrepository layer. How could one get out of this situation? Get a separate\ndatabase transaction, call the ActiveQueue table locking method, get the\nnecessary data from the repositories, write the necessary data using the\nrepository methods, and commit the transaction. I understand this, but\nI won't do this for now, because I will have to create classes for creating\ntransactions and split IProcessingQueueRepository into two repositories\nIProcessingQueueRepository and IActiveQueueRepository, and all\nthis for the sake of one place in the code. Am I right? I don\u2019t know. But we\nlive in the real world where it is possible to move away from patterns if\nyour code is ultimately clearer. After all, in the end, patterns were created\nprecisely for a simpler understanding of the code.\n\nNext in this code, I want to pay attention to the ProcessMap class,\nwhich will be responsible for such functionality as whether we move\nfurther along the process map. If we had a rich model, then ProcessMap\nwould definitely be an entity, but now it is just a class that is close to\nservices. Perhaps we could even rename it ProcessMapService.\n\nListing 5-10 shows an implementation of the HandleEntitiesAsync\nfunction.\n\nListing 5-10. HandleEntitiesAsync Function\n\nprivate async Task HandleEntitiesAsync(ProcessMap processMap,\nList<ProcessingQueueElement> queueElements)\n\n{\nawait HandleEventsAsync(processMap, queueElements) ;\nawait HandleProcessingQueueAsync(processMap,\nqueueElements) ;\n\n}\n\nPlease note that first the bot \u201crips\u201d the entity from the node using\nevents and only after that processes the nodes.\n\nListing 5-11 shows the implementation of the HandleEventsAsync\nfunction.\n\nListing 5-11. HandleEventsAsync Function\n\nprivate async Task HandleEventsAsync(ProcessMap processMap,\nList<ProcessingQueueElement> queueElements)\n{\nList<string> entitiesIds = queueElements.ConvertAll\n(e => e.EntitylId);\nList<Event> unprocessedEvents =\n(await _eventRepository.GetUnprocessedAsync\n(entitiesIds))\n-ToList();\nforeach (ProcessingQueueElement queueElement in\nqueueElements)\n{\nvar entityEvents =\nunprocessedEvents\n-Where(e => e.EntityId == queueElement.\nEntityId)\n\n-OrderBy(e => e.CreatedAt) ;\nforeach (Event entityEvent in entityEvents)\n\n{\nint? nextNodeId = processMap\n-GetNextNodeId(queueElement .NodeId,\nentityEvent. Type) ;\nif (!nextNodeId.HasValue)\ncontinue;\n\nawait _eventRepository\n-MarkAsProcessedAsync(entityEvent.Id);\n\nawait _processingQueueRepository\n-UpsertAsync(queueElement.EntityId,\nnextNodeId.Value) ;\n\n}\n\nPlease note that the entity identifier is a string value. Why not a\nlong? It\u2019s simple\u2014we will have several entity types in our system such as\ngenerator, subtheory, and theory. If they all have a long ID, then how can\nwe understand which entity ID 1457 belongs to? Therefore, the id will be a\nuniversally unique identifier.\n\nNote A universally unique identifier (uid) is a standard identifier,\nusually of the form 0453bf87-68d4-4568-8f0b-c642154f579c. It\ngives sufficient confidence that where and when the uuid was not\ngenerated, it most likely will not match any previously created uuid.\n\nThis code also takes into account that there can be several events. The\nbot will process them in the order in which events enter the system.\n\nAnother important point is that the bot processes only those events\nwhose triggers are located lower than the current position of the entity on\nthe process map. This is done on purpose because, logically, some events\nmay no longer be relevant when the entity has reached a certain state.\n\nListing 5-12 shows an implementation of the\nHandleProcessingQueueAsync function.\n\nListing 5-12. HandleProcessingQueueAsync Function\n\nprivate async Task HandleProcessingQueueAsync(\nProcessMap processMap,\nList<ProcessingQueueElement> queueElements)\n\nIEnumerable<ProcessEntityData> entitiesData =\nawait _processEntityDataQueries\n-GetDataAsync(queueElements.ConvertAll\n(e => e.EntityId));\nList<ProcessEntityData> entitiesDataList = entitiesData.\nToList();\nforeach (ProcessingQueueElement queueElement in\n\nqueueElements)\n{\n\ntry\n\n{\n\nint? nextNodeId = processMap.\nGetNextNodeId(queueElement .NodeId) ;\nif (nmextNodeId == null)\n\nthrow new Exception(\"next node is empty\");\nvar entityData = entitiesDataList.First(d => d.Id\n== queueElement.EntityId) ;\nawait MoveAsync(\n\nprocessMap,\n\nnextNodeld,\n\nentityData,\nqueueElement) ;\n}\ncatch (Exception e)\n{\n_logger.LogError(e, $\"processing entity error.\nEntity id '${queueElement.EntityId}'\");\n}\n\nThere are a few interesting things about this feature. First, it refers\nto the class that implements the IProcessEntityDataQueries interface.\nThis class should be provided by the application that connects the\nlibrary. The idea is that the application will create a class derived from\nProcessEntityData, which contains the minimum necessary information\nabout the entity. Why is all this needed? It\u2019s need to not to receive this\ndata when processing each step, and there may be several of them in\none robot pass. Imagine a situation where on each node you use the\nsame information that will not change, for example, some constant data\nabout the entity. So as not to get it from the database every time, I added\nProcessEntityData. This class will contain immutable and easily obtainable\ninformation about the entity. For subtheories, for example, this could be\nthe theory identifier or something else.\n\nBefore moving on to implementing the MoveAsync function, I'd like to\ndemonstrate the fields of Node because it depends on the node parameters\nhow the Entity will be processed.\n\nListing 5-13. Node Class\n\npublic class Node\n\n{\n\npublic int Id;\n\npublic int Code;\n\npublic string Name;\npublic bool IsParent;\npublic int ParentId;\npublic NodeType? Type;\npublic bool Fast;\npublic string Params;\npublic int WaitingSeconds;\npublic int ActId;\npublic int EventTypeld;\npublic bool Deleted;\n\nIt is worth explaining why each of the fields is needed.\n\nId. Each node has its own identifier, which is needed for\nnodes with conditions, for example: \u201cIf the quality condi-\ntion is completed, then go to the node with id 1783.\u201d\n\nThe Code field. This is required to sort nodes on the\nprocess map. The robot needs to somehow understand in\nwhat sequence to process the steps of the map.\n\nName. This is exclusively a UI field.\n\nIsParent and ParentId. These are important fields. Our\napplication can process entities of different types, and\neach of them can have its own process map, but how can\nwe separate them from each other? The easiest way is to\ngroup. It was for grouping purposes that I entered these\ntwo fields.\n\n\u2014 Type. This is a field that stores the node type. It is from\nthis that the program will understand how to process\nthis node.\n\n\u2014 Fast. This is perhaps one of the most interesting node\nfields. I added this field to indicate that the robot should\nperform several steps in one pass. If a node has the value\nof this field equal to true, then the robot will process it and\nthen process the next step, and so on until the next node\nhas the value of this field false. This field can be used to\nregulate the load, set fast and low-cost nodes to fast, or\nwhen you want to perform a series of steps without the\nrisk of your entity being ripped by a trigger in the middle\nof processing.\n\n\u2014 Params. This is a string with node execution parameters\nthat will be passed to the class that implements the\nspecific action.\n\n\u2014 WaitingSeconds. This is an option for nodes with the\nWaiting type. It shows the number of seconds the entity\nmust wait on this node.\n\n\u2014 ActId. This is the value that will be passed to\nIProcessActFactory to obtain an implementation of the\nIProcessAct interface.\n\n\u2014 EventTypeld. This parameter will store the event type\nidentifier. Events will be stored in a separate table, and, of\ncourse, each of them will have its own type, because events\nare different. The robot will understand which trigger to\ndisrupt the entity precisely thanks to this parameter.\n\n\u2014 Deleted. This field is required for the soft delete feature of\nanode. In fact, if a node has a value of this field that is\ntrue, this means the process map will not see it.\n\nLet\u2019s move on to the very heart of our bot, namely, the MoveAsync\nfunction.\n\nListing 5-14. MoveAsync Function\n\nprivate async Task MoveAsync(\nProcessMap processMap,\nint? nodeld,\nProcessEntityData entityData,\nProcessingQueueElement queueElement)\n\nif (!nodeId.HasValue)\nreturn;\n\nNode node = processMap.GetNode(nodeId.Value) ;\n\n(bool move, int? nextNodeId) = node.Type switch\n\n{\nNodeType.Act=> await MakeActAsync(processMap, node,\nentityData),\nNodeType.Waiting => await MakeWaiting(processMap, node,\nentityData, queueElement),\nNodeType.Terminal => await\nMakeTerminalAsync(processMap, node, entityData),\nNodeType. Trigger => MakeNextStep(processMap, node),\nNodeType.Description => MakeNextStep(processMap, node),\nnull when node.ItsParent =>\nMakeNextStep(processMap, node),\n_ => throw new Exception($\"unknown node type\n{node.Type}\")\n\nhs\n\nif (nextNodeId.HasValue)\n\nawait _processingQueueRepository.\nUpsertAsync(entityData.Id, nextNodeId.Value) ;\n\nmove = move && node.Fast;\n\nif (move)\nawait MoveAsync(processMap, nextNodeId, entityData,\nqueueElement) ;\n\nThe first thing you need to pay attention to is that the MoveAsync\nfunction is recursive. That is, it calls itself. Typically, recursion is used\nwhen it is not clear how many iterations need to be performed. We don\u2019t\nknow this in advance, because we don\u2019t know what types of nodes we will\nencounter when processing an entity and whether they will all be fast (with\nthe field value fast = true). Another notable point in this code is the move\nvariable. Why not stop only based on the node. Fast condition? Why did\nit have to be complicated? It\u2019s simple: we will have nodes like \u201cStop and\nreport,\u2019 which must perform some action, which means it will be a node\nwith the Act type, but after its execution, the bot should not move further.\n\nListing 5-15 shows the code that implements the remaining processing\nfunctions for each type of step.\n\nListing 5-15. MakeActAsync Function\n\nprivate async Task<(bool move, int? nextNodeId)> MakeActAsync(\nProcessMap processMap,\nNode node,\nProcessEntityData entityData)\n\ntry\n\n{\nIProcessAct? act = _processActFactory.\nGetAct (node. ActId) ;\n\n-UpsertAsync(entityData.Id, node.Id, processingTime) ;\nreturn (false, null);\n\n}\n\nprivate async Task<(bool move, int? nextNodeId)>\nMakeTerminalAsync(\n\nProcessMap processMap,\n\nNode node,\n\nProcessEntityData entityData)\n\nawait _processingQueueRepository.RemoveAsync(entityData.Id,\nnode.Id);\nreturn (false, null);\n\n}\n\nprivate (bool move, int? nextNodeId) MakeNextStep(\nProcessMap processMap,\n\nNode node)\n\n{\nint? nextNodeId = processMap.GetNextNodelId(node. Id) ;\nreturn (true, nextNodeld);\n\n}\n\nPerhaps the only noteworthy thing about this code is that the\nMakeAsync() function of the IProcessAct interface returns (bool move,\nint? nextNodeId). I explained why I needed the move variable earlier,\nbut why did I need the nextNodelId value? It is necessary for acts with\nconditions, where when a certain condition is met, it is necessary to move\nthe entity not to the node immediately after the act but to some completely\ndifferent place on the process map.\n\n-UpsertAsync(entityData.Id, node.Id, processingTime) ;\nreturn (false, null);\n\n}\n\nprivate async Task<(bool move, int? nextNodeld)>\nMakeTerminalAsync(\n\nProcessMap processMap,\n\nNode node,\n\nProcessEntityData entityData)\n\nawait _processingQueueRepository.RemoveAsync(entityData.Id,\nnode.Id);\nreturn (false, null);\n\n}\n\nprivate (bool move, int? nextNodeId) MakeNextStep(\nProcessMap processMap,\n\nNode node)\n\n{\nint? nextNodeId = processMap.GetNextNodelId(node. Id) ;\nreturn (true, nextNodeId) ;\n\n}\n\nPerhaps the only noteworthy thing about this code is that the\nMakeAsync() function of the IProcessAct interface returns (bool move,\nint? nextNodeId). I explained why I needed the move variable earlier,\nbut why did I need the nextNodelId value? It is necessary for acts with\nconditions, where when a certain condition is met, it is necessary to move\nthe entity not to the node immediately after the act but to some completely\ndifferent place on the process map.\n\nListing 5-16 shows the methods implemented in the ProcessMap class.\n\nListing 5-16. GetNextNodeld Function\n\npublic int? GetNextNodeId(int nodeId, int eventType)\n{\nNode currentNode = GetNode(nodeId) ;\nNode? nextNode =\n_nodes\n-Where(n =>\nn.Deleted == false\n&& n.ParentId == currentNode.ParentId\n&& n.Type == NodeType. Trigger\n&& n.EventTypeId == eventType\n&& n.Code <= currentNode.Code)\n-MinBy(n => n.Code);\n\nreturn nextNode?.Id;\n\n}\n\npublic int? GetNextNodeId(int nodeId)\n{\nNode currentNode = GetNode(nodeId) ;\nNode? nextNode =\n_nodes\n-Where(n =>\nn.Deleted == false\n&& n.ParentId == currentNode.ParentId\n&& n.Code <= currentNode.Code)\n-MinBy(n => n.Code);\n\nreturn nextNode?.Id;\n\nListing 5-16 shows that nodes are sorted by code. It is also taken into\naccount that an event can have several triggers, in which case the entity\nwill fall to the trigger node closest to its current position.\n\nI hope that I showed a fairly clear and easy-to-use straight machine.\nNow, based on this example, you can implement your own or use an\nexisting one, but I hope the basic principle of operation is clear to you.\n\nBackworker\n\nThere is one more general mechanism whose operation I will reveal. This\nis a mechanism for running background tasks on a schedule. We will\n\nneed such a mechanism, for example, in the real trading subsystem in the\nStrategy Manager Service. Its Tasks application will periodically check the\ntypes of financial instruments and the list of working strategies to instruct\nthe Strategy Service to enable or disable instrument-strategy pairs. Also,\nthis mechanism will most likely be needed to receive data from exchanges,\nbecause not all exchanges implement a web socket interface for all of their\nfunctionality. You can take one of the implemented libraries or write your\nown. Here I will demonstrate one of the simplest implementations of this\nmechanism.\n\nThe idea of how it works is similar to how the state machine was\nimplemented. Each application pod will run an infinite loop, which will\nperiodically take on a task. As with the state machine, of course we will\nencounter the problem of having several pods for the application and solve\nit in the same way. I ended up with the list of tables in the database that is\nshown in Figure 5-7.\n\nTaskid\n\ntals Timestamp\n\nTaskid\nLastStartDate\nLastStopDate\n\nFigure 5-7. Database table schema\n\nAs in the example with the state machine, we need a table to store\nactive tasks so that other pods do not take them to work. We also need a\ntable to store information with the date of the last start and stop of task\nprocessing. This information will be needed to determine whether it is\ntime to run the task or not. But everything is in order. First, we need to\nimplement an extension for IServiceCollection, where we will add all\nthe necessary dependencies, including the hosted service.\n\nListing 5-17. AddBackworker Function\n\npublic static IServiceCollection AddBackworker(\nthis IServiceCollection services,\nAction<BackworkerOptions> setupAction,\nType actFactoryType,\nparams Assembly[] assemblies)\n\nservices .AddOptions();\nservices .Configure(setupAction) ;\n\nservices .AddSingleton<BackworkerManager>();\nservices .AddSingleton(typeof(IBackworkerTaskFactory),\nactFactoryType) ;\n\nAddTasksImplementations(services, assemblies) ;\nservices .AddHostedService<BackworkerHostedService>() ;\n\nreturn services;\n\nListing 5-17 shows the implementation of the Add Dependency feature\nfor the Backworker mechanism. You probably noticed that this code is\nvery similar to the code implemented in Listing 5-7, where we connected\ndependencies for ProcessBot. And that\u2019s great! A consistent code style is\nvery important. I love .NET and programs developed on it for this quality,\nuniformity, and a single code style.\n\nI won't bore you with the implementation of the\nBackworkerHostedService class because it is similar to the\nProcessBotHostedService class. Let's jump straight into the\nBackworkerManager. Listing 5-18 shows an implementation of the\nRunAsync method, which is run periodically by ProcessBotHostedService.\n\nListing 5-18. RunAsync Function\n\npublic async Task RunAsync(CancellationToken cancellationToken)\n{\nBackworkerTask? backworkerTask =\nawait _backworkerTaskRepository.\nGetAndLockStartBackworkerTaskAsync() ;\n\nif (backworkerTask == null)\nreturn;\n\ntry\n{\nawait _backworkerTaskLogRepository\n-UpsertStartAsync(backworkerTask. Id) ;\n\nIBackworkerTaskAct? task =\n_backworkerTaskFactory.\nGetTask(backworkerTask. Type) ;\n\nawait task.RunAsync(backworkerTask.MagicString,\n\ncancellationToken) ;\n\nawait _backworkerTaskLogRepository\n.UpsertStopAsync(backworkerTask. Id) ;\n\n}\ncatch (Exception e)\n{\n_logger.LogError(e,\n$\"Unknown error run backworker task\n{backworkerTask}\") ;\n}\n\nawait _backworkerTaskRepository\n-UnlockBackworkerTask(backworkerTask. Id) ;\n\nAs in the case of ProcessBot, this function calls the repository function\nGetAndLockStartBackworkerTaskAsync, which contains the logic for\nselecting the task that should run. Please note that the TaskLog table is\nwritten twice, before the task starts and after.\n\nListing 5-19 shows an implementation of the BackworkerTask class.\n\nListing 5-19. BackworkerTask Class\n\npublic class BackworkerTask\n{\npublic int Id;\npublic string Name;\npublic int Type;\npublic bool Active;\n\npublic string MagicString;\n\npublic int RepeatPeriodMs;\npublic int RestartDelayMs;\npublic int CrashRestartDelayMs;\n\npublic bool NeedsToStart(\nDateTime now,\nDateTime? lastStart,\nDateTime? lastStop,\nDateTime? lockTime)\n\nreturn Active\n&& TimeToStart(\nnow,\nlastStart ?? DateTime.MinValue,\nlastStop ?? DateTime.MinValue,\nlockTime) ;\n\n}\n\nprivate bool TimeToStart(\nDateTime now,\nDateTime lastStart,\nDateTime lastStop,\nDateTime? lockTime)\n\nbool scheduleStartTime =\n(now - lastStart).TotalMilliseconds >=\nRepeatPeriodMs\n&& (now - lastStop).TotalMilliseconds >=\nRestartDelayMs ;\n\nbool restartCrash =\n\nlockTime.HasValue\n&& (now - lockTime.Value).TotalMilliseconds >=\nCrashRestartDelayMs;\n\nreturn scheduleStartTime || restartCrash;\n\nthe meaning of most fields is clear from their names, but I will still\nexplain them so that there is no misunderstanding.\n\n\u2014 Id. This is the task identifier. This is the only unique\nfield in the table.\n\n\u2014 Name. This is a field that has no logical load but is\nnecessary for the user.\n\n\u2014 Type. It is by this field that the class that implements the\nIBackworkerTaskFactory interface will create classes\nthat implement the IBackworkerTaskAct logic. The\nTasks table can contain several tasks with the same type\nand different launch parameters. This is necessary for\nhandlers of the same type.\n\n\u2014 Active. This flag is responsible for enabling/disabling\nthe task. Essentially this is a soft delete.\n\n\u2014 MagicString. This is a line with the parameters for\nlaunching the handler. This could contain anything,\nincluding JSON with a complex parameters object.\n\n\u2014 RepeatPeriodMs. This parameter displays how often\nthe task should run in milliseconds.\n\n\u2014 RestartDelayMs. Imagine a situation where\nRepeatPeriodMs = 10 seconds and your task completed\nin 20 seconds. Should it start again immediately, or\n\nshould it wait a while? This parameter was introduced\nprecisely so that some tasks would not be launched\nimmediately after execution but after some time\n\nhad passed.\n\n\u2014 CrashRestartDelayMs. When a pod starts a task, it\nmakes an entry in the ActiveTasks table and notes in it\nthe time when it started working on this task. After this,\nthe pod may cease to exist, but the entry in ActiveTasks\nwill remain. This means that another pod needs to take\nover this task, but how will it understand that this can be\ndone? After all, ActiveTasks has a record that this task is\nalready in operation. It is for this case that\nCrashRestartDelayMs was introduced. If more than\nCrashRestartDelayMs milliseconds have passed since\nthe blocking time marked in ActiveTasks, then another\npod can take over this task.\n\nSummary\n\nIn this chapter, I highlighted the main approach that I will use in\ndeveloping system applications, namely, the use of commands instead of\nservices. It also highlighted the main advantages of this approach.\n\nI also showed the simplest implementations of a state machine anda\nbackworker, which we will use in our services.\n\nAs a result, I hope you have accumulated enough information to start\nimplementing application services.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 6,
                "chapter_name": "CHAPTER 6",
                "chapter_path": "./screenshots-images-2/chapter_6",
                "sections": [
                    {
                        "section_id": 6.1,
                        "section_name": "Optimization\nAlgorithms",
                        "section_path": "./screenshots-images-2/chapter_6/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_6/section_1/4ba62584-2a6e-42fa-93e1-f6b2391a57ba.png",
                            "./screenshots-images-2/chapter_6/section_1/ef53494e-81d2-494e-89dd-1af29e39efe5.png",
                            "./screenshots-images-2/chapter_6/section_1/13ef2892-413e-4795-ae86-13d82cd055f4.png",
                            "./screenshots-images-2/chapter_6/section_1/a41fc9db-ddd1-4c1a-956b-18ef8052b03b.png",
                            "./screenshots-images-2/chapter_6/section_1/61aa308f-366d-4f30-8dbe-a7b3bcd9f7b2.png",
                            "./screenshots-images-2/chapter_6/section_1/3f6303a2-2306-4786-8a2f-1adc43fff367.png",
                            "./screenshots-images-2/chapter_6/section_1/cda41af4-3244-47b0-bfcd-22235d8b55f3.png",
                            "./screenshots-images-2/chapter_6/section_1/c73ad04d-366c-40e7-b34b-95f549a051d0.png",
                            "./screenshots-images-2/chapter_6/section_1/fc2187ba-f970-416a-9571-f56677624465.png",
                            "./screenshots-images-2/chapter_6/section_1/5ebb5a0c-4246-434e-a9d9-d6625168da2e.png",
                            "./screenshots-images-2/chapter_6/section_1/50a0e71d-f731-44a2-8e57-44c47d6f2128.png",
                            "./screenshots-images-2/chapter_6/section_1/03825905-63a1-4408-98d5-05fc08376c40.png",
                            "./screenshots-images-2/chapter_6/section_1/7f0f6481-90fc-48ec-b09d-65ab8ffd623e.png",
                            "./screenshots-images-2/chapter_6/section_1/c49e347b-8bb2-4d88-8f71-67348e00693a.png",
                            "./screenshots-images-2/chapter_6/section_1/f88996cd-1c72-4c82-af60-2b2f76bf270e.png",
                            "./screenshots-images-2/chapter_6/section_1/50e26daa-b61d-41b5-bc48-dafabafdf749.png",
                            "./screenshots-images-2/chapter_6/section_1/4c91fdae-3c6c-47d9-b302-945b62d49729.png",
                            "./screenshots-images-2/chapter_6/section_1/8363823b-16d1-4b5b-bdd8-6f494618eba5.png",
                            "./screenshots-images-2/chapter_6/section_1/1089e2be-030e-4ec2-8323-b41ead27a975.png",
                            "./screenshots-images-2/chapter_6/section_1/fadc8b47-bccd-4736-81db-f37ac9b0f922.png",
                            "./screenshots-images-2/chapter_6/section_1/22f0d470-28f4-4a1d-aec5-868ef35e528a.png",
                            "./screenshots-images-2/chapter_6/section_1/65e570aa-b25d-4799-b547-86fa7f69fabe.png",
                            "./screenshots-images-2/chapter_6/section_1/e02fdc63-9efd-4bf4-91ce-6bb0b5e1037b.png",
                            "./screenshots-images-2/chapter_6/section_1/ab15fc3a-cf69-4150-8d45-e71f5e7679f0.png",
                            "./screenshots-images-2/chapter_6/section_1/25e25f0b-664e-47e7-ab4e-e371425d07a1.png",
                            "./screenshots-images-2/chapter_6/section_1/5bb27431-709f-4623-847d-754c09600d88.png",
                            "./screenshots-images-2/chapter_6/section_1/774e1aef-cda2-4d92-baa8-a7115f4ede19.png",
                            "./screenshots-images-2/chapter_6/section_1/6a6ede2e-60b8-49dc-bd7a-a53c0902c95b.png",
                            "./screenshots-images-2/chapter_6/section_1/8756c1b1-992b-426b-a505-567d91703a4c.png",
                            "./screenshots-images-2/chapter_6/section_1/4b85a87a-8f69-435e-a342-5333f2aef709.png",
                            "./screenshots-images-2/chapter_6/section_1/5268fb2d-0ff0-40aa-9912-87fa9efefeca.png",
                            "./screenshots-images-2/chapter_6/section_1/3cc59db9-c715-4342-b4eb-1d85b8813a06.png",
                            "./screenshots-images-2/chapter_6/section_1/276955ca-9923-4af5-854d-a5e6dcff448f.png",
                            "./screenshots-images-2/chapter_6/section_1/8e618861-380d-4c66-acfb-d9d8e0156025.png",
                            "./screenshots-images-2/chapter_6/section_1/3d94151e-f3ce-4640-ad07-38026fa110e7.png",
                            "./screenshots-images-2/chapter_6/section_1/5a46100c-7f62-4c8e-b39f-2c822160dd7f.png",
                            "./screenshots-images-2/chapter_6/section_1/56e94ff2-136c-484f-9164-b6f09c09ccc0.png",
                            "./screenshots-images-2/chapter_6/section_1/3f645296-6aa9-4cab-af6e-d9eb2c15de87.png",
                            "./screenshots-images-2/chapter_6/section_1/f566746b-5f79-4c03-880f-80d82bff812a.png",
                            "./screenshots-images-2/chapter_6/section_1/40d48d3c-b27c-42bf-8e89-04f7dfd2884f.png",
                            "./screenshots-images-2/chapter_6/section_1/b4687a6b-c6ec-4d3d-87f8-16901c2a26e1.png",
                            "./screenshots-images-2/chapter_6/section_1/82a349d2-990c-46df-a551-f27b01bd8c53.png",
                            "./screenshots-images-2/chapter_6/section_1/9d88c399-d71b-4cab-925e-c58e596a46d9.png",
                            "./screenshots-images-2/chapter_6/section_1/06c1a32d-965c-4ad3-9dff-f99c4e19bffe.png",
                            "./screenshots-images-2/chapter_6/section_1/4415e4f1-b63a-44eb-af1f-28a2a2808c1e.png",
                            "./screenshots-images-2/chapter_6/section_1/38b4ebdc-6270-45a7-bacb-ddfe40c5d3e0.png",
                            "./screenshots-images-2/chapter_6/section_1/3a5bc2b9-a249-4370-9586-417622c9cd5d.png",
                            "./screenshots-images-2/chapter_6/section_1/53dcc5bf-cf7b-4ec4-aacd-34b5397a8bac.png",
                            "./screenshots-images-2/chapter_6/section_1/a078eddb-d643-43f2-b765-8e7fa7960648.png",
                            "./screenshots-images-2/chapter_6/section_1/ffdb95db-5849-4e97-aeb1-e8083740ae38.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "One of the key modules of our system is the optimization algorithm\nmodule, which searches for and optimizes strategies in the strategy search\nsubsystem.\n\nOur task of finding a profitable strategy has several features such as\nnonlinearity, multiextremality, complete absence of analytical expression,\nhigh dimension of the search space, and high computational complexity\nof the optimized function. All of these features explain why there is no\nuniversal algorithm for solving the optimization problem and finding\na profitable strategy. This means that the optimization module must\nimplement a number of different optimization algorithms.\n\nTo solve the global optimization problem, several classes of\noptimization algorithms have been developed, one of which is the\npopulation algorithms class.\n\nIn population algorithms, simultaneous work is carried out on several\noptions when solving an optimization problem, in contrast to classical\nalgorithms, in which only one candidate evolves.\n\nPopulation algorithms have a number of advantages that make them\nperfect for solving our problem.\n\n\u00ab They have proven themselves to be excellent in solving\nproblems of high dimensionality, multimodality, and\nlow formalization.\n\n\u00ab They are not algorithms with a strictly defined order of\nsteps. They rather have a set of standard operations and\nrules with which you can create a large number of your\nown variations of optimization algorithms.\n\n\u00a2 They are most effective in finding a suboptimal, that is,\nclose to optimal, solution. To find a profitable strategy,\na suboptimal solution is often enough.\n\nIn this chapter, I will cover the minimum necessary theory that will\nallow you to dive into the world of population algorithms and implement\nan optimization module.\n\nFormulation of the Problem\n\nIn optimization theory, there are two types of optimization problems:\ndeterministic and stochastic. In the first case, the target function is\ndeterministic. That is, it does not contain random parameters. The\nstochastic function contains it. Our target function, namely, the function\nfor calculating the performance strategy on a section of historical data, is\ndeterministic. The general formulation of a deterministic optimization\nproblem is as follows:\n\nmax f(X) = (X= f\u00b0\n\n|X|: The dimension of the vector of variable parameters X = x1, x1,\n\nF(X): The objective function or optimality criterion.\nX*: The he required optimal solution.\n\nf*: The esired optimal value.\n\nD=G{(xX): The set of admissible vector values X, where G(X)\nis the vector bounding function consisting of components\n& (X), 8(X), sey Bic(X) 1 2 |G\n\nThe determinism of the task means that the objective function /(X)\nand the limiting function G(X) do not contain random parameters.\n\nIf |X| > 1, then the problem is called multiparameter.\n\nAn objective function may have points at which it reaches its largest or\nsmallest value. These points are called extrema. If the objective function\nhas several such points, then this function is said to be multi-extremal.\n\nA test is an operation of one-time calculation of the target and limiting\nfunctions. In our case, calculating the objective function is an expensive\noperation that requires a lot of computing resources, so the main\nrequirement for optimization algorithms is to find the optimal value of the\nobjective function in the least number of tests.\n\nPopulation Algorithms\n\nThe problem of finding the optimal solution is now clear, so let\u2019s start\nsolving it using population algorithms.\n\nThe main idea of these algorithms is based on working on several\nsolutions at once. One solution option, in population algorithms, is\ncalled an agent. The set of agents generated at the iterative step is called a\npopulation.\n\nThe general scheme for solving an optimization problem using\npopulation algorithms includes the following steps:\n\n1. Initialization of the population. Using some\nalgorithm, a first approximation of the solution to\nthe optimization problem is generated. That is, the\nfirst set of agents will be generated.\n\n2. Migration. According to a certain scenario or set of\noperations, agents are migrated in such a way as to\nultimately approach the desired extremum. That is,\nthe next generation of agents will be created.\n\n3. Checking the search termination condition. The\nconditions for the end of iterations are checked. If\nthese conditions are not met, then return to step 2.\n\nWhen initializing a population, both deterministic and random\nalgorithms can be used. If the initial population is formed near the global\nextremum, that is, the maximum or minimum value of the function\nthroughout the entire definition domain, this will significantly speed up\nthe search for the optimal solution. But in the general case, we do not have\na priori information about the location of the global extremum, so often\nthe agents of the first population are distributed evenly throughout the\nentire search area.\n\nThere are two popular search termination conditions. The first is by the\nnumber of iterations, when the search stops after creating a given number\nof generations. The second is according to the stagnation condition, when\nthe best achieved value of the objective function does not change for a\ngiven number of generations.\n\nIt is clear that population algorithms have a highly modular structure.\nThis means that by varying operations and migration algorithms, you can\nget a large variety of your own unique optimization algorithms.\n\nIn most cases, population agents have the following properties:\n\n+ Autonomy. Agents move in the search space\nconditionally independently of each other.\n\n+ Stochasticity. The process of migration or generation\nof new agents contains a random parameter.\n\n\u00a2 Limited representation. All agents have information\nonly about part of the search area they are investigating.\n\nIn some algorithms, agents \u201cshare\u201d information with\neach other, but in most algorithms this is not the case.\n\n\u00a2 Decentralization. There is no hierarchy among agents.\n\n\u00a2 Communication skills. Agents, to varying degrees, can\nexchange information with each other.\n\nOne of the problems in designing population algorithms is the\nproblem of maintaining a balance between search intensity and search\nbreadth. Intensity refers to the rate of convergence, or the speed at which\nthe algorithm finds a solution. And the problem of search breadth is\nunderstood as diversifying this, that is, ensuring a sufficient variety of\nagents to increase the likelihood of finding a global extremum.\n\nIntensification of the search requires rapid convergence, which\nentails a requirement for a rapid reduction in the diversity of agents.\nDiversification, on the contrary, is designed to provide a broader overview\nof the space under study, which entails the requirement to maintain a large\nnumber of agents.\n\nA popular approach to maintaining a balance between the intensity\nand breadth of search is the so-called adaptation and self-adaptation\nmechanisms. When these mechanisms are applied, the free parameters\nof the algorithms gradually change so as to gradually move from\ndiversification to intensification.\n\nSince population algorithms are stochastic, their efficiency strongly\ndepends on the values of random variables, which means they can\nachieve different results even while maintaining the same values of\nfree parameters. For this reason, multiple runs are used to evaluate the\neffectiveness of algorithms. When the same algorithm is used to solve the\nsame problem, this approach is called the multistart method.\n\nGenetic Algorithms\n\nGenetic algorithms are a popular type of algorithm belonging to the\npopulation class. These are the ones I will use in the search for the optimal\nstrategy.\n\nGenetic algorithms became known to the world after the publication\nof the book Adaptation in Natural and Artificial Systems (J. Holland, 1975).\nThis class of algorithms was based on the ideas of Darwin's theory of\nnatural selection.\n\nDarwin showed that the evolutionary development of the earth\u2019s flora\nand fauna is based on the following principles:\n\n\u00a2 Heredity. Some traits of parents are passed onto\noffspring.\n\n\u00a2 Variability. It is difficult to find two identical\nindividuals.\n\n+ Natural selection. Only the fittest individuals survive.\n\nEveryone knows that the substance that determines hereditary\nprocesses is deoxyribonucleic acid (DNA). It is the molecular biological\nprocesses of heredity that form the basis of genetic algorithms.\n\nThe structure containing DNA is called a chromosome. A gene is a\nspecific part of a chromosome in which innate personality qualities are\nencoded (eye color, skin color, height, etc.). A locus is the location ofa\ngene on achromosome. An allele is the functional significance of each\ngene. A genotype is the totality of genes of a particular individual. The set\nof personality characteristics is called a phenotype.\n\nTo give an analogy with our system, a chromosome is a set of strategy\nparameter values. A gene is the value of one of the parameters, for example\nLookbackPeriod for the average directional index (ADX) indicator.\n\nDuring the sexual reproduction of living beings, the fusion of two sex\ncells occurs in which the DNA of the parents interact with each other and\nthe result is the DNA of the descendant. This procedure is called crossing.\n\nBecause of many factors, genes in the DNA of the parents\u2019 germ cells\ncan change. This process is called mutation. Mutated genes are passed on\nto the offspring and give it properties not found in either parent. If unique\nproperties turn out to be useful, then they are likely to be retained in the\npopulation.\n\nThe diagram ofa typical genetic algorithm is as follows::\n\n1. According to some algorithm, a set of individuals\n(agents) is created.\n\n2. Individuals are evaluated using an objective\nfunction. This means that for each individual, we\ncalculate the objective function.\n\n3. The selection stage is carried out. That is, based on\nadaptability (the value of the objective function), we\nselect individuals for crossing.\n\n4. We apply mutation and crossing operators to\nselected individuals. As a result, we get a new\ngeneration (population) of individuals.\n\n5. We check the algorithm stopping condition. If the\ncondition is not met, then return to step 2.\n\nThe essence of genetic algorithms is that each new generation, on\naverage, is more fit than the previous one.\n\nMutation Operators\n\nThe essence of the mutation operator is to replace gene x; with gene x; .\nThat is, in the general case, any mutation operator consists of two stages.\n\n1. Selecting genes to be replaced\n2. Replacing these genes\n\nLet's take a closer look at a few operators.\n\nRandom Operator\n\nThe method is to assign to gene x,a random number from the\ninterval [x xy ].\n\nThe algorithm for the random mutation operator is as follows:\n\n1. We generate n random integer nonmatching\nnumbers whose values are in the interval from 1 to\n|X|. These numbers will be equal to the numbers\nof genes that will be subject to mutation. n is a free\nparameter of the operator, which is responsible for\nthe number of genes to be mutated.\n\n2. We generate a random number in the interval from\nx, tox; and equate this value to the gene numbered\ni of the descendant.\n\n3. Using the same scheme, we mutate the remaining\ngenes selected for mutation.\n\n4. The descendant takes the remaining genes from the\noriginal individual without changes.\n\nThe simplest implementation of this operator can be considered the\nimplementation of the boundary mutation operator, in which the gene\nx, is assigned the value x, or x; with equal probability. See Figure 6-1.\n\na 2} af\n\nFigure 6-1. Interval of acceptable mutant gene values: example 1\n\nArithmetic Real Number Creep Operator\n\nThe algorithm for this operator looks exactly like the random operator\nalgorithm. But the formula in step 2 takes the following form:\n\nx, =x, +6(2y\u2014-1)\n\n\u00e9: This is another free parameter.\n\ny: This is a random number that ranges from 0 to 1.\n\nAsa result, the value x/ will take values on the interval [x, \u2014 &} x; + \u20ac].\nSee Figure 6-2.\n\n\u2014._ASJdNH\na-\u20ac a, at\u00e9\n\nFigure 6-2. Interval of acceptable mutant gene values: example 2\n\nGauss Operator\n\nAccording to the algorithm of this operator, the new value x; must deviate\nfrom the parent value x, by an amount calculated by the Gaussian function.\n\nx! =x; +P(y,0)\n\nyu: This is a free operator parameter, which is the mathematical\nexpectation or an average value. It is usually equal to 0.\n\no: This is a free operator parameter. The standard deviation is\nresponsible for how much the final value of the function will differ from\nthe value of the mathematical expectation. See Figure 6-3.\n\n\u00bb\nFigure 6-3. Graph of the probability of assigning a value y to a gene\n\nCrossover Operators\n\nThe purpose of these operators is to obtain, from two parent individuals,\n\none or more offspring individuals. Or, to put it in formulas, it creates child\n\nchromosomes X,,X,, ...,X,, based on two parent chromosomes, X, and X).\nLet\u2019s look at a few operators.\n\nFlat Crossover\n\nIn this operator, the gene x; of the child is a random number located in the\ninterval from x/\"\" to x\", where x\" is the minimum of the parent gene\nvalues, and x\u201d is the maximum of them. See Figure 6-4.\n\n4+ +>\nginin EA gmax\n\ni t i\n\nFigure 6-4. Range of acceptable values\n\nBlend Crossover\n\nIn this operator, the gene x! of the child is a random number located in the\ninterval from x/\"\"-\u2014Ao to x\u2122\u201c +Ao.\n\no, =x\"\u2122- xn\"\n\nAis a free operator parameter. Obviously, the larger it is, the more\nthe gene of the descendant will differ from the genes of the parents. You\ncan build your algorithm in such a way that the parameter value will be\ndifferent for each gene. See Figure 6-5.\n\nAo Ao\n\u2014) uy i >\nza ae\n\nFigure 6-5. Range of acceptable values\n\nArithmetical Crossover\n\nAccording to this operator, the chromosomes of the descendants are\ncreated according to the following formula:\n\nXn = AM, +(1 ~A)x,,\n\nX= Am, +(1-A)x,\n4: This is a random number ranging from 0 to 1.\n\nHeuristic Crossover\n\nIn this operator, the gene x! of the descendant is calculated using the\nfollowing formula:\n\ni\n\nx= A(x, -x,,) +x,\n\nIn this formula, it is assumed that the first individual is more fit than\nthe second.\n\n4: This is a random number that can range from 0 to 1.\n\nLinear Crossover\n\nAccording to this operator, three descendants will be created according to\nthe following formulas:\n\nmy =0.5x,; +0.5x,,\nx}, =1.5x,, -0.5x,,\n\nx, =0.5x,, +1.5x,,\n\nSee Figure 6-6.\n\nJ\nal x x,\n\nFigure 6-6. Range of acceptable values\n\nFuzzy Crossover\n\nWhen you use this operator, you will end up with two children. The\nprobability that the gene x; of a daughter individual is described by a\ntriangular probability density function designated as F( x; ). So for x\u2019, the\nleft corner of the triangle will be located at the value x \u2014 Ao, and the right\ncorner will be located at x! +Ao.\n\nAis the operator parameter; the most commonly used value is 0.5. See\nFigure 6-7.\n\nFigure 6-7. Graph of the probability of assigning values to genes\n\nSimulated Binary Crossover (SBX)\n\nAccording to this operator, two descendants are created; the value of gene i\nis calculated by the following formula:\n\nx1, =0.5((1-w)x,, +(1+)x,,)\n\nx, =0.5((I-u)x,, +(1+u)x,,)\n\nuis a number whose probability density is calculated using the\nfollowing formula:\nAu) { ms\n\nnis a free parameter of the operator, a number taking values from 2 to 5.\nAn increase in the number n entails an increase in the probability that the\nvalue of the child gene will be generated in the vicinity of the value of the\nparent gene. See Figure 6-8.\n\nT,u(0,1) > 0,5\nT,u(0,1) < 0,5\n\n\nTig\n\nFigure 6-8. Graph of the probability of assigning values to genes\n\nFiltering Operators\n\nThis group of operators helps to form a new population by adding the most\nsuitable individuals to it.\n\nRoulette Method (Proportional Sampling)\n\nThe roulette method is based on representing the population in the form\nof a roulette wheel, where each individual has its own sector, the size of\nwhich is proportional to the value of its objective function. See Figure 6-9.\n\nE> {ca\n\nFigure 6-9. Roulette of probabilities\n\nThe filtering algorithm using the roulette method is as follows:\n\n1. For each individual s,, we calculate the probability of\nSf\n\nits selection using the formula P, = Tjy\u2014-\n\n2. Divide the interval from 0 to 1 by |S| subintervals\n\nin proportion to the values calculated in the\nprevious step.\n\n3. We spin the roulette. We generate a random number\nfrom 0 to 1, depending on which sector this number\nfalls into, and that individual will be selected.\n\n4. We repeat step 3 until the required number of\nindividuals is selected.\n\nIt is clear from the formula that the higher the subinterval allocated for\nan individual, or, in other words, the value of the objective function, the\nhigher the probability that it will be selected.\n\nThe disadvantage of this method is that individuals with low\nadaptability will be very quickly excluded from the population, which\nwill lead to premature stagnation of the algorithm. Another disadvantage\nof the method is that individuals with high adaptability will not always\nbe selected. As a result, the new population may lose promising search\ndirections.\n\nProportional Sampling Method\n\nThis method is considered a development of the roulette method. It is built\non the following formula:\n\n_ f(s)\nf(S)\n\n\u201c\n\nJf (S) is the average value of adaptability of individuals of generation S.\n\nThe integer part of \u00bb will indicate how many times an individual needs\nto be recorded in the intermediate population, and the fractional part\nshows its probability of getting there again.\n\nStochastic Universal Method\n\nThis is another variation of the proportional filtering method. But the\nselection is carried out in two stages.\n\n1. The n fittest individuals will be included in the new\npopulation. n is a free operator parameter.\n\n2. The remaining required number of individuals is\nselected using the roulette method.\n\nAs a result of this method, individuals with high adaptability can enter\nanew population more than once, which means they are more likely to\ninterbreed with more than one individual.\n\nTournament Method\n\nThe method involves the formation of groups of n individuals each\nbased on the population. In each group, an individual with the greatest\nadaptability is selected and will be included in the intermediate\npopulation.\nnis a free operator parameter called tournament size. Obviously, if it is\nequal to 1, then the tournament filtering method will degenerate into the\nrandom filtering method. Typically the value of this parameter is 2 or 3.\nThe tournament filtering algorithm is as follows:\n\nIn any way we divide the population into groups of n\nindividuals in each.\n\nIn each group, for each individual, we calculate its\nadaptability and select the most adapted individual.\nWe include this in the intermediate population.\n\nRepeat steps 1 and 2 as many times as necessary.\nThe final intermediate population will be the result\nof this method.\n\nRank-Based Method\n\nThe rank method is similar to the roulette method, only instead of the\nselection probability depending on the value of the individual's objective\nfunction, this method uses the selection probability depending on\n\nthe rank.\n\nThe rank is equal to the number of the individual in the list of\nindividuals in the population, sorted by increasing the value of the\nobjective function.\n\nThe rank filtering algorithm is as follows:\n\n1.\n\nWe calculate the objective function for all\nindividuals in the population.\n\nWe sort the individuals in ascending order of the\nobjective function.\n\nWe number this list and assign each individual this\nnumber, which is called a rank.\n\nWe match the rank to the value of the selection\nprobability function. As a function, you can use\n\na simple linear function of the form y(r) = ar + b,\na<0. Where r - is a rank, a and b - are free operator\nparameters.\n\n5. Using the roulette method and using the\nprobabilities from the previous step, we select the\nrequired number of individuals.\n\nThe main advantage of rank selection is the elimination of early\nstagnation of the genetic algorithm, since the method helps preserve\npopulation diversity.\n\nElitism-Based Method\n\nThis method is based on two steps. At the first step, the required number\nof best individuals is guaranteed to be selected. At the second stage, the\nmissing quantity of copies is selected using any of the mentioned filtering\nmethods. There are modifications of this algorithm when the second\nstep does not select individuals from the remaining ones but generates\nnew ones based on one of the initialization algorithms for the initial\npopulation.\nThe intermediate population may include, for example, 10% of the best\nindividuals, and the remaining 90% are selected using the roulette method.\nThe main advantage of this method is that it guarantees the\npreservation of one or more of the fittest individuals.\n\nClipping Method\n\nThe clipping method is a type of filtering method based on elitism. It\n\nsets the threshold for the value of the objective function g. We sort the\n\npopulation individuals in descending order of their objective function\n\nvalue. We randomly select an individual whose fitness is greater than the\n\nthreshold value g. We repeat the operation the required number of times.\nOf course, this method can be modified, and individuals can be\n\nselected not by a random method but, for example, by the roulette method.\n\nThe main disadvantage of this method is the fact that there is a high\nprobability that individuals with the highest adaptability will not end up in\nthe intermediate population.\n\nCrowding Method\n\nThe crowding method is based on the removal of close individuals from a\npopulation. For these purposes, the value of the function that determines\nthe measure of proximity of individuals is used. For example, for these\npurposes, you can use the Euclidean norm.\n\nv (s82)= (x. -x,)\n\nThe algorithm of this method is as follows:\n\n1. Fora population, we form a matrix of distances\nbetween individuals of the population with the\nvalues of the proximity measure y(5;, sz).\n\n2. We select a cell in this matrix with the minimum\nvalue of the proximity measure and, with equal\nprobability, exclude individual s, or s, from the new\npopulation.\n\n3. We continue to repeat step 2 until the required\nnumber of individuals remains in the population.\n\nThis method can be modified. For example, we could use tournament\nselection, where groups are formed not randomly but based on the values\nof proximity measures.\n\nIn addition to the considered methods of forming a population in two\nstages, like this:\n\nS(t) S'(t) > S(t+1)\n\nit makes sense to consider the possibility of forming a population in\nthree stages, like this:\n\nS(t) > S'(t) > S\"(t) > S(t+1)\n\nS(#) is an auxiliary population created, for example, using some\nmutation operator. Or maybe it makes sense to use different filtering\nmethods both times.\n\nSelection Operators\n\nThe purpose of these operators is to select from a population pair of\nindividuals to be crossed. The basic principle of selection operators is\nthat the probability of selecting the fittest individuals increases with the\nincreasing population number.\n\nThe vast majority of selection operators are based on an assessment of\nthe fitness of individuals. Figure 6-10 shows examples of the dependence\nof the probability of selection on the fitness value of an individual.\n\nVieule\n\nf(z) f(x) f(z) f(x)\nb c\n\nFigure 6-10. Examples of the dependence of the srobabilt of\nselection on the fitness value of an individual\n\nThe sampling function in Figure 6-10a corresponds to proportional\nsampling.\n\nIn the case of the function in Figure 6-10b, individuals with average\nfitness scores have an equal chance of being selected as individuals\nwith high fitness scores. Selection operators of this type slow down the\nconvergence of the algorithm or the improvement in the average fitness of\nthe population in favor of a more complete exploration of the search space.\nThat is, the balance between intensity and breadth is shifted in favor of\nbreadth.\n\nFigure 6-10c shows the opposite situation: individuals with average\nfitness have a significantly lower probability of selection compared to\nindividuals with high fitness, which increases the convergence of the\nalgorithm but reduces the diversity of the population.\n\nThe nature of the function presented in Figure 6-10d allows the\nadvantages of the two previous operator implementations to be combined.\nIn most cases, two individuals are used for crossing. To select them,\nyou can use filtering operators, with a given target number of individuals\n\nequal to 2. But there are also several specific selection operators.\n\nPanmixia Method\n\nThe essence of the method is a random, equally probable selection of\nparental individuals. The main feature of the method is that one individual\ncan end up in several parental pairs. The method is simple to implement\nand quite effective. A well-known disadvantage of this method is its\ndegradation with increasing population size. As the population size\nincreases, the effectiveness of this method and the algorithm as a whole\ndecreases.\n\nThe method algorithm looks like this:\n\n1. We assign each individual of the population a\n\nprobability of \u201c= is| :\n2. Using the roulette method, we select the first\nindividual for the parent pair.\n\n3. We select the second individual in the same way.\nIf the second individual matches the first, then\n\ntry again.\n\nSelective Selection Method\n\nThis method is based on two conditions.\n\n\u00ab Only those individuals whose fitness is higher than\nor equal to the average fitness of individuals in the\npopulation become parents.\n\n\u00a2 Allindividuals satisfying the first condition can form\n\npairs with equal probability.\nThe method algorithm is as follows:\n\n1. For each individual in the population, we calculate\nthe value of the objective function.\n\n2. We calculate the average fitness value of the\npopulation: f .\n\n3. We select individuals from the population whose\n\nfitness is not lower than the average value calculated\nin the previous step.\n\n1\n4. Weassign each individual a probability: # = isj :\n\n5. Using the roulette method, we select a pair of parent\nindividuals.\nBecause of the limitation of individuals who can participate in\n\ncrossing, this method has high convergence, which can lead to early\ntermination of the algorithm in the local minimum zone.\n\nInbreeding\n\nThis selection method is based on two stages. In the first stage, the first\nparent is selected randomly. In the second stage, the selection of the\nparental pair is carried out on the basis of probability, depending on the\nvalue of the measure of proximity to the first individual. The closer the\nindividual is, the more likely it is that it will be chosen as the second parent\nin the pair. The Euclidean norm can be used as a measure of proximity.\n\n\u00a5 (5,582) = you -x,,)\n\nThe algorithm of this method is as follows:\n\n1. Using the panmixia method, we select the first\nparental individual from the population.\n\n2. For all remaining individuals, we calculate the\nmeasure of closeness to the first parent.\n\n3. We assign to each individual a probability\nvalue proportional to the value of the proximity\n\nmeasure: [t= v(s)\nv\n4. Using the roulette method, we select the second\nparent individual based on the values of the\nprobability function calculated in the previous step.\n\nThis method provides high search intensity by quickly dividing the\n\npopulation into separate groups of individuals close to each other.\n\nOutbreeding\n\nThis selection method is based on two stages. In the first stage, the first\nparent is selected using the panmixia method. In the second stage, the\nparental pair is selected based on the probability depending on the value\n\nof the measure of proximity to the first individual. The further away the\nindividual is, the more likely it is that it will be chosen as the second parent\nin the pair. The scheme of the outbreeding method practically coincides\nwith the scheme of the inbreeding method, with the difference that for\neach individual we assign a probability value inversely proportional to the\nvalue of the proximity measure.\n\nue I/y(s,)\n\nIs]\nyal! Wy\n\nThe outbreeding method, as opposed to the inbreeding method,\nprevents early convergence of the algorithm in favor of population\ndiversity and, as a consequence, high diversification of the search.\n\nThe inbreeding and outbreeding methods can be modified by using\nother filtering operators, such as selective selection, to select the first\nindividual. You can also try different formulas for measuring the proximity\nmeasure, which will also affect the operation of the algorithm. It is obvious\nyou can build your own variation of the genetic algorithm based on a\ncombination of several selective selection methods.\n\nRestrictions\n\nMany of the previously discussed mutation and crossover operators\nuse a random variable to create a new individual. This gives rise to the\npossibility that the chromosome of a new individual will go beyond the\npermissible D values.\n\nLet me remind you of formula D, which we used when setting up the\noptimization problem.\n\nD={X| G(X) > 0} is the set of admissible values of the vector X, where\nG(X) is the function limiting the vector, consisting of components g,(X),\n8:(X), ..-, Bic(X).\n\nThere are several options to solve this problem.\n\u00a2 Use operators that generate only valid individuals.\n\n\u00a2 Use algorithms for reducing conditional optimization\nproblems to unconstrained optimization problems.\n\n\u00ab Use special methods developed for evolutionary\nalgorithms.\n\nAlgorithms for reducing a conditional optimization problem to\nunconstrained optimization include the following:\n\n\u00a2 Penalty method\n\n\u00a2 Sliding tolerance method\nSpecial methods include the following:\n\n\u00ab Death penalty\n\n\u00ab Static penalties\n\n\u00ab Dynamic penalties\n\n\u00ab Segregated genetic algorithm\n\n\u00a2 Reduction method\n\n\u00ab Behavioral memory method\n\nSliding Tolerance Method\n\nThe essence of this method is that the condition G(X) > 0 is satisfied with\nsome accuracy. The value X is considered valid if 0 < x(X) < v and invalid if\nK(X) > v.\n\nv=v(t): This is the sliding tolerance criterion\n\ndepending on the iteration number.\n\nx(X): This is the functional defined over all limiting\nfunctions.\n\nThe sliding tolerance criterion should decrease with an increasing\nnumber of iterations t. As the value v decreases, the boundaries of region D\nat which the value is considered acceptable also narrows. As a result, with\na sufficiently high number of iterations, only valid values will be accepted\nfor consideration.\n\nThe functional x(X) must be created in such a way that when X belongs\nto the range of acceptable values D, x(X) = 0. And also the value x(X)\nincreased as the value of X moved away from the nearest boundary of the\nrange of acceptable values.\n\nThe method algorithm looks like this:\n\n1. Using a set of operators, the next generation of\nagents is created without taking into account the\nconditions of D. Next, each of them is tested. If\nx(X) <p, that is, the value is admissible, we assume\nthat the agent is admissible and leave it in the\npopulation.\n\n2. Ifx(X) >\u00bb, that is, the value is unacceptable, then we\nlook for point X \u2019, which lies closer to the boundary\nof the region of acceptable values D. To do this, it is\nnecessary to solve the problem of local\nunconditional optimization. We will talk about these\nalgorithms as little later in this chapter)\nmin\u00ab(Y) = \u00ab(X\") with the termination condition\n\nbeing the expression x(X) < v.\n\n3. When all agents become valid, we move on to the\nnext iteration of the optimization algorithm.\n\nThe main advantage of this algorithm is that the permissible range of\nvalues narrows gradually as it approaches the solution of the optimization\nproblem. In other words, in the first iterations the restrictions are much\n\nsofter compared to the restrictions in the last iterations. This allows you to\nreduce computational resources in the first iterations of searching for the\noptimal solution.\n\nPenalty Method\n\nThe essence of this method is to transform the conditional optimization\nproblem.\n\nmax f(X) = f(X\") = f*\n\nOn the unconstrained optimization problem, we have this:\n\nmax y(X) = max(f(X) + 0(%,2))\n\n#(X, a) is a penalty function whose value increases as X approaches the\nrange of permissible values D.\n\nais the value of the penalty function parameter. The higher it is, the\nfaster the value of the penalty function increases. See Figure 6-11.\n\n#(X,a)\n\nFigure 6-11. Examples of penalty function graphs\n\nFigure 6-11 shows examples of penalty function graphs. It shows\n\nGs > Ay >).\n\nThe penalty function #(X, a) is chosen in such a way that when the\nvalue of X is in the range of acceptable values, the value of the function\ny(X) differs very little from the value of the objective function f(X). This\ndifference grows as X moves away from the range of acceptable values. It is\nworth noting that, despite the penalty functions, the values of X can still go\nbeyond the range of acceptable values and be even more optimal than the\nvalues that satisfy the conditions of D.\n\nIn the general case, the penalty function formula has the\nfollowing form:\n\n6(X,a)= adpl, (s.(\u00a5))\n\na: This is a vector of penalty function parameters.\n\np: This is a vector of coefficients that allows you to change the influence\nof an individual component X on the final value of the penalty function.\n\nL(gX)): This is a functional over the limiting function. Typically the\nformula for this functionality looks like this:\n\n{ree =0 G(x)20\nL(g(X)) >0 G(X) <0\n\nThis formula shows that if X is in the region of acceptable values, then\nthe value of the penalty function is equal to zero. As soon as X leaves this\nregion, then the value of the functional begins to become greater than zero.\n\nIt would be logical to use the distance from point X to the nearest\nboundary of the region of permissible values D to calculate L. But\noften calculating this distance is a difficult task. Therefore, the other\nfunctionality is used more often.\n\nL3(9j(X)) = (e(X))?\n\n0 @xr0\n= {oun ace\n\nAs a result, the algorithm of the penalty function method looks\nlike this:\n1. We create an initial population X\u00b0 and set the initial\nvalues of the parameters of the penalty function a, p.\n\n2. Using a set of operators, we generate a new set of\nindividuals X\u2019.\n\n3. We calculate the values of the unconditional\noptimization function for it.\n\n4. Using a set of operators, we again generate a new set\nof individuals X'\"*'.\n\n5. We check the conditions of restrictions. If the\nconditions are met and the condition for ending the\nsearch is met, then we consider that we have found\nthe optimal solution and stop searching. Otherwise,\naccording to some rule, we increase the values of\nthe parameters (those genes that went beyond the\npermissible values) and again proceed to step 4.\n\nThe criterion for ending the search for an unconstrained optimization\nproblem is most often the criterion for ending the search for conditional\noptimization.\n\nThe main disadvantage of this method is the significant complication\nof the function being optimized, which is the price to pay for eliminating\nrestrictions.\n\nDeath Penalty\n\nThis method is based on simply discarding invalid individuals.\nThe algorithm for this method is as follows:\n\n1. The operator is executed, resulting in a new\nindividual s.\n\n2. The new individual is checked for admissibility; that\nis, a check is made to check the restrictions G(X) > 0.\n\n3. Ifthe individual successfully passes the test, then\nit remains in the new population. If not, then it is\ndiscarded and goes to step 1.\n\nIn this approach, there is a high risk that this algorithm will go in\ncycles; that is, each newly generated individual at the first step will not be\nwithin the range of acceptable values.\n\nWhen the set of admissible values of the objective function is a\nmultidimensional parallelepiped, then the check at step 2 is reduced\nto checking each gene of the individual s\u2019 separately using the formula\n\nxj\" Sx/Sx\" If we are talking about an operator that changes only\ncertain genes, then it is enough to discard the invalid gene and repeat the\ncalculations of the operator again.\n\nThe disadvantage of this method is the need to repeatedly apply the\noperator, although perhaps not to all genes, but to some of them.\n\nStatic Penalties\n\nThe peculiarity of this method is that it takes into account not how strongly\nthe restrictions were violated but how many of them were violated.\nThe penalty function for this method is as follows:\n\n6(X)=6-LG\n\na\n\nbis the free method parameter. It is a large positive number.\n\nThe value of the modified objective function in this case is calculated\nusing the following formula:\n\n10 ~ {03\u00b0 eke\n\nThe free parameter b must be chosen in such a way that the value\nof the objective function for values outside the acceptable range is\nsignificantly less than for acceptable values.\n\nThe main disadvantage of this method is that it does not take into\naccount how many boundaries of permissible values were violated but\ntakes into account the total number of their violations.\n\nDynamic Penalties\nThe penalty function for this method is as follows:\n\n(x) =(at! $6.00)\n\na, b, c: These are free method parameters:\nL{g{X)): This function is calculated by the following formula:\n\n_fo 9X) 20\nuatX)= {Tay HH) 0\nA special feature of the dynamic penalty method is that the penalty\nincreases with the number of generations t. Recommended values for free\nparameters a, b, c are a = -0.5, b = 2.0, c= 2.0.\n\nSegregated Genetic Algorithm\n\nThis algorithm uses not one but two penalty functions: \u00a2,(X), \u00a2,(X). The\ngoal of this algorithm is to try to avoid penalty functions that are too large\nor too small.\n\nThe sequence of steps of this algorithm is as follows:\n\n1. For each individual s of the population, we calculate\nthe values of both penalty functions: #,(X), \u00a2.(X).\n\n2. We sort each of the values #,(X), \u00a22(X) in\nascending order.\n\n3. We combine these lists into one sorted array of\nlength 2|S| and remove the last |S| terms so that the\nlength of the remaining part becomes equal to |S|.\nThe remaining members will correspond to the\nindividuals that violated the limits of acceptable\nvalues to the least extent.\n\n4. We apply genetic operators to the resulting\npopulation to obtain a new population, S'*'.\n\nThe problem with this method is the lack of clear recommendations on\nthe choice of penalty functions: #,(X), \u00a2.(X).\n\nReduction Method\n\nThe reduction method is based on the use of the reducing function r(X),\nwith the help of a transformation of an unacceptable individual s~ to an\nadmissible s\u2019. The individual s' obtained in this way is called restored.\n\nThere are a large number of different reducing functions. Let's look at\nthe mutation operator as an example. Suppose that as a result of applying\nthis operator to a valid individual, the parent s has mutated some of the\ngenes so that the descendant s~ is invalid.\n\ns = (hy hs hs Mragry oy Wags Pigs Mess os h,), where the overline of a gene\nis a symbol of its mutation.\n\noa ue\n\nFigure 6-12. The operator of projecting a point onto a\nmultidimensional parallelepiped\n\nPlease note that the reconstructed individual s\u2019 can be taken both from\npoint X, and from point X, .\n\nBehavioral Memory Method\n\nThe idea of this method is to gradually connect restrictions. That is, the\nmore iterations completed or the more populations created, the more\nrestrictions are connected.\n\nThe algorithm for this method is as follows:\n\n1. When a certain number of iterations is reached, we\nadd the first constraint.\n\n2. Using one of the already discussed methods of\ntaking into account restrictions, we ensure that\nthe majority of individuals in the population are\nacceptable.\n\n3. After a certain number of iterations, we activate the\n\nCr ae\n\nFigure 6-12. The operator of projecting a point onto a\nmultidimensional parallelepiped\n\nPlease note that the reconstructed individual s\u2019 can be taken both from\npoint X, and from point X, .\n\nBehavioral Memory Method\n\nThe idea of this method is to gradually connect restrictions. That is, the\nmore iterations completed or the more populations created, the more\nrestrictions are connected.\n\nThe algorithm for this method is as follows:\n\n1. When a certain number of iterations is reached, we\nadd the first constraint.\n\n2. Using one of the already discussed methods of\ntaking into account restrictions, we ensure that\nthe majority of individuals in the population are\nacceptable.\n\n3. After a certain number of iterations, we activate the\nsecond constraint.\n\n4. Again, using one of the methods of taking into\naccount restrictions, we ensure that the majority of\nindividuals in the current population are acceptable\nunder two conditions.\n\n5. And so on until all the conditions of the restrictions\nare taken into account.\n\nLocal Unconstrained Optimization Algorithms\n\nThe goal of these algorithms is to quickly search for a local extremum of\nthe objective function.\n\nThis is necessary at the last stage of optimization to improve the best\nindividuals. When the parameter values of these agents serve as starting\npoints for local search algorithms, this allows you to achieve even better\nresults from the genetic algorithm.\n\nThese methods are also used in some constraint accounting\nalgorithms. We looked at one of these methods: sliding tolerance method.\n\nThere are three classes of stochastic local search algorithms: single-\npoint/one-step, multistep algorithms, and multipoint algorithms.\n\nOne-Step Algorithms\n\nIn general, the formula for the one-step random search (RS) algorithm is as\nfollows:\n\nX= Xx*4)*D*\n\nkis a positive number meaning the step size in the random\ndirection D*.\n\nIn its simplest form, the sequence of actions in a one-step local search\nalgorithm looks like this:\n\n1. We randomly or otherwise select a starting point in\nthe range of acceptable values.\n\n2. Randomly select direction D*.\n3. We step toward this direction by the amount 4\u2018.\n\n4. Ifthe condition f(X**') > f(X*) is met, then we\naccept a new point and repeat all steps, but with the\nexact X**!; otherwise, we return to point 1, using\npoint X*.\n\nOf course, in the general case, the determination function X**! is\nnot such a simple linear function but rather represents a more complex\ndeterministic or stochastic function of the following form:\n\nxe =0(Xx* D')\n\nSelecting the Search Direction\n\nThe random line search (RLS) algorithm was proposed by\nH. J. Bremermann in 1970. The components of the direction vector D\u00ab\naccording to this algorithm are determined by the following formula:\n\nd, = +U(0;1)\n\nThat is, each component of the vector can be equally distributed\nbetween three numbers: -1, 0, and +1.\n\nThe step size according to the RLS algorithm is determined by the\nfollowing formula:\n\nA\u2018=a max (xy xf\")\n\nxf\" 4 xy\" : This creates the boundaries of the range of\n\npermissible values.\n\nIn the SDPS algorithm, the step is reduced according to the following\nformula:\n\nke \u2014k\n\nA= hy Te\n\nAg: This is the initial step size; it is a free parameter.\n\nk=; This is the maximum number of iterations.\n\nk: This is the current iteration number.\n\nObviously, according to this method, the step will decrease as it\napproaches the optimal value of the objective function\n\nAccording to the adaptive maxing random search (AMRS) algorithm,\nstep size A should be calculated in two stages. At the first stage, the\nmaximum permissible value 4,,,.. is determined, which ensures the\nadmissibility of all points of the form X**! = X* + AmaD.\n\nAt the second stage, the step is calculated as a random variable located\nin the area U(0, 2,,q,)- In this method, as in SDPS, the step decreases as the\noptimal value of the objective function is approached.\n\nOne of the classic algorithms that demonstrates the operation of one-\nstep algorithms is the return algorithm when a step fails.\n\nTo obtain a new approximation, it uses a standard formula of the\nfollowing form:\n\nx = x' + A\u2018D*\nThe algorithm diagram looks like this:\n\n1. We set the starting point X\u2019, as well as the initial\nvalues of the free parameters: 4\u00b0, which is the initial\nstep length; #, which is the maximum number of\nunsuccessful attempts (it is recommended to set\nthis value equal to |X|); and 7, which is a step 2\nreduction factor.\n\nIn the SDPS algorithm, the step is reduced according to the following\nformula:\nkn\" \u2014k\n=\n\nLady\n\nAq: This is the initial step size; it is a free parameter.\n\nk=; This is the maximum number of iterations.\n\nk: This is the current iteration number.\n\nObviously, according to this method, the step will decrease as it\napproaches the optimal value of the objective function\n\nAccording to the adaptive maxing random search (AMRS) algorithm,\nstep size A should be calculated in two stages. At the first stage, the\nmaximum permissible value 4,,,.. is determined, which ensures the\nadmissibility of all points of the form X**! = X* + AmaD.\n\nAt the second stage, the step is calculated as a random variable located\nin the area U(0, 2,,,)- In this method, as in SDPS, the step decreases as the\noptimal value of the objective function is approached.\n\nOne of the classic algorithms that demonstrates the operation of one-\nstep algorithms is the return algorithm when a step fails.\n\nTo obtain a new approximation, it uses a standard formula of the\nfollowing form:\n\nx = x + A\u2018 DS\nThe algorithm diagram looks like this:\n\n1. We set the starting point X\u2019, as well as the initial\nvalues of the free parameters: 4\u00b0, which is the initial\nstep length; #, which is the maximum number of\nunsuccessful attempts (it is recommended to set\nthis value equal to |X|); and 7, which is a step A\nreduction factor.\n\n2. Set the initial value of the counter of failed\nattempts as j=1.\n\n3. Using some algorithm, we calculate the vector D\u2018.\nFind the current value of X* and the value of the\nobjective function f(X*).\n\n4. Ifthe condition f(X**') > f(X*) is satisfied, then go to\nstep 2. If not, then go to the next step.\n\n5. Ifj<, thenj =j+1, and go to step 2. If not, then go\nto the next step.\n\n6. We check the search end condition. If the condition\n\nis met, then we stop the calculations; if not, then we\nsetd =n and go to step 2.\n\nFigure 6-13 illustrates how this algorithm works.\n\nFigure 6-13. Extremum search trajectory\n\n6. Ifthe condition f(X**') > f(X*) is not met, then\nwe make j attempts to increase the value of the\nobjective function by changing the search direction;\nif this does not lead to a result, then we reduce the\nstep length and go to step 2.\n\nFigure 6-14 shows the operation of this algorithm.\n\n0 zy\n\nFigure 6-14. Representations of how the algorithm works\n\nMultipoint Algorithms\n\nThe idea of this group of algorithms is to use not one point, but several, to\nfind the optimal value of the objective function.\n\nSimplex or Complex Algorithm\n\nComplex is a polyhedron with n>(|X|+1) vertices.\nIn its enlarged form, the algorithm is constructed from several steps.\n\n1. Generation of the complex\n2. Reflection of the top of the complex\n\n3. Compression of the complex\n\n6. Ifthe condition f(X**') > f(X*) is not met, then\nwe make j attempts to increase the value of the\nobjective function by changing the search direction;\nif this does not lead to a result, then we reduce the\nstep length and go to step 2.\n\nFigure 6-14 shows the operation of this algorithm.\n\n0 Pal\n\nFigure 6-14. Representations of how the algorithm works\n\nMultipoint Algorithms\n\nThe idea of this group of algorithms is to use not one point, but several, to\nfind the optimal value of the objective function.\n\nSimplex or Complex Algorithm\n\nComplex is a polyhedron with n>(|X|+1) vertices.\nIn its enlarged form, the algorithm is constructed from several steps.\n\n1. Generation of the complex\n2. Reflection of the top of the complex\n\n3. Compression of the complex\n\nGeneration of the complex\nThis operation must be carried out using any one-step local\noptimization algorithm.\n\n1. Choose a starting point.\n\n2. We generate the required number of\nvertices of the complex using the formula\n\nX'=x\u00b0 aa +AD . In this formula ||D||\n\nis the norm of the vector D, which means that the\nconstruction DI has unit length and parameter D\nserves as a direction indicator.\n\nFigure 6-15 demonstrates the complex generation process.\n\nT24\n\n0\n\nFigure 6-15. Complex generation\n\nReflection of the top of the complex\n\nThe purpose of this step is to reflect the vertex X\u2019 of complex C through\nthe center of gravity. Usually they reflect the vertex with the worst value of\nthe objective function. In the resulting complex C\u2019, all vertices, the edge of\n\nthe i-th, coincide with the corresponding vertices of the original complex C.\nThe i-th vertex is on a straight line passing through vertex X' and the center\nof gravity of complex C.\n\nThe formula for calculating the reflected vertex is as follows:\n\nX=X_+4(X,-Xx')\n\nAis the coefficient of stretching of the complex. It is a free algorithm\nparameter. Of course, this parameter can be adaptive. So, for example,\nyou can decrease the value of this as the number of iterations increases.\nOr you can increase it if there is no significant increase in the value of the\nobjective function.\n\nThe center of gravity can be determined by the following formula:\n\nle\nX, =o\n\nAccording to this formula, the center of mass of the complex is the\narithmetic mean of all vertices of the complex. The logic for determining\nthe center of mass can be complicated by introducing significance\ncoefficients for the vertices, depending on the values of the objective\nfunction. Thus, if some of the vertices have values of the objective function\nthat are much better than the values of the remaining vertices of the\ncomplex, then the center of mass will be shifted toward them.\n\nIt is worth noting that this procedure is carried out several times.\n\nFigure 6-16 shows an example of how vertex flipping works.\n\n22 22 e\nxy \u201c\nx}\n' * Xuus x?\nxv \u2018 4\n\u00b0X} x?\n3\n> > >\n0 7% 60 ZO Eat\n\nFigure 6-16. Trajectory of change of the complex\n\nCompression of the complex\n\nThis step is similar to the complex stretching step. It also involves\nreflection of the vertex X' of complex C through the center of gravity. But in\nthis case, the formula for obtaining a new vertex is as follows:\n\nX=X_+B(X,-X')\n\nAis the free parameter of the algorithm. This is the so-called\ncompression ratio. It must be less than 1.\nAsimplified algorithm of the method complex looks like this:\n\n1. We generate the initial complex C\u2019 from the initial\npoint X\u00b0. To do this, we generate the vertices of the\ncomplex using one or another algorithm.\n\n2. We calculate the values of the objective function at\neach vertex.\n\n3. We reflect the vertex X\u2019 that has the worst value of\nthe objective function and obtain a new vertex x!\nand a new complex C\u2019. We calculate the value of the\nobjective function at the new vertex.\n\n4. Ifthe value of the objective function at the new\nvertex has improved compared to the old vertex,\nthen we compress the complex and proceed\nto step 2.\n\n5. We check the search end condition. If it is satisfied,\nthen we stop the calculations. Otherwise, go\nto step 2.\n\nYou can use the following conditions as search end conditions:\n\n\u00ab The maximum length of a complex edge does not\nexceed the specified solution accuracy.\n\n\u00ab The maximum difference between the values of the\nobjective function at the vertices of the edges of the\ncomplex does not exceed the required accuracy of the\nsolution.\n\nHypersphere Algorithm\n\nThe idea of the hypersphere algorithm is to generate random points evenly\ndistributed over the surface of the hypersphere.\nThe algorithm looks like this:\n\n1. We set the initial point X\u00b0, the initial radius of the\nhypersphere R\u00b0, and the number of points on the\nhypersphere n.\n\n2. We generate n random points X;, uniformly\ndistributed over the surface of a hypersphere of\nradius R' with a center at point X'.\n\n3. We calculate the value of the objective function at\nall points obtained and find the point at which this\nvalue is the best.\n\n4. Using any of the single-point optimization\nalgorithms, we find the maximum of the objective\nfunction in the direction (X/-X') using the\nformula *\"\u201d =max(X\" +A(X} -x')).\n\n5. Wecheck the search end condition. If it is satisfied,\nthen we stop the calculations. Otherwise, we set\nthe point X'*'as the center of the sphere and go\nto step 2.\n\nAs with any optimization algorithm, there are many variations for\nthis one. For example, you can change the radius of the hypersphere as it\napproaches the optimal value. You can also not search for the minimum of\nthe objective function in the direction (X/ \u2014 X\u2018) but perform a step with a\ngiven length. Some generate points on the hypersphere not uniformly, but\nrandomly in a certain sector.\n\nThe radius of the hypersphere can be used as a criterion for ending the\nsearch; it should not be less than the specified accuracy of the solution.\n\nRandom Search Algorithms\n\nThis group of algorithms makes significant use of random variables to\nfind a local extremum. This group of algorithms can also be used to find\nthe global optimal value of the objective function and generate the first\ngeneration of genetic algorithm.\n\nMonte Carlo Algorithm\n\nThis algorithm can rightfully be considered the ancestor of all other\nrandom search algorithms. It is often used to generate starting points for\nother more complex algorithms.\n\nIt consists of several steps.\n1. Set the final number of iterations n and set t=1.\n\n2. Using any random number generator, we generate\nthe point X\"*' and calculate the value of the\nobjective function at it. Increase t by one t=t+1.\n\n3. Ifthe number of iterations t exceeds the maximum\nnumber of iterations n, then we stop the\ncalculations. Otherwise, repeat step 2.\n\nSimulated Annealing Algorithm\n\nOne of the oldest algorithms that has proven its effectiveness in solving\nmany problems. The idea of the algorithm was based on a mechanism for\ncorrecting defects in the crystal lattice of metals.\n\nDefects in the crystal lattice of a metal are often caused by the fact that\nsome of the atoms occupy incorrect (nonoptimal) positions. At normal\ntemperature, they do not have enough kinetic energy to overcome the\npotential barrier and take the correct position; that is, the crystal lattice is\nin a state of local energy minimum. To overcome the barrier and bring the\nsystem from a local minimum to a global one, the system is heated. In this\ncase, atoms occupying the wrong position acquire energy and can take the\ncorrect places. In this case, as the metal cools, the atoms lose energy, and\nthe system again stabilizes in a state of local minimum.\n\nIf this analogy is applied to optimization theory, then each local\nminimum can be considered as a defective crystal lattice. Improvement\nof the solution occurs due to periodic changes in the found solution, the\nintensity of which decreases as it approaches the optimal solution.\n\nThe main difference between this algorithm and others is that it allows\nperiodic deterioration of the solution to the optimization problem.\n\nThe algorithm diagram looks like this:\n\n1. Weset the starting point X\u00b0, and \u00e9 - is a positive\nthreshold, which will decrease as the iterations\nof the algorithm increase. It represents a random\nvariable with a mathematical expectation. This gives\nmeaning to the temperature of the annealed metal.\n\n2. We randomly generate a new value in the vicinity of\nthe current approximation X\"*! = w(X\u2019).\n\n3. The solution X'*' becomes a new approximation\nwith a probability determined by the formula\n\n1 pest\nON = {ea-2 Ly piisgt\n\nRandom Restarts Algorithm\n\nRandom search algorithms have one big drawback: they require a large\n\nnumber of tests. This algorithm belongs to the class of two-phase random\n\nsearch algorithms. Such algorithms include two search phases: global\n\nphase and local phase. The goal of the first phase is to generate a certain\n\nnumber of random points. The second phase consists of using local search\n\nalgorithms, where the starting point is the point formed in the first stage.\nThe general scheme of this algorithm is as follows:\n\n1. Set the total number of starting points n.\n2. Generate coordinates of point X\u2019.\n\n3. Using point X' as the initial point, we find the local\nextremum using one of the previously presented\nlocal search algorithms.\n\n4. Ifthe number of starting points is less than n, then\nwe return to step 2; otherwise, we complete the\ncalculations.\n\n262\n\nThe danger of this approach is that some local solutions may be found\nmany times, while others may not be found at all.\n\nIterated Local Search\n\nThe idea of this algorithm is to use perturbation of the previous solution\nfound instead of generating starting points randomly. The problem with\nthis approach is that it is necessary to overcome the local extremum zone.\nOtherwise, the local search algorithm will return to this extremum again.\nTherefore, on the one hand, perturbation should be strong enough, but it\nshould not be too strong. Otherwise, this algorithm will differ little from\nthe random restarts algorithm.\n\nThe sequence of actions of the iterated local search algorithm is as\nfollows:\n\n1. We generate a random initial value X\u00b0 belonging to\nthe range of acceptable values.\n\n2. Iuse point X\u2018 as the starting point; using any local\nsearch algorithm we find the solution x!.\n\n3. Perturbate point x! and get point X'*'.\n\n4. Ifthe condition for ending the search is met, then\nwe stop the calculations; otherwise, we return\nto step 2.\n\nPerturbation\n\nThe perturbation procedure can be built on the basis of any population\nalgorithm. Often a genetic algorithm is used for these purposes. There\nare also a large variety of perturbation implementation options based on\nalgorithms using random variables.\n\nThe main thing is that perturbation meets the following requirements:\n\n+ It must be strong enough to overcome the area of\nattraction of the current local extremum.\n\n\u00ab It doesn\u2019t have to be completely random.\n\n\u00a2  Itcanuse the history of solutions found.\n\nSummary\n\nIn this chapter, you learned the basics of population algorithms, in\nparticular the genetic algorithm. I showed the logic of a number of\noperators of this algorithm, which will help create the first version of a\nlibrary of optimization algorithms.\n\nIt is worth noting that the genetic algorithm is far from the only\nalgorithm from the population class.\n\nAlso, to solve the problem of searching and optimizing profitable\nstrategies, algorithms such as the particle swarm optimization algorithm,\nthe artificial immune systems algorithm, and many others are of interest.\nThe implementation of these algorithms, as well as an increase in\nthe number of operators used, can be considered a growth point for\nour system.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 7,
                "chapter_name": "CHAPTER 7",
                "chapter_path": "./screenshots-images-2/chapter_7",
                "sections": [
                    {
                        "section_id": 7.1,
                        "section_name": "Implementation\nof Optimization\nAlgorithms",
                        "section_path": "./screenshots-images-2/chapter_7/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_7/section_1/deb35620-ec49-49f8-89a0-74759be1f28d.png",
                            "./screenshots-images-2/chapter_7/section_1/25bb9138-6ca5-460f-a3fc-3e61bfb8e564.png",
                            "./screenshots-images-2/chapter_7/section_1/b861759c-7e8d-40a9-bde3-c505750f959b.png",
                            "./screenshots-images-2/chapter_7/section_1/379d7296-055f-45c0-bdac-7831b8535e59.png",
                            "./screenshots-images-2/chapter_7/section_1/7abeb184-93ea-4829-b614-49002b55d39c.png",
                            "./screenshots-images-2/chapter_7/section_1/78221898-fe1f-4d9b-9254-3859463cd264.png",
                            "./screenshots-images-2/chapter_7/section_1/fa91f90e-65c7-45f7-9d16-c7dc6070ce16.png",
                            "./screenshots-images-2/chapter_7/section_1/b7fb5052-e6aa-4c82-b76d-dcdc57dbaf5c.png",
                            "./screenshots-images-2/chapter_7/section_1/353b3407-83a0-4fbe-8ca0-4d31e4c215b7.png",
                            "./screenshots-images-2/chapter_7/section_1/7abe4b02-aeaa-4ee4-9a65-87137eaa84e4.png",
                            "./screenshots-images-2/chapter_7/section_1/1fd22f10-c3b6-4d68-a2df-4ec66cf4633f.png",
                            "./screenshots-images-2/chapter_7/section_1/7a1d5983-2779-4486-ad88-a5d540856d78.png",
                            "./screenshots-images-2/chapter_7/section_1/3ef6e0ce-505b-42b7-947c-ceb2aa75d33e.png",
                            "./screenshots-images-2/chapter_7/section_1/4aae1be8-8cc6-4efe-b444-1726f72dc443.png",
                            "./screenshots-images-2/chapter_7/section_1/4f9a3d8e-661e-4171-ad92-6187cfda962b.png",
                            "./screenshots-images-2/chapter_7/section_1/4c83776c-882e-420d-8f9f-0154eccd5af5.png",
                            "./screenshots-images-2/chapter_7/section_1/fd57dfe7-68ad-4cdc-b18d-1819875e67a3.png",
                            "./screenshots-images-2/chapter_7/section_1/4702aadd-163d-46fd-bd42-52d3b5daaef1.png",
                            "./screenshots-images-2/chapter_7/section_1/73d6c2cb-d55f-45e2-a2ca-ba33a65c1eb6.png",
                            "./screenshots-images-2/chapter_7/section_1/275ebfe6-ea49-4168-b676-53241e97feca.png",
                            "./screenshots-images-2/chapter_7/section_1/775b71c1-afdf-4645-8128-eb0cad49464c.png",
                            "./screenshots-images-2/chapter_7/section_1/a0b40d70-d2c6-4f8f-85d9-2875301eaf60.png",
                            "./screenshots-images-2/chapter_7/section_1/b6371807-26aa-45ab-859e-f7361271bbe9.png",
                            "./screenshots-images-2/chapter_7/section_1/c3e2a46a-673d-4d7f-925b-3c6bf8212739.png",
                            "./screenshots-images-2/chapter_7/section_1/82a7811d-640e-4f90-8134-6d4ecce9e392.png",
                            "./screenshots-images-2/chapter_7/section_1/524c3eff-b0b8-40ba-b181-b56887efce97.png",
                            "./screenshots-images-2/chapter_7/section_1/ab7e3e6f-79dc-4f4f-94dc-d57236828a44.png",
                            "./screenshots-images-2/chapter_7/section_1/6de48b4b-18e4-4004-bef6-5b9bde24b2bf.png",
                            "./screenshots-images-2/chapter_7/section_1/4a66be9b-79f5-4291-b990-fb0f77559b4f.png",
                            "./screenshots-images-2/chapter_7/section_1/3ba6bcab-528f-4bf0-9a0f-09a4e085224d.png",
                            "./screenshots-images-2/chapter_7/section_1/c684a25b-1ee6-46a0-a376-addee54730c7.png",
                            "./screenshots-images-2/chapter_7/section_1/0bf1740a-1df3-41ec-81c0-ac0bb607ab82.png",
                            "./screenshots-images-2/chapter_7/section_1/60292ad9-b438-4331-9be5-d11cc7f6ee48.png",
                            "./screenshots-images-2/chapter_7/section_1/d594be96-9d81-4d25-bb5c-ac21fb7eea71.png",
                            "./screenshots-images-2/chapter_7/section_1/ad30bc7f-d959-4e4d-ba0b-f4e6e1b39014.png",
                            "./screenshots-images-2/chapter_7/section_1/96e795e3-2c22-447a-a946-cf1093492fd5.png",
                            "./screenshots-images-2/chapter_7/section_1/5ee66d79-d93a-4e0f-9e4f-ce2d3ea50417.png",
                            "./screenshots-images-2/chapter_7/section_1/42e239b2-915f-4601-a79e-f02fb24592a4.png",
                            "./screenshots-images-2/chapter_7/section_1/829df3d5-762a-4373-9c68-fa664b484eb1.png",
                            "./screenshots-images-2/chapter_7/section_1/d93f1788-e962-47a4-80ee-48325bc5b1c2.png",
                            "./screenshots-images-2/chapter_7/section_1/eeef5310-125b-477c-83c8-caf529f95c77.png",
                            "./screenshots-images-2/chapter_7/section_1/c3d56a05-8395-4ff1-b0e7-d76242df06c9.png",
                            "./screenshots-images-2/chapter_7/section_1/e66317e4-588d-4e6d-abe8-86dfd6618294.png",
                            "./screenshots-images-2/chapter_7/section_1/c6594f75-d1e5-40b9-ba72-daf68da0169b.png",
                            "./screenshots-images-2/chapter_7/section_1/286c3601-1ad1-4613-ade1-bec726a6d059.png",
                            "./screenshots-images-2/chapter_7/section_1/f195619f-8599-4e6d-88c4-5c450e4981d0.png",
                            "./screenshots-images-2/chapter_7/section_1/649a672e-99ae-460a-b1fb-55d5feda8f79.png",
                            "./screenshots-images-2/chapter_7/section_1/5cbd0746-406e-4f2f-ad8e-31f0517b13fc.png",
                            "./screenshots-images-2/chapter_7/section_1/caa50732-3d4c-467a-9427-361375fdb19c.png",
                            "./screenshots-images-2/chapter_7/section_1/76c5613f-4f22-4425-8a4f-ee2612c9d7a6.png",
                            "./screenshots-images-2/chapter_7/section_1/919a8669-c552-4e71-bdcb-8a9709294622.png",
                            "./screenshots-images-2/chapter_7/section_1/dea514aa-a07c-4943-99a4-9b467ab982aa.png",
                            "./screenshots-images-2/chapter_7/section_1/b5639758-59df-4724-8639-3671de75a8e4.png",
                            "./screenshots-images-2/chapter_7/section_1/5a6c1b12-1509-4acf-8b81-1f638aedafe1.png",
                            "./screenshots-images-2/chapter_7/section_1/d61829bf-8593-423c-a773-20223f373a9d.png",
                            "./screenshots-images-2/chapter_7/section_1/4564648f-70b3-46d8-9a61-3e1e65f3d4ac.png",
                            "./screenshots-images-2/chapter_7/section_1/3b312896-19c3-4a4c-87bf-28388d2b53e1.png",
                            "./screenshots-images-2/chapter_7/section_1/7d55a6b3-0fea-4900-87ba-a43d0c35e0bc.png",
                            "./screenshots-images-2/chapter_7/section_1/273b329f-b6cd-4aea-932a-a838878bec2a.png",
                            "./screenshots-images-2/chapter_7/section_1/77cd569f-c984-449a-8cbc-95ec2b2b2ed2.png",
                            "./screenshots-images-2/chapter_7/section_1/08ba82bf-8e8e-4886-9801-7406cd1f4af6.png",
                            "./screenshots-images-2/chapter_7/section_1/1bf68b25-b53c-4566-94b9-f72de4f97d9c.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In the previous chapter, I covered the theory of constructing optimization\nalgorithms. We looked at what genetic algorithms are and from which\noperators they can be constructed. In this chapter, the time has come to\nput this information together to create a library that will become one of the\nimportant modules of the system for searching for profitable strategies.\n\nAs with building any module or service, creating this will consist of\nseveral steps.\n\n1. Write a description of use cases. This step is\nnecessary to understand what functionality will be\nincluded in the new library and how it will be used.\n\n2. Make a list of the required functionality.\n3. Implementit.\n\nIn this chapter, I plan to first talk to you about my expectations of the\noptimization algorithms module and describe my general vision.\n\nAfter this, we will implement the simplest optimization algorithm,\nnamely, the brute-force algorithm. Since it is simple, when implementing\n\nit, most of our effort will be on creating the foundation of the module.\nImplementing a mechanism that includes new optimization algorithms\nwill not affect library users.\n\nOnce the foundation is ready, we will begin implementing the genetic\nalgorithm.\n\nI am using a framework to implement .NET, but that does not mean\nthis chapter will be useful only to those who already know or are interested\nin .NET. I could have used any other popular language and framework with\nequal success. The ideas discussed in this chapter will be useful to any\nperson who has decided to create their own trading system, regardless of\nthe chosen programming language.\n\nI hope that after reading this chapter you will have enough information\nand ideas to create your own library of optimization algorithms.\n\nGeneral View\n\nIn the previous chapter, much attention was paid to the fact that\noptimization algorithms are not a list of clearly defined rules but rather\nideas for constructing your own algorithms. If we take the genetic\nalgorithm as an example, many operators have been developed for it,\non the basis of which you can implement a large number of your own\nvariations of the genetic algorithm.\n\nAnd since the list of optimization algorithms is not limited and each of\nthem is unique and has its own list of settings and parameters, this means\nthat the optimization algorithm in the service for finding a profitable\nstrategy will be an entity.\n\nI see the scenario for creating an optimization algorithm as follows:\n\n1. The user opens a special form for creating an\noptimization algorithm in the UI part of the\napplication.\n\n2. The user possibly enters the name of the new\nalgorithm.\n\n3. The user selects the type. In this chapter, we\nimplement only two types of algorithms: brute-force\nalgorithm and genetic algorithm.\n\n4. The user configures operator types or other options.\n5. The user sets the values of free parameters.\n6. The user saves the result.\n\nWhat does the module of optimization algorithms have to do with\nthis? After all, it will not contain a UI or even a database. But pay attention\nto steps 3, 4, and 5. Where will the application get the list of available\nalgorithm types? What about the types of operators and the list of free\nparameters for them? All this information will have to be provided by the\noptimization algorithms module.\n\nHere we have highlighted the first functionality that the module must\nimplement.\n\nFunctional requirement: Return all necessary information for creating\nand configuring variations of optimization algorithms.\n\nLet's say the user created a new optimization algorithm or changed\nan existing one. How will he understand that his algorithm is efficient\nenough? Of course, it makes sense to perform a preliminary check by\ntesting it on some simple subtheory with a small number of optimized\nparameters and on a not too large period of historical data, but is this\nenough? In addition, even such testing will take time and may not reveal\nall the advantages or disadvantages of the new optimization algorithm.\n\nAll this leads to the need to create a different way to test the\neffectiveness of algorithms. And there is such a way. It is based on training\nalgorithms on special mathematical functions. Of course, this method\ndoes not give an absolute result. As was correctly noted in the previous\nchapter, the problem of finding optimal parameter values is completely\n\nunformalized. That is, it does not have any mathematical model. This\nmeans it is impossible to find a training mathematical function that is\nremotely similar to this.\n\nBut we know that it is multi-extremal and has a range of permissible\nvalues, which is a multidimensional parallelepiped. This knowledge\nallows us to test the performance of the algorithm on multi-extremal\nmathematical functions with or without the addition of a range of\nacceptable values.\n\nFunctionality requirement: Provide functionality that allows you to test\nthe created algorithm on training mathematical functions.\n\nFrom the fact that using the module it is possible to optimize not only\nstrategies, but also mathematical functions, another requirement follows.\nFunctional requirement: The module must be independent of the\n\ncontext in which it is used.\n\nThis means that for the algorithms embedded in the module, there\nshould be no difference between the optimization of the candle interval\n(1 min, 5 min, 1 h, and so on) for calculating the indicator of one of the\nconditions of the signal to buy the strategy and the value of one of the\ncomponents of the vector X of the three-dimensional function of Hartman.\n\nSo, using the optimization algorithms module, the user was able to\ncreate a new algorithm and test its operation on mathematical functions,\nafter which he selected the new algorithm in the settings of the theory\ngenerator and clicked the generate button. Next, the theory is generated,\nand on its basis a subtheory is created, which uses this algorithm to create\nand test strategies.\n\nLet\u2019s imagine that the user has chosen a brute-force algorithm, and\naccording to the subtheory settings, there are several thousand variants\nof strategies, each of which needs to be tested. Should the algorithm\nimmediately return several thousand variants of parameter values? Of\ncourse not. First, saving and queuing thousands of strategies at once is\nnot a good idea, because something can go wrong in the middle of this\nprocess.\n\nSecond, there is a possibility that the user may change his mind and\nstop the calculation. Then it will turn out that a large number of strategies\nand tasks will be created in vain and will only waste space in the database.\nThis means that it makes sense for the module to provide variations in\nparameter values in portions.\n\nThe iterative nature of most optimization algorithms also speaks in\nfavor of chunkiness. If we take, for example, a genetic algorithm, then it has\nthe concept of generations, which are also generated sequentially.\n\nFunctional requirement: Generating sets of values for calculating the\nobjective function (calculating strategy indicators) must be an iterative\nprocess.\n\nAs a result, the operation of the module can be represented as a loop,\n\nSetofparams Values 1\nSet of params Values 2\nSetofparams Values N\n\nas shown in Figure 7-1.\n\nSet of params\nSettings\n\nOptimization\nalgorithm\n\nSetofparams | Values1 | Criterion1 |\nSetofparams | Values2 | Criterion 2\nSetofparams ValuesN __Criterion4_|\n\nFigure 7-1. Operation of the optimization module\n\nLet's fix the final list of functionality that is required from the library.\n\n1. Provide all the necessary information to create and\nconfigure variations of optimization algorithms.\n\n2. Amodule must be independent of the context in\nwhich it is used.\n\n3. Generating sets of values for calculating the\nobjective function should be an iterative process.\n\n4. Provide functionality that allows you to test the\ncreated algorithm on training mathematical\nfunctions.\n\nBrute-Force Algorithm\n\nThe essence of this method is to enumerate all the possible options\nfor parameter values. Let's start with the first requirement: provide\ninformation about the algorithm settings. First, let's discuss how the library\nclasses will be used.\n\nI see it this way:\n\n1. The connection will of course be made using\nIServiceCollection. Dependency injection (DI)\nfacilitates testing by allowing dependencies to\nbe replaced with mock implementations. It also\nreduces coupling between modules and promotes\nbetter separation of responsibilities in code. This\nis a generally accepted practice that should not be\nabandoned, even if at first glance it seems that DI is\nnot needed.\n\n2. Ofcourse, enum or its equivalent will be used to\nstore the list of available algorithm types if we need\nmore advanced functionality in the future.\n\n3. All functionality will be embedded in classes\nthat implement the IOptimizationAlgorithm\ninterface. One class will be created for each type of\noptimization algorithm.\n\n4. To obtain an instance of a class that implements an\nalgorithm, you need to contact the factory, which\nwill match the type of the algorithm with the desired\nclass and generate its instance.\n\nLet's get started. Listing 7-1 shows an implementation of an extension\nto IServiceCollection. Here I use functionality that was implemented in\nthe latest version of .NET 8 Keyed Services. The idea is to be able to add a\nnamed implementation of an interface. I use one of the enum elements as\nthe key.\n\nListing 7-1. Adding Dependencies\n\npublic static IServiceCollection AddOptimizationAlgorithms (this\nIServiceCollection services)\n\n{\nservices .AddSingleton<AlgorithmFactory>();\nservices\n-AddKeyedTransient<10ptimizationAlgorithm,\nBruteForceAlgorithm>(\nAlgorithmTypes .BruteForce) ;\nreturn services;\n}\n\nI connect the factory as a singleton because this class is stateless, so I\ndon\u2019t see the need to generate a new instance every time I get an instance\nfrom the collection. But lOptimizationAlgorithm will be Transient,\nbecause it will store the necessary settings for calculating the next portion\nof parameter values.\n\nListing 7-2 shows the implementation of the function that gets an\ninstance of an algorithm in the AlgorithmFactory class.\n\nListing 7-2. GetOptimizationAlgorithm Function\n\npublic I0ptimizationAlgorithm GetOptimizationAlgorithm(\nAlgorithmTypes type)\n\nreturn _serviceProvider\n-GetRequiredKeyedService<10ptimizationAlgorithm> (type) ;\n\nGetting Info\n\nLet\u2019s take a look at IOptimizationAlgorithm in Listing 7-3, since the first\nstep was to implement the functionality of obtaining information about the\nalgorithm. Now it contains only one function.\n\nListing 7-3. 1OptimizationAlgorithm Interface\n\npublic interface I0ptimizationAlgorithm\n\n{\npublic AlgorithmTypeInfo GetTypeInfo();\n\nThe brute-force algorithm has only one free parameter: the number\nof returned sets of values at each iteration. So, the AlgorithmTypelInfo\nclass looks simple (Listing 7-4), but when we start implementing a genetic\nalgorithm, it becomes much more complex.\n\nListing 7-4. AlgorithmTypelInfo Record\n\npublic record AlgorithmTypeInfo(AlgorithmTypes Type)\n\n{\npublic List<AlgorithmTypeInfo_Param> Params { get; }\n\n= new();\n\npublic record AlgorithmTypeInfo_Param(\nParamTypes Type,\ndecimal DefaultValue) ;\n\nThe information generation function for BruteForceAlgorithm will\nlook like that shown in Listing 7-5.\n\nListing 7-5. GetTypelnfo for Brute-Force Algorithm\n\npublic AlgorithmTypeInfo GetTypeInfo()\n{\nvar info = new AlgorithmTypeInfo(AlgorithmTypes.\nBruteForce) ;\ninfo.Params\n-Add(new AlgorithmTypeInfo_Param(ParamTypes.\nPointsCount, 100));\n\nreturn info;\n\nI've added the PointsCount parameter, so now let's pass it to the class\nthat implements the algorithm. To do this, I created an AlgorithmInfo\nclass, which is very similar to AlgorithmTypeInfo, but instead of\ndefaultValue, you need to fill in the value field.\n\nYou also need to add the Init() function to the\nI0ptimizationAlgorithm interface and call it in the factory. Listing 7-6\nshows the modified code in the AlgorithmFactory class. I made both\nfactory methods public. One creates an algorithm for the purpose of\ncalculation, and the other creates the necessary information.\n\nListing 7-6. GetOptimizationAlgorithm Function\n\npublic I0ptimizationAlgorithm GetOptimizationAlgorithm(\nAlgorithmInfo info,\nList<FunctionVariable> functionVariables)\n\n{\nI0ptimizationAlgorithm optimizationAlgorithm =\nGetOptimizationAlgorithm(info. Type) ;\noptimizationAlgorithm. Init(info, functionVariables) ;\nreturn optimizationAlgorithm;\n}\n\npublic I0ptimizationAlgorithm GetOptimizationAlgorithm(\nAlgorithmTypes type)\n{\n\nreturn _serviceProvider\n.GetRequiredKeyedService<I0ptimizationAlgorithm> (type) ;\n\nListing 7-7 demonstrates the implementation of the Init function of\nthe BruteForceAlgorithm class.\n\nListing 7-7. Init Function\n\npublic void Init(AlgorithmInfo info, List<FunctionVariable>\n\nfunctionVariables)\n{\n_pointsCount =\n(int)info.Params\n-First(p => p.Type == ParamTypes.\nPointsCount) .Value;\n\n_functionVariables = functionVariables;\n\nLet's take a look at the FunctionVariable type, which is a\nrepresentation for a function parameter. It is the set of these parameters\nthat the optimization module must optimize. Listing 7-8 shows my\nimplementation of this class.\n\nListing 7-8. FunctionVariable Record\n\npublic record FunctionVariable\n\n{\npublic IVariableId Id { get; }\n\npublic decimal? MinValue { get; }\npublic decimal? MaxValue { get; }\npublic decimal? Step { get; }\n\npublic List<decimal>? Values { get; }\n\npublic FunctionVariable(\nIVariablelId id,\ndecimal minValue,\ndecimal maxValue,\ndecimal step)\n\n{\nId = id;\nMinValue = minValue;\nMaxValue = maxValue;\nStep = step;\n\n}\n\npublic FunctionVariable(IVariableId id,\nList<decimal>? values)\n\n{\n\nId = id;\nValues = values;\n\nFirst, pay attention to the type of the Id field. Imagine a scenario where\nan application works with a library. The service for searching for optimal\nstrategies based on subtheory must generate an array of these parameters.\nThen the library returns sets of these parameters with values. How will\nthe application understand which signal, condition, and indicator this\nparameter belongs to? It would be possible to make this field as a string in\nwhich the application encoded the necessary information, for example, in\nJSON format. But what if some algorithm needs to sort these identifiers or\nsome other action is needed? It\u2019s just that the string most likely will not be\nable to provide us with a sufficient level of functionality.\n\nAt this point, the IVariableld interface looks pretty simple.\n\ninterface IVariableId: IEquatable<IVariableId>\n\nIimmediately added IEquatable<IVariableId> because\nimplementations of this interface will probably have to be compared with\neach other.\n\nPlease note that I have significantly simplified the range of acceptable\nvalues of the objective function, leaving only min, max parameters or a\nlist of values, because this library is created to find profitable strategies,\nso I believe that I cannot implement more complex scenarios of limiting\nfunctions in it. Pay attention to the two constructors; they ensure data\nintegrity. In one case, the list of values will be filled, and in the other, the\nboundaries of possible values will be filled. This mechanism could be\nimplemented by using inheritance, where one type would implement a\nvariable with restrictions and another with a list of values.\n\nGetting a Set of Values\n\nIt's time to implement a method for getting sets of values. Listing 7-9 shows\n\nmy implementation of this function.\n\nListing 7-9. GetNextPoints Function\n\npublic IEnumerable<AlgorithmPoint> GetNextPoints(\n\nList<ObjectiveFunctionResult>? previousResults)\n\nList<AlgorithmPoint> allPoints = GetPoints();\nIEnumerable<AlgorithmPoint> nextPoints = allPoints\n-Where(allPoint =>\npreviousResults == null\n|| !previousResults.Exists(r => r.Point ==\nallPoint))\n-Take(_pointsCount) ;\nreturn nextPoints;\n\nThere is nothing complicated about the function itself. Of interest\nis the AlgorithmPoint class and the comparison operator r.Point ==\n\nallPoint. Listing 7-10 shows an implementation of this class.\n\nListing 7-10. AlgorithmPoint Class\n\npublic class AlgorithmPoint\n\n{\n\npublic List<FunctionVariableValue> Values { get; } = new();\n\npublic static bool operator ==(AlgorithmPoint? a,\nAlgorithmPoint? b)\n\n{\nif (ReferenceEquals(a, b))\n\nreturn true;\n\nTable 7-1. Variables Example\n\nId Min max step\n1 1 2 1\n\n2 10 20 10\n3 100 200 100\n\nThen the algorithm will look like this:\n\n1. Take all possible values of variable 1. Obviously,\nthis has only two possible values: 1 and 2. Create a\ntemplate from these two values. Get an array of two\ntemplates.\n\n2. Take the first template [1, ...] and \u201cexpand\u201d it to the\nvalues of the second variable. Get the patterns: [1,\n10, ...] and [1, 20, ...].\n\n3. Take the pattern [1, 10, ...] and expand it to the\nvalues of the third variable. Get possible sets of\nvalues: [1, 10, 100] and [1, 10, 200].\n\n4. Repeat steps 2 and 3 until all unfilled templates are\nexhausted.\n\nThe idea of recursion is that steps 2 and 3 are no different from each\nother; they can be replaced by a function that receives a list of templates\nas input and then takes an unused variable, \u201cexpands\u201d the templates, and\ncalls itself again, and so on until as long as there is an unused variable.\n\nThe call tree will look like Figure 7-2.\n\nTable 7-1. Variables Example\n\nId Min max step\n1 1 2 1\n\n2 10 20 10\n3 100 200 100\n\nThen the algorithm will look like this:\n\n1. Take all possible values of variable 1. Obviously,\nthis has only two possible values: 1 and 2. Create a\ntemplate from these two values. Get an array of two\ntemplates.\n\n2. Take the first template [1, ...] and \u201cexpand\u201d it to the\nvalues of the second variable. Get the patterns: [1,\n10, ...] and [1, 20, ...].\n\n3. Take the pattern [1, 10, ...] and expand it to the\nvalues of the third variable. Get possible sets of\nvalues: [1, 10, 100] and [1, 10, 200].\n\n4. Repeat steps 2 and 3 until all unfilled templates are\nexhausted.\n\nThe idea of recursion is that steps 2 and 3 are no different from each\nother; they can be replaced by a function that receives a list of templates\nas input and then takes an unused variable, \u201cexpands\u201d the templates, and\ncalls itself again, and so on until as long as there is an unused variable.\n\nThe call tree will look like Figure 7-2.\n\nList<AlgorithmPoint> points = GetPoints(template) ;\nresult .AddRange(points) ;\n}\n\nreturn result;\n\nFunctionVariable? GetRemainderVariable()\n\n{\nforeach (FunctionVariable functionVariable in _\nfunctionVariables)\n{\nif (!pointTemplate! .Values\n-Exists(v => v.Id.Equals\n(functionVariable.Id)))\nreturn functionVariable;\n}\nreturn null;\n}\nIEnumerable<AlgorithmPoint> GetTemplates()\n{\n\nList<decimal> values = remainderVariable.GetValues();\nvar templates = new List<AlgorithmPoint>();\nforeach (decimal value in values)\n{\nAlgorithmPoint newTemplate = new AlgorithmPoint();\nnewTemplate. Values\n\u00abAdd(new FunctionVariableValue(remainder\nVariable.Id, value));\n\nforeach (FunctionVariableValue item in\npointTemplate. Values)\n\nList<AlgorithmPoint> points = GetPoints(template) ;\nresult .AddRange(points) ;\n}\n\nreturn result;\n\nFunctionVariable? GetRemainderVariable()\n\n{\nforeach (FunctionVariable functionVariable in _\nfunctionVariables)\n{\nif (!pointTemplate! .Values\n-Exists(v => v.Id.Equals\n(functionVariable.Id)))\nreturn functionVariable;\n}\nreturn null;\n}\nIEnumerable<AlgorithmPoint> GetTemplates()\n{\n\nList<decimal> values = remainderVariable.GetValues();\nvar templates = new List<AlgorithmPoint>();\nforeach (decimal value in values)\n{\nAlgorithmPoint newTemplate = new AlgorithmPoint();\nnewTemplate. Values\n\u00abAdd(new FunctionVariableValue(remainder\nVariable.Id, value));\n\nforeach (FunctionVariableValue item in\npointTemplate. Values)\n\nnewTemplate.Values\n-Add(new FunctionVariableValue(item. Id,\nitem.Value)) ;\n}\n\ntemplates .Add(newTemplate) ;\n}\n\nreturn templates;\n\nThe condition for exiting recursion is the fact that the algorithm no\nlonger finds unused variables, that is, when the remainderVariable\nvariable is equal to null. Of course, this algorithm is far from optimal, but\nit is easy to understand. You can store hashes of used variables in some\nvariable and not loop through all sets of variables each time. But I tried to\nimplement an algorithm that is understandable to everyone. If your skills\nand knowledge allow you to optimize it, then that\u2019s great!\n\nHow to Use\n\nSo, BruteForceAlgorithm has been implemented. Let's try to connect our\nlibrary and see if itis convenient to use. Listing 7-12 presents the simplest\nimplementation of the algorithm.\n\nListing 7-12. Example of Using the Algorithm\n\nvar services = new ServiceCollection();\nservices .AddOptimizationAlgorithms() ;\nServiceProvider provider = services. BuildServiceProvider();\n\nAlgorithmFactory algorithmFactory = provider.GetRequiredService\n<AlgorithmFactory>();\n\nAlgorithmInfo info = new(AlgorithmTypes.BruteForce) ;\ninfo.Params.Add(new AlgorithmInfo_Param(ParamTypes.\nPointsCount, 2));\n\nList<FunctionVariable> functionVariables = new();\nfunctionVariables.Add(new FunctionVariable(new\nVariableId(\"First\"), 1, 2, 1));\nfunctionVariables.Add(new FunctionVariable(new\nVariableId(\"Second\"), 10, 20, 10));\nfunctionVariables.Add(new FunctionVariable(new\nVariableId(\"Third\"), 100, 200, 100));\n\nI0ptimizationAlgorithm? algorithm = algorithmFactory.\nGetOptimizationAlgorithm(info, functionVariables) ;\nList<ObjectiveFunctionResult>? previousResults = new();\n\nList<AlgorithmPoint> points = algorithm!.\nGetNextPoints(previousResults) .ToList();\nList<(int step, List<AlgorithmPoint>)> result = new();\nint step = 0;\nwhile (points.Any())\n{\n\nresult.Add((step, points));\n\nstep++;\n\npoints\n-ForEach(p => previousResults.Add(new\nObjectiveFunctionResult(p, 1)));\n\npoints = algorithm! .GetNextPoints(previousResults).\nToList();\n\nIn this code, I created an algorithm that returns sets of values of 2.\nAlso, the target function contains variables as in the example we discussed\nearlier. As a result, this piece of code will return the following result:\n\nStep | First | Second | Third |\nfo | [10 | 100 |\nlo 1 | | 20 |\nla | | 20 | 200 |\n1 |a [20 | 200 |\n}2 12 | | 100 |\n1212 | 10 | 20 |\n13 12 120 | 100 |\n\nOf course, work on the implementation of this algorithm is far from\nfinished, because the library does not have a single test. But I will leave\ntesting this code outside the scope of the book to focus your attention on\nthe main thing.\n\nGenetic Algorithm\n\nIt\u2019s time to implement the genetic algorithm. We already have the\nfoundation of the library. Let\u2019s build a new algorithm into this. I will recall\nits main aspects. This is one of the population algorithms, the idea of\nwhich is based on the creation of several independent agents (population),\nwhich, according to some logic, migrate across the range of acceptable\nvalues in search of the optimal value of the objective function.\n\nThe general scheme of any population algorithm is as follows:\n\n1. According to some logic, an initial population or\nfirst set of agents is generated.\n\n2. The agent migration process is in progress. If we\ntake the genetic algorithm into consideration, then\nfor it the migration process is presented as a set\nof operators. During the migration process, a new\npopulation or the next set of agents is generated.\n\n3. The search completion conditions are checked. If\nthis is done, then the calculations stop. Otherwise,\ngo to step 2.\n\nThe most interesting and difficult part of creating this algorithm is the\nmigration process. As mentioned earlier, for genetic algorithms, it looks\nlike a set of operators.\n\nThese are the types of operators:\n\n\u00ab Mutation. The idea of this operator is to use some\nalgorithm to change the values of the agent's genes and\nthereby create a new population. That is, the result of\nthis operator is the creation of a new population.\n\n\u00ab Crossover. In this operator, two agents (individuals)\nare crossed using some algorithm, resulting in the\ncreation of one or more agents. This operator also\nentails the emergence of a new population.\n\n\u00a2 Selection. This operator does not entail the creation\nof new agents, but it is necessary for selecting pairs\nfor the crossover operator. It turns out that you cannot\napply the crossover operator until you use the selection\noperator.\n\n\u00a2 Filtering. This operator is necessary for selecting\nthe fittest individuals. It does not entail the creation\nof a new population but filters the old one so that\npoorly adapted individuals do not participate in other\noperators in the future.\n\nSteps\n\nIna general sense, a genetic algorithm is not some kind of strict set of rules\nbut rather a set of instructions with which you can construct as many of\nyour own variations of optimization algorithms as you want. It was this\nknowledge that prompted me to create the concept of the step. Each step\nwill have its own type, order, and set of parameters, as well as a list of child\nsteps. I have identified four types of steps for myself.\n\n1. Initialization. At this stage, the first population is\ncreated.\n\n2. Mutation. In this step, a mutation operator is\napplied to the current population.\n\n3. Filtering. At this step, a filtering operator is applied\nto the current population.\n\n4. Breeding. This step contains two steps: Selection\nStep and Crossing Step. I found it inappropriate to\nseparate these two steps into two different units\nbecause you can\u2019t cross without first selecting.\n\nThe idea is that you can construct your own algorithms using and\ncombining steps 2, 3, and 4 in any number and in any order. For example,\nthanks to this architecture, you can create an algorithm like this:\n\n1. Initialization. An initial population is created\nusing the flat operator. That is, agents are created\nuniformly over the entire range of acceptable values.\n\n2. Mutation. The mutation is performed using the\nrandom operator.\n\n3. Breeding. Using the panmixia method for selection,\nwe produce the crossovering fuzzy operator.\n\n4. Filtering. We filter the current population using the\nelitism-based method.\n\n5. Mutation. This happens using the gauss operator.\n6. And so on. This list can go on forever.\n\nIn this book I will show the simplest implementation of this algorithm,\nso I will implement the simplest condition for ending the search: by the\nnumber of iterations. It turns out that the algorithm itself will have only\none parameter equal to the number of generations.\n\nGetting Info\n\nLet's start the implementation with the GetTypeInfo method. Obviously,\nthe genetic algorithm class itself should not know anything about what\nparameters are needed for each of the steps.\n\nThis means that these are the steps:\n\n1. The GetTypelnfo method of the GeneticAlgorithm\nclass will call the GetTypeInfo method of all\navailable step types.\n\n2. Youneed to create an JAlgorithmStep interface with\nthe GetTypelnfo function. It turns out that each step\nwill be a class that implements this interface.\n\n3. Since each step will have its own parameters, it\nis necessary to implement a factory that will help\ncreate a step of each type.\n\nSince the concept of steps and their sequences appeared, it is\nnecessary to change the AlgorithmInfo and AlgorithmTypelnfo types.\n\nListing 7-13 presents a new implementation of the AlgorithmTypeInfo\ntype. In this case, I added the AllowedSteps field, because now each\nalgorithm can contain steps.\n\nListing 7-13. AlgorithmTypelnfo Record\n\npublic record AlgorithmTypeInfo(AlgorithmTypes Type)\n{\npublic List<AlgorithmTypeInfo_AllowedStep> AllowedSteps {\nget; } = new();\npublic List<AlgorithmTypeInfo_Param> Params { get; }\n= new();\n\nListing 7-14 shows an implementation of the AlgorithmTypeInfo_\nAllowedStep type. Note that the constructor has an Index parameter. The\npoint is that we need to somehow indicate that a certain step is mandatory\nand also indicate its sequence number in advance. This concerns the\ninitialization phase. This is mandatory and should always come first. I\n\ndidn\u2019t create a separate type for the step parameters because I think the\nAlgorithmTypeInfo_Param type I created earlier is perfect for this task.\n\nListing 7-14. AlgorithmTypeInfo_AllowedStep Record\n\npublic record AlgorithmTypeInfo_AllowedStep(StepTypes Type,\nint? Index)\n\n{\npublic List<AlgorithmTlypeInfo_Operator> AllowedOperators {\nget; } = new();\npublic List<AlgorithmTypeInfo_AllowedStep> Steps { get; }\n= new();\npublic List<AlgorithmTypeInfo_Param> Params { get; } = new();\n}\n\nThe AlgorithmTypelInfo_Operator class, shown in Listing 7-15,\nincludes only a set of parameters and a type.\n\nListing 7-15. AlgorithmTypeInfo_Operator Record\n\npublic record AlgorithmTypeInfo_Operator(OperatorTypes Type)\n{\n\npublic List<AlgorithmTypeInfo_Param> Params = new();\n\n}\n\nListing 7-16 demonstrates the [Algor ithmStep interface. For now\nthere is only one function in this, but as the functionality expands, this will\nalso grow.\n\nListing 7-16. LAlgorithmStep Interface\n\npublic interface IAlgorithmStep\n\n{\npublic AlgorithmTypeInfo_ AllowedStep GetInfo();\n\n}\n\nSince we have a new set of classes, we somehow need to add them\nto the collection and create a factory for them. I don\u2019t want the central\npart of the library to know anything about the steps and their presence\nin the algorithm, so I created my own implementation of the extension\nfor IServiceCollection for each algorithm. Listing 7-17 presents a new\nimplementation of the AddOptimizationAlgorithms function. As you\ncan see, now work with IServiceCollection is hidden in each of the\nalgorithms, which is very convenient.\n\nListing 7-17. Adding Dependencies\n\npublic static IServiceCollection AddOptimizationAlgorithms(this\nIServiceCollection services)\n\n{\nservices .AddSingleton<AlgorithmFactory>();\nservices .AddBruteForceAlgorithm() ;\nservices .AddGeneticAlgorithm() ;\nreturn services;\n\n}\n\nListing 7-18 shows an implementation of the AddGeneticAlgorithm\nmethod. In it add the GeneticAlgorithm class, a factory for creating steps\nand all the step classes.\n\nListing 7-18. AddGeneticAlgorithm Dependencies\n\npublic static IServiceCollection AddGeneticAlgorithm(this\nIServiceCollection services)\n{\nservices\n-AddKeyedTransient<I0ptimizationAlgorithm,\nGeneticAlgorithm>(\n\nAlgorithmTypes.Genetic) ;\nservices .AddSingleton<StepFactory>();\n\nservices\n-AddKeyedTransient<IAlgorithmStep , BreedingStep>(\nStepTypes . Breeding) ;\nservices\n-AddKeyedTransient<IAlgorithmStep , FilteringStep>(\nStepTypes. Filtering) ;\nservices\n-AddKeyedTransient<IAlgorithmStep, InitializationStep>(\nStepTypes. Initialization) ;\nservices\n-AddKeyedTransient<IAlgorithmStep , MutationStep>(\nStepTypes .Mutation) ;\n\nreturn services;\n\nNow that we have the steps already added to the IServiceCollection,\nit's time to implement the GetTypeInfo method in the GeneticAlgorithm.\nListing 7-19 shows my implementation. I added one parameter that\ncontrols the number of generations. Please note that this is the number\nof generations, not populations. I did this on purpose because many\nsteps, such as mutation, will generate a population. I call a generation the\ncomplete passage of the algorithm through all steps. The interesting thing\nabout this code is how I implemented obtaining information for all steps. I\ntook all the classes that implement the IAlgorithmStep interface and one\nby one called their methods for obtaining information.\n\nListing 7-19. GetTypeInfo Method\n\npublic AlgorithmTypeInfo GetTypeInfo()\n\n{\nvar info = new AlgorithmTypeInfo(AlgorithmTypes.Genetic) ;\n\ninfo. Params .Add(\nnew AlgorithmTypeInfo_Param(ParamTypes.\nGenerationsCount, 10));\n\nIEnumerable<IAlgorithmStep> steps =\n_stepFactory.GetAll();\n\nforeach (IAlgorithmStep step in steps)\ninfo.AllowedSteps.Add(step.GetInfo());\n\nreturn info;\n\nLet's dive into the implementation of the GetInfo functions of each of\nthe steps. Obviously, to obtain complete information about the step, it is\nnecessary to obtain information for each of the implemented operators.\nThis means that another I0perator interface is needed. Moreover, each\nstep will have its own, because the purpose and functionality of each of\nthem differs.\n\nLet's start with InitializationStep. For this step I implemented two\nstatements: FlatOperator and FlatManagedOperator.\n\nThe idea of FlatOperator is to uniformly distribute a predetermined\nnumber of initial individuals over the range of acceptable values.\n\nFlatManagedOperator is very similar to FlatOperator, but it does\nnot specify the size of the initial population but rather a percentage of the\nmaximum possible number of individuals.\n\nI won't bore you with showing the implementation of the\nInitializationStepCollectionExtensions and OperatorFactory\nclasses, because their code is very similar to the code implemented earlier.\n\nListing 7-20 shows my implementation of the Get Info method of the\nInitializationStep class. The only interesting thing about this code\nis that I immediately define the order for this step. This means this step\nshould always come first and cannot be skipped.\n\nListing 7-20. Get Step Function\npublic AlgorithmTypeInfo_AllowedStep GetInfo()\n\n{\nAlgorithmTypeInfo_AllowedStep info = new(StepTypes.\nInitialization, 0);\nIEnumerable<IOperator> operators = _operatorFactory.\nGetAl11();\nforeach (IOperator @operator in operators)\n\ninfo.AllowedOperators .Add(@operator.GetInfo());\n\nreturn info;\n\n}\n\nNext, in each of the statements, I implemented the GetInfo method\napproximately, as shown in Listing 7-21.\n\nListing 7-21. Get Operator Info Function\n\npublic AlgorithmTypeInfo_Operator GetInfo()\n{\nvar @operator = new AlgorithmTypeInfo_\nOperator (OperatorTypes.Flat) ;\n@operator. Params .Add(\nnew AlgorithmTypeInfo_Param(ParamTypes.\nPopulationSize, 10));\n\nreturn @operator;\n\nI think we can stop here. I hope the information I gave you will be\nenough to implement the GetInfo method for the remaining steps and\ntheir operators.\n\nGetting a Set of Values\n\nLet's move on to the central function of this algorithm, namely, the\nGetNextPoints function. First, let's decide on the sequence of actions.\nLet's imagine that a user has designed the following genetic algorithm:\n\n\u00ab Initialization\n\n\u00ab Mutation\n\u00ab Filtering\n+ Breeding\n\u00ab Filtering\n\nThe stopping condition will be the creation of GenerationsCount\ngenerations.\n\nSo, the application calls the GetNextPoints method of our algorithm\nin a loop, gets a new list of sets of values to calculate, calculates the\nobjective function values for each of them, and calls the GetNextPoints\nmethod again. This continues until GetNextPoints returns an empty list of\nvalue sets.\n\nObviously, to count the number of generations, the optimization\nalgorithm needs to know what generation and step it is at the next time\nGetNextPoints is called. It would be logical to store this counter in the very\ninstance of the class that implements the optimization algorithm. But you\ncan\u2019t do this, because in reality several instances of the application will be\nraised, one for each pod. And if so, then there will be several instances of\nclasses.\n\nWe cannot guarantee that GetNextPoints will be called by only one\nspecific instance of the class. Also, do not forget that the pod can cease to\nexist at any time and then the application will lose information about the\ncurrent generation and step, which is unacceptable. There are two options\nleft: store information about the current generation somewhere in external\nstorage, such as Redis or PostgreSQL, or entrust this task to the calling\napplication.\n\nI really don\u2019t like both options; in the first one our library forces the\napplication to use a certain kind of storage, and in the second one we\nexpose some implementation details of the library.\n\nI chose the second option. That is, I entrusted the storage of\ninformation to the calling application. But at the same time, I tried to\nmake this information as impersonal as possible in order not to disclose\nimplementation details and to allow other algorithms to use this field.\n\nListing 7-22 demonstrates how I changed the GetNextPoints function\nof the IOptimizationAlgorithm interface.\n\nListing 7-22. GetNextPoints Function\n\n(List<AlgorithmPoint> points, string? magicString)?\nGetNextPoints(\nList<ObjectiveFunctionResult>? previousResults = null,\nstring? magicString = null);\n\nAs you can see, I added the magicString parameter. Great name, isn\u2019t\nit? This is returned every time the GetNextPoints method is called. The\ncalling application must save it and then pass it back as a parameter the\nnext time the function is called.\n\nListing 7-23 demonstrates my implementation of the MagicData class\nfor a genetic algorithm. It shows that magicString is a JSON string into\nwhich the class instance is parsed.\n\nListing 7-23. MagicData Class\n\npublic class MagicData\n\n{\npublic int GenerationNumber { get; set; }\npublic int StepIndex { get; set; }\npublic MagicData(string? jsonString = null)\n{\nif (jsonString != null)\n{\nMagicData? obj = JsonSerializer\n.Deserialize<MagicData>(jsonString) ;\nif (obj == null)\nthrow new ArgumentException(nameof(jsonString)) ;\nGenerationNumber = obj.GenerationNumber;\nStepIndex = obj.StepIndex;\n}\n}\npublic MagicData(){}\npublic override string ToString()\n{\nreturn JsonSerializer.Serialize(this) ;\n}\n}\n\nLet's go through all the steps:\n\n1. The first call to GetNextPoints occurs.\npreviousResults = null, magicString =\nnull. We deserialize magicString and get\nGenerationNumber=0, StepIndex=0.\n\nWe get an instance of the Initialization class of the\nstep, because StepIndex = 0.\n\nWe turn to the method for obtaining a list of sets of\nvalues of this step and obtain the following points or\nthe current population.\n\nWe get the identifier of the next step, write\nGenerationNumber=0, StepIndex=1 in magicData\nand return all the information to the calling method.\n\nGetNextPoints is called. We were returned a certain\nset of previousResults and GenerationNumber=0,\nStepIndex=1.\n\nWe get an instance of the step Mutation class,\nbecause StepIndex = 1. To get the next population,\nyou need to pass the current population to the\nmutation step method so that it can mutate all\nagents using the selected operator.\n\nWhen this is the first generation, it is easy to get the current population,\nbut imagine that this is not the first generation. How do you select only the\nnecessary instances from previousResults?\n\nIt is for this purpose that I added the Id field to the\nObjectiveFunctionResult class. And in the MagicData class is the\nPopulationIds field, which contains a list of solution identifiers. An\napplication that will use a library of optimization algorithms will be able to\nprovide this identifier, because in essence ObjectiveFunctionResult is a\nmapping of the Task entity, which of course has an identifier.\n\nLet's continue:\n\nThe Mutation step returned a list of new sets of\nvalues to calculate, which we passed to the calling\nfunction.\n\nBut what's important is that this set of values is not a new generation.\nThe new generation consists of the population obtained in the previous\nstep plus the list of sets obtained in the Mutation step. It is also necessary\nto take into account that the mutation step can create a new generation\nby joining mutated individuals to the previous generation, or it can do\nthis by replacing parents. It turns out that each step must implement two\nfunctions: one to get a list of parameter sets and the second to get a new\npopulation. The first entails transferring control to the calling function so\nthat it can calculate the objective function for new agents, and the second\ngenerates a new population.\n\nThere is another fact that speaks in favor of creating two functions. This\nis the presence of such a step as Filtering. At this step, new agents are not\nformed, but a part of the current population is eliminated, and this is how\nthis step forms a new population.\n\nLet's say the Mutation step now has two functions. One of them\ngenerates a new list of parameter sets, and the second generates a\nnew population. It seems reasonable to first call the function to get\nnew individuals and then get a new population. But this order is not\nconvenient, because after receiving a list of new individuals, it is necessary\nto transfer control to the calling function, which means there can be no\ntalk of a subsequent call to the function for obtaining a new population.\n\nBefore we continue, I would like to draw your attention to one more\npoint. I mentioned that the Mutation step can have the option of replacing\nparents with children, which means that each set of values must have its\nown MagicData. Therefore, I added a field of type string MagicData to the\nAlgorithmPoint class. And I created the PointMagicData class for this.\n\nSince the logic of the algorithm has changed, it\u2019s probably worth\nstarting to describe the steps again.\n\n1. The first call to GetNextPoints occurs.\npreviousResults = null, magicString =\nnull. We deserialize magicString and get\nGenerationNumber=0, StepIndex=0. Based\n\non this data, we obtain the current population\ncurrentPopulation and the results of calculations\nobtained from the previous list of new individuals\ncurrentPreviousResults. Of course, both of these lists\nare empty because we called the function for the\nfirst time.\n\n2. We start the loop with the condition that the list\nof new individuals that need to be returned to\nthe calling function\u2014nextPoints\u2014is empty. On\neach pass of this loop, the algorithm will call the\nfunctions of the next step. Not all steps generate new\nindividuals.\n\n3. In this loop, we get an instance of the current, zero\nstep and call this GetNextPopulation method. This\nmethod does not spawn new individuals, so for\nthe Initialization step, it will always return the list\npassed to it.\n\n4. Next we get the next step. In this logic, we will have\nto make an exception for the Initialization step,\nbecause we cannot get the next step but need to stop\nat the current one.\n\n5. We call the GetNextPoints method of the current\nInitialization step, which, of course, will return new\nindividuals that the function will pass to the calling\nfunction.\n\n6. And soon.\n\nListing 7-24 shows my implementation of the first step of\nthe GetNextPoints method. This code fragment initializes three\nimportant variables: currentMagicData, currentPopulation, and\ncurrentPreviousResults, which will be needed in the loop from step 2.\n\nListing 7-24. Start of GetNextPoints Function\n\npublic (List<AlgorithmPoint> points, string magicString)?\nGetNextPoints(\nList<ObjectiveFunctionResult>? previousResults = null,\nstring? magicString = null)\n\npreviousResults ??= new();\n\nMagicData currentMagicData = new MagicData(magicString) ;\n\nList<ObjectiveFunctionResult> currentPopulation =\nGetCurrentPopulation(currentMagicData,\npreviousResults) ;\n\nList<ObjectiveFunctionResult> currentPreviousResults =\nGetCurrentPreviousResults (currentMagicData,\npreviousResults) ;\n\nListing 7-25 shows a code snippet that implements the loop\nfrom step 2.\n\nListing 7-25. Second Part of GetNextPoints Function\n\nList<AlgorithmPoint>? nextPoints = null;\nvar nextMagicData = new MagicData();\nwhile (nextPoints == null || !nextPoints.Any())\n{\nAlgorithmInfo_ Step currentStepInfo = _info.Steps\n-First(s => s.Index == currentMagicData.StepIndex) ;\nIAlgorithmStep currentStep = _stepFactory\n-GetStep(currentStepInfo, _functionVariables) ;\ncurrentPopulation = currentStep\n-GetNextPopulation(currentPopulation,\ncurrentPreviousResults) ;\n\nnextMagicData.PopulationIds = currentPopulation\n-ConvertAll(i => i.Id);\n\nAlgorithmInfo_Step? nextStepInfo =\n\nGetNextStep(currentMagicData, currentPopulation) ;\n\nbool stoppingConditionFulfilled =\nCheckStoppingCondition(nextStepInfo, currentMagicData,\ncurrentStepInfo) ;\n\nif (stoppingConditionFulfilled)\nreturn null;\n\nnextMagicData.GenerationNumber = currentMagicData.\n\nGenerationNumber;\n\nnextMagicData.StepIndex = nextStepInfo. Index;\n\nif (nextStepInfo! .Index <= currentStepInfo. Index\n\n&& currentPopulation.Any())\nnextMagicData.GenerationNumber++;\n\nIAlgorithmStep nextStep = _stepFactory.\nGetStep(nextStepInfo, _functionVariables) ;\nnextPoints = nextStep\n-GetNextPoints(\ncurrentPopulation,\nnew PointMagicData(\nnextMagicData.GenerationNumber,\nnextMagicData.StepIndex)) ;\ncurrentMagicData = nextMagicData;\n\nIn this piece of code, I do the following:\n\n1. I getinformation about the current step,\ncurrentStepInfo. It is necessary to obtain an instance\nof the class that implements the step.\n\nUsing the factory, I get an instance of the\ncurrentStep step class.\n\nI call the GetNextPopulation method of the current\nstep and save the result to the currentPopulation\nvariable.\n\nSince we now know the identifiers of individuals in\nthe current population, we need to write them into\nour magicData.\n\nI receive information about the next step. In\nListing 7-26, I provided my implementation of the\nGetNextStep method.\n\nBased on the new step index, we can conclude\nwhether this is the next generation or not. This\nmeans we can check the condition for completing\nthe calculations. If the condition has not yet\noccurred, then we continue the calculations.\n\nIf the index of the new step is less than the index\nof the current one, this means that the algorithm\nhas gone through all the steps and will now\nbegin to generate a new generation. This means\nyou can increase the generation number in the\nnextMagicData variable.\n\nThe GetNextPoints method of the new step is\ncalled. If it returns new individuals, then control is\ntransferred to the calling function.\n\nListing 7-26. Implementation of a Method to Get the Next Step\n\nprivate AlgorithmInfo_Step GetNextStep(\nMagicData currentMagicData,\nList<ObjectiveFunctionResult> previousResults)\n\nif (!previousResults.Any())\nreturn _info.Steps.Single(s => s.Index == 0);\n\nAlgorithmInfo_Step? nextStep =\n_info.Steps\n-Where(s => s.Index > currentMagicData.StepIndex)\n-MinBy(s => s.Index) ;\nif (nextStep == null)\nnextStep = _info.Steps\n-Where(s => s.Index > 0)\n-MinBy(s => s.Index) ;\n\nreturn nextStep! ;\n\n}\n\nInitialization Step\n\nLet's implement our first step, namely, the Initialization Step. Let me\nremind you that I plan to implement two operators in this, FlatOperator\nand FlatManagedOperator.\n\nListing 7-27 demonstrates the implementation of the Init function.\nThere is nothing special about this, except that an instance of the operator\nclass is immediately obtained.\n\nListing 7-27. Init Function\n\npublic void Init(\nAlgorithmInfo_Step step,\nList<FunctionVariable> functionVariables)\n\nano\n\nee WX Oe ee\n\n{\n\n_step = step;\n\n_functionVariables = functionVariables;\n\n_operator = _operatorFactory.GetOperator(_step.Operator) ;\n}\n\nThe GetNextPopulation function, as I said earlier, returns the\npreviousResults sent. Listing 7-28 shows a simple implementation of\nthe GetNextPoints method. This is where the Generate operator function\nis called.\n\nListing 7-28. GetNextPoints Function\n\npublic List<AlgorithmPoint> GetNextPoints(\nList<ObjectiveFunctionResult>? population = null,\nPointMagicData? magicData = null)\n\nreturn _operator.Generate(_functionVariables, magicData) ;\n\nLet's start implementing the operators. Let me remind you what their\nlogic is.\n\nThe idea of FlatOperator is to uniformly distribute a predetermined\nnumber of initial individuals over the range of acceptable values.\n\nFlatManagedOperator is very similar to FlatOperator, but it does\nnot specify the size of the initial population but rather a percentage\nof the maximum possible number of individuals. It turns out that in\nboth operators the same function is called to generate individuals; the\ndifference is only in the desired number of new individuals.\n\nListing 7-29 shows the implementation of the Generate method for\nFlatOperator. As you can see, there is practically no logic in this.\n\nlong populationSizeLong = (long)(_coveredPercent / 100 *\nvariablesCount) ;\n\nint populationSize = (int)Math.Min(populationSizeLong, _\nmaxPopulationSize) ;\n\npopulationSize = Math.Max(populationSize, _\nminPopulationSize) ;\n\nreturn populationSize;\n\nI showed you the basic idea of implementing this step. I also laid\ndown a fairly simple architecture for the solution, in which to add a new\noperator. It is enough to add only one class that implements the I0perator\ninterface.\n\nMutation Step\n\nI will show the implementation of this step using the random operator as\n\nan example. The essence of this method is to replace a certain number of\n\nparent genes with random values located in the range of acceptable values.\nListing 7-31 shows an implementation of the method for obtaining\n\na population. It contains a simple logic of combining the previous\n\npopulation with all the mutated individuals. This means that at this step\n\nthe number of individuals always doubles.\n\nListing 7-31. GetNextPopulation for Mutation Step\n\npublic List<ObjectiveFunctionResult>\nGetNextPopulation(List<ObjectiveFunctionResult>\npreviousPopulation,\nList<ObjectiveFunctionResult> previousResults)\n\nlong populationSizeLong = (long)(_coveredPercent / 100 *\nvariablesCount) ;\n\nint populationSize = (int)Math.Min(populationSizeLong, _\nmaxPopulationSize) ;\n\npopulationSize = Math.Max(populationSize, _\nminPopulationSize) ;\n\nreturn populationSize;\n\nI showed you the basic idea of implementing this step. I also laid\ndown a fairly simple architecture for the solution, in which to add a new\noperator. It is enough to add only one class that implements the I0perator\ninterface.\n\nMutation Step\n\nI will show the implementation of this step using the random operator as\n\nan example. The essence of this method is to replace a certain number of\n\nparent genes with random values located in the range of acceptable values.\nListing 7-31 shows an implementation of the method for obtaining\n\na population. It contains a simple logic of combining the previous\n\npopulation with all the mutated individuals. This means that at this step\n\nthe number of individuals always doubles.\n\nListing 7-31. GetNextPopulation for Mutation Step\n\npublic List<ObjectiveFunctionResult>\nGetNextPopulation(List<ObjectiveFunctionResult>\npreviousPopulation,\nList<ObjectiveFunctionResult> previousResults)\n\nList<ObjectiveFunctionResult> nextPopulation = new();\nnextPopulation.AddRange(previousPopulation) ;\nnextPopulation.AddRange(previousResults) ;\n\nreturn nextPopulation;\n\nThe GetNextPoints method presented in Listing 7-32 is also quite\nsimple. In this cycle, all parents undergo a mutation procedure.\n\nListing 7-32. GetNextPoints Function\n\npublic List<AlgorithmPoint> GetNextPoints(\nList<ObjectiveFunctionResult>? population = null,\nPointMagicData? magicData = null)\n\n{\nvar points = new List<AlgorithmPoint>();\nif (population == null)\nreturn points;\nforeach (ObjectiveFunctionResult parent in population)\n{\nAlgorithmPoint mutant = Mutate(parent);\nif (magicData != null)\nmutant .MagicData = magicData.ToString();\npoints .Add(mutant) ;\n}\nreturn points;\n}\n\nListing 7-33 shows an implementation of this procedure.\n\nIt implements the following algorithm:\n\n1. We take all the variables that can contain more than\none value and put them in the changeableVariables\nvariable.\n\n2. After this, we randomly select the required number\nof genes for the mutation procedure.\n\n3. Call the Mutation function of the selected operator\nand replace the parent gene with the resulting value.\n\nListing 7-33. Mutate Function\n\nprivate AlgorithmPoint Mutate(ObjectiveFunctionResult parent)\n\n{\n\nvar mutant = new AlgorithmPoint();\n\nList<IVariableId> changeableVariables = new();\nforeach (FunctionVariable functionVariable in _\nfunctionVariables)\n{\n\nList<decimal> variations = functionVariable.\n\nGetValues();\n\nif (variations.Count>1)\n\nchangeableVariables .Add(functionVariable. Id) ;\n\n}\n\nvar random = new Random();\nList<IVariableId> variablesForMutation =\nrandom.GetList(changeableVariables, _mutationCount) ;\nforeach (var parentVariableValue in parent.Point.Values)\n{\nif (variablesForMutation.\nContains(parentVariableValue.Id))\n\nreturn _operator.GetNextPopulation(previousPopulation) ;\n\nI have implemented two operators for this step.\n\nRoulette Operator\n\nWe discussed this method in detail in the previous chapter. I will just\nremind you of the basic principle. The essence of the method is to present\nindividuals in the form of a roulette wheel, which is divided into sectors.\nEach sector is assigned to a specific individual. The size of the sector\ndepends on the fitness level of the individual.\n\nThe selection algorithm looks like this:\n\n1. For each individual, the probability of its selection is\ncalculated. To do this, take the value of its objective\nfunction and divide it by the sum of the values of all\nindividuals in the population.\n\n2. We divide the interval from 0 to 1 into subintervals\nproportional to the values from step 1.\n\n3. We generate a random number from 0 to 1.\nDepending on which interval it falls in, that\nindividual will be selected.\n\n4. Repeat step 3 as many times as required.\n\nIt follows from the algorithm that this operator has only one free\nparameter: the required population size.\n\nListing 7-35 shows an implementation of the RouletteOperator\u2019s\nGetNextPopulation method. It does not yet have the basic logic of the\nroulette method. I moved this to another class because the roulette method\nwill be used in other operators. Please note that a list of individuals with the\nweight of each of them is passed to the Roulette. Selection method.\n\nreturn _operator.GetNextPopulation(previousPopulation) ;\n\nI have implemented two operators for this step.\n\nRoulette Operator\n\nWe discussed this method in detail in the previous chapter. I will just\nremind you of the basic principle. The essence of the method is to present\nindividuals in the form of a roulette wheel, which is divided into sectors.\nEach sector is assigned to a specific individual. The size of the sector\ndepends on the fitness level of the individual.\n\nThe selection algorithm looks like this:\n\n1. For each individual, the probability of its selection is\ncalculated. To do this, take the value of its objective\nfunction and divide it by the sum of the values of all\nindividuals in the population.\n\n2. We divide the interval from 0 to 1 into subintervals\nproportional to the values from step 1.\n\n3. We generate a random number from 0 to 1.\nDepending on which interval it falls in, that\nindividual will be selected.\n\n4. Repeat step 3 as many times as required.\n\nIt follows from the algorithm that this operator has only one free\nparameter: the required population size.\n\nListing 7-35 shows an implementation of the RouletteOperator\u2019s\nGetNextPopulation method. It does not yet have the basic logic of the\nroulette method. I moved this to another class because the roulette method\nwill be used in other operators. Please note that a list of individuals with the\nweight of each of them is passed to the Roulette. Selection method.\n\nList<ProbabilityElement<T>> probabilityElements =\nGetProbabilityElements(list) ;\n\nvar random = rand ?? new Random();\n\nfor (int i = 0; i < size; i++)\n\n{\n\ndouble u = random.NextDouble() ;\nProbabilityElement<T> nextPoint =\n\nprobabilityElements\n.First(e => u > e.MinInterval && u <=\ne.MaxInterval) ;\nresult.Add(nextPoint.ListElement. Entity) ;\n}\nreturn result;\n}\nElitism Operator\n\nThis method was developed to ensure that the best individuals are\nguaranteed to be included in the new population. It consists of two steps.\nAt the first stage, the best individuals are selected. They are placed on the\nlist of individuals of the new population. The second completely copies the\nroulette method. That is, the missing number of individuals is added to the\nnew population using the roulette method.\n\nBased on this logic, this operator has two parameters: the percentage\nof individuals out of the total number that are considered elite and the\nrequired size of the new population.\n\nListing 7-37 shows an implementation of the\nGetNextPopulation method.\n\nListing 7-37. GetNextPopulation Function\n\npublic List<ObjectiveFunctionResult> GetNextPopulation(\nList<ObjectiveFunctionResult> previousPopulation)\n\nvar individuals = new List<ObjectiveFunctionResult>();\nint eliteCount = (int)(_elitePercent / 100 *\npreviousPopulation.Count) ;\nindividuals .AddRange(\npreviousPopulation\n-OrderByDescending(i => i.Value).ToList()\n-GetRange(0, elitCount-1));\nint remainder = _populationSize - individuals.Count;\n\nList<(ObjectiveFunctionResult Entity, double\n\nProbabilityWeight)> listForRoulette =\npreviousPopulation.ConvertAll(i => (i, (double)\ni.Value)) ;\n\nList<ObjectiveFunctionResult> rouletteIndividuals =\n\nRoulette.Selection(listForRoulette, remainder) ;\n\nindividuals .AddRange(rouletteIndividuals) ;\n\nreturn rouletteIndividuals;\n\nIn Listing 7-37 I first calculate the size of the elite and put that value\ninto the eliteCount variable. After that, I sort the previous population\nin descending order of the value of the objective function and take the\ntop elements in the resulting eliteCount list. After this, I call the roulette\nmethod Roulette.Selection that we previously implemented.\n\nListing 7-37. GetNextPopulation Function\n\npublic List<ObjectiveFunctionResult> GetNextPopulation(\nList<ObjectiveFunctionResult> previousPopulation)\n\nvar individuals = new List<ObjectiveFunctionResult>();\nint eliteCount = (int)(_elitePercent / 100 *\npreviousPopulation.Count) ;\nindividuals .AddRange(\npreviousPopulation\n-OrderByDescending(i => i.Value).ToList()\n-GetRange(0, elitCount-1));\nint remainder = _populationSize - individuals.Count;\n\nList<(ObjectiveFunctionResult Entity, double\n\nProbabilityWeight)> listForRoulette =\npreviousPopulation.ConvertAll(i => (i, (double)\ni.Value));\n\nList<ObjectiveFunctionResult> rouletteIndividuals =\n\nRoulette.Selection(listForRoulette, remainder) ;\n\nindividuals .AddRange(rouletteIndividuals) ;\n\nreturn rouletteIndividuals;\n\nIn Listing 7-37 I first calculate the size of the elite and put that value\ninto the eliteCount variable. After that, I sort the previous population\nin descending order of the value of the objective function and take the\ntop elements in the resulting eliteCount list. After this, I call the roulette\nmethod Roulette.Selection that we previously implemented.\n\nBreeding Step\n\nThe purpose of the breeding step is to create new individuals by crossing\nindividuals of the parents. The algorithm for this step is quite simple. First,\nwe select pairs for crossing using some algorithm. Second, we cross them\nusing one of the previously described operators.\n\nListing 7-38 shows an implementation of the GetNextPoints method.\nIn this function, I first check that the current population consists of at least\ntwo individuals; otherwise, further steps are meaningless. Then, I call\nthe GetParentsList function configured by the selection step and save\nthe resulting pairs of parents into the parentsList variable. After this, I\nperform the crossing by calling the Crossing function for each group of\nparents.\n\nListing 7-38. GetNextPoints Function for Breeding Step\n\npublic List<AlgorithmPoint> GetNextPoints(\nList<ObjectiveFunctionResult>? population = null,\nPointMagicData? magicData = null)\n\nvar nextGeneration = new List<AlgorithmPoint>();\nif (population != null && population.Count < 2)\nreturn nextGeneration;\n\nList<List<ObjectiveFunctionResult>> parentsList =\n_selectionStep.GetParentsList(population, _\ngroupsCount) ;\n\nforeach (List<ObjectiveFunctionResult> parents in\n\nparentsList)\n\n{\n\nList<AlgorithmPoint> children = _crossingStep\n.Crossine(parents, functionVariables):\n\nif (magicData != null)\n\n{\nstring magicDataString = magicData.ToString();\nchildren.ForEach(c => c.MagicData =\nmagicDataString) ;\n\n}\n\nnextGeneration.AddRange(children) ;\n\n}\n\nreturn nextGeneration;\n\nThe GetNextPopulation function, shown in Listing 7-39, creates a\nnew population based on a previous, or parent, population and a set of\ndescendant individuals. In this step I added the ReplaceWorst parameter.\nIf this flag has a positive value, then the descendant individuals will\ncompletely replace the worst parent individuals. Otherwise, the new\npopulation will consist of both offspring and parent individuals. If we\nlook in the long term, then thanks to this logic, offspring individuals will\ncompete not only with individuals of their generation but also with all\nparent individuals. Of course, this is impossible to find in the real world,\nbecause there are no immortal living beings.\n\nListing 7-39. GetNextPopulation Function\n\npublic List<ObjectiveFunctionResult> GetNextPopulation(\nList<ObjectiveFunctionResult> previousPopulation,\nList<ObjectiveFunctionResult> previousResults)\n\nif (previousPopulation.Count == 1)\nreturn previousPopulation;\n\nvar individuals = new List<ObjectiveFunctionResult>();\n\nif (_replaceWorst)\n{\nint needParentsCount =\npreviousPopulation.Count>previousResults.Count\n? previousPopulation.Count -\npreviousResults.Count\n: 05\nvar needParents = previousPopulation\n-OrderByDescending(p => p.Value).\nTake(needParentsCount) ;\nindividuals. AddRange(needParents) ;\nindividuals .AddRange(previousResults) ;\n}\nelse\n{\nindividuals. AddRange(previousPopulation) ;\nindividuals. AddRange(previousResults) ;\n\n}\n\nindividuals = individuals.GroupBy(i => i.Id)\n-Select(g => g.First()).ToList();\n\nreturn individuals;\n\n}\nSelection Step\n\nThe purpose of this step is to create a set of parent groups for crossing. The\nGetParentsList function of the class that implements this step has no\nlogic. It calls the function of the same name of the selected operator.\n\nSelection Operator\n\nThe idea of this operator is that only those individuals whose fitness is\nhigher than or equal to the average fitness of the current population are\n\nincluded in the list of parents. Next, pairs are selected using the roulette\nmethod, where all elite individuals have an equal probability of being\nselected into a pair.\n\nListing 7-40 shows an implementation of this operator.\n\nListing 7-40. GetParentsList Function\n\npublic List<List<ObjectiveFunctionResult>> GetParentsList(List<\nObjectiveFunctionResult> individuals, int groupsCount)\n\n{\n\nvar parentsList = new List<List<ObjectiveFunction\nResult>>();\n\nvar elite = new List<ObjectiveFunctionResult>();\nint eliteCount = _elitPercent / 100 * individuals.Count;\nelite .AddRange(individuals.OrderByDescending(i => i.Value).\nToList()\n\n-GetRange(0, eliteCount-1));\n\nList<(ObjectiveFunctionResult Entity, double\nProbabilityWeight)> listForRoulette =\n\nelite.ConvertAll(i => (i, (double)i.Value));\nfor (int i = 0; i < groupsCount; i++)\n\n{\nList<ObjectiveFunctionResult> parentsGroup =\nRoulette. SelectionDistinct(listForRoulette, 2);\nparentsList.Add(parentsGroup) ;\n}\n\nreturn parentsList;\n\n\nPanmixia Operator\n\nThis is perhaps the simplest selection operator. The idea of this operator is\nto randomly select parental individuals with equal probability. Listing 7-41\nshows its implementation.\n\nListing 7-41. GetParentsList Function\n\npublic List<List<ObjectiveFunctionResult>> GetParentsList(List<\nObjectiveFunctionResult> individuals, int groupsCount)\n\n{\n\nvar parentsList = new List<List<ObjectiveFunction\nResult>>();\n\nfor (int i = 0; i < groupsCount; i++)\n\n{\nList<ObjectiveFunctionResult> parentsGroup = Roulette.\nSelectionDistinct(individuals, 2);\nparentsList.Add(parentsGroup) ;\n}\nreturn parentsList;\n}\nCrossing Step\n\nThe purpose of this step is to create offspring individuals based on the\ngroups of parent individuals formed in the previous step. As in the case\nof the selection step, the Crossing function of the class that implements\nthis step does not have logic. It calls the function of the same name of the\nselected operator.\n\nLet\u2019s look at the flat operator implementation of this step. The idea is\nthat the gene of a descendant is a random number located between the\nminimum and maximum values of the parents\u2019 genes.\n\nListing 7-42 shows an implementation of the Crossing function.\nPlease note that to determine the interval within which the gene value of\nthe descendant will be located, I select the best and worst individual from\nthe group of parent individuals. This operation is actually meaningless\nfor this operator, but it makes a lot of sense for other operators I have\nimplemented, such as the heuristic operator, where the value of the child\ngene should be located closer to the best value of the parent gene.\n\nListing 7-42. Crossing Function\n\npublic List<AlgorithmPoint> Crossing(List<ObjectiveFunction\nResult> parents, List<FunctionVariable> functionVariables)\n\n{\n\nvar nextGeneration = new List<AlgorithmPoint>();\n\nObjectiveFunctionResult parent1\nObjectiveFunctionResult parent2\nvar point = new AlgorithmPoint();\nnextGeneration.Add(point) ;\n\nforeach (FunctionVariableValue value1 in parenti.\nPoint.Values)\n\n{\n\nparents[0];\nparents[1];\n\nFunctionVariableValue value2 = parent2.Point.Values.\nFirst(v => v.Id.Equals(value1.Id));\n\nFunctionVariable functionVariable = functionVariables.\nFirst(v => v.Id.Equals(value1.Id));\n\ndecimal best = parent1.Value > parent2.Value ? value1.\nValue : value2.Value;\n\ndecimal worst = parent1.Value < parent2.Value ? value1.\nValue : value2.Value;\n\ndecimal crossValue = Crossing(best, worst,\nfunctionVariable) ;\n\npoint.Values.Add(new FunctionVariableValue(value1.Id,\ncrossValue));\n\n}\n\nreturn nextGeneration;\n\nListing 7-43 demonstrates the implementation of the Crossing\nfunction, but for a gene. And again in this code the already implemented\nRoulette class comes to our aid.\n\nListing 7-43. Crossing Variable\n\nprivate decimal Crossing(decimal best, decimal worst,\nFunctionVariable functionVariable)\n\n{\n\ndecimal crossValue = best;\n\nif (best != worst)\n{\n\ndecimal minValue\ndecimal maxValue\n\nMath.Min(best, worst) ;\nMath.Max(best, worst) ;\n\nList<decimal> accessValues =\nfunctionVariable.GetValues()\n-Where(v => v >= minValue && v <= maxValue).\nToList();\ncrossValue = Roulette.Selection(accessValues) ;\n\n}\n\nreturn crossValue;\n\nTest Functions\n\nOne of the requirements for the module was the requirement for the\nimplementation of mathematical functions, thanks to which you can check\nthe performance of the created algorithm. One of the requirements for\nsuch a function is the need for a large number of local extrema. One of\nthe most common functions that satisfies this condition is the Rastrigin\nfunction. This is exactly what I was one of the first to implement.\n\nThe formula for this is as follows:\n\nx)\nW(X) = Se \u2014 10cos(2mz;) + 10)\ntof\n\nObviously, the minimum and, accordingly, optimal solution to this\nfunction will be 0, with the value of all variables equal to 0.\n\nI want to draw your attention to the fact that although the optimization\nproblem often sounds like minimizing the value of the objective function,\nour task in finding the most profitable strategy is a maximization problem.\nThis shouldn\u2019t bother you. If you multiply the value of the objective\nfunction by -1, then the maximization problem becomes a minimization\nproblem.\n\nListing 7-44 shows an implementation of the Rastrigin function.\n\nListing 7-44. Test Calculate Function\n\npublic static decimal Calculate(\nList<FunctionVariable> functionVariables,\nAlgorithmPoint point)\n\ndouble result = 0;\nforeach (FunctionVariable variable in functionVariables)\n{\ndouble x = (double)point.Values.First(v => v.Id ==\nvariable. Id) .Value;\n\nresult += x * x - 10 * Math.Cos(2 * Math.PI * x) + 10;\n\n}\n\nreturn (decimal)result;\n\nSubTheory Example\n\nThe optimization algorithms module has been implemented. Let\u2019s look at\nthe use case for this in more detail. Let\u2019s imagine that we have a SubTheory\nwith the following parameters:\n\nSignal to open a position:\n\nGroup AND:\nVolume < Const\nBbw < Const\nLp < BbwL\nSignal to close a position:\nGroup AND:\nHp > BbwU\n\nRisk control will be presented in the form of a stop-loss order.\nVolume is the trading volume of the candle. The candle itself can be\nobtained thanks to three parameters.\n\n\u00ab CandleIntervalld: Candle interval identifier (1min,\n2min, and so on)\n\n\u00a2 CandleFrom: Parameter that determines how\nmany candles back you need to move away from the\ncurrent one\n\n\u00ab CandleTo: Parameter that determines how many\ncandles back you need to move away from CandleFrom\n\nThanks to these parameters, you can get a set of candles for which\nthe Volume indicator is calculated. The search for candles for all other\nindicators that require this occurs in a similar way. If the condition\ninvolves two indicators that require information about the candle, then for\ncondition = true, the condition must be met for all candles in the left and\nright parts.\n\nConst is a constant or a specific number that does not depend on\ntrading data. For this there is only one parameter, which is volume, that is,\nthe value of the constant itself.\n\nBbw (bollinger bands width) is the indicator with two parameters:\nlookbackPeriods and standardDeviations. This indicator also contains\nthree parameters to determine the candle on which this will be calculated.\n\nLp is the low price of the selected candle. It has no specific parameters\nother than the three (CandleIntervalld, CandleFrom, and CandleTo)\ndescribed earlier.\n\nBbw (bollinger bands lower band) is an indicator with two\nparameters: lookbackPeriods and standardDeviations. This indicator also\ncontains three parameters to determine the candle on which this will be\ncalculated.\n\nHP is high price. It has no specific parameters other than the\nparameters necessary to define a candle.\n\nBbwU (bollinger bands upper band) is an indicator with two\nparameters: lookbackPeriods and standardDeviations. This indicator also\ncontains three parameters to determine the candle on which this will be\ncalculated.\n\nStop-loss order has only one parameter: protected coefficient. Using\nthis, you can calculate the limit price. If the current price of a financial\nasset is above this level, the position is closed.\n\nI would like to draw your attention to the way I decided to set the\nparameters for the CandleFrom and CandleTo variables. If you use\nstandard from, to, and step, then there is a high probability of intersection\nof values, as well as invalid data, such as when CandleFrom = 5 and\nCandleTo = 1. To avoid this, I decided to vary the CandleFrom and\nCandleInterval parameters. Then CandleTo is easy to define: CandleTo =\nCandleFrom + CandleInterval.\n\nIf we take all the signal parameters, we get a list of variables for\nthe optimization algorithm, as shown in Table 7-2. As you can see, the\ntransition from SubTheory parameters to optimization algorithm variables\nis quite easy to implement.\n\nTable 7-2. Open Position Signal Params\nObject Name Param From To Step\n\nOpen signal\n\nVolume Candleintervalld Amin, Smin, 10min, 1h, 4h\nCandleFrom 0 2 1\nCandleinterval 0 5 1\n\nConst Volume 10 2000 10\n\nBbw LookbackPeriods 7 500 1\nStandardDeviations 2 5 1\nCandlelntervalld 1min, 5min, 10min, 1h, 4h\nCandleFrom 0 2 1\nCandleinterval 0 5 1\n\nConst Volume 10 2000 10\n\nLp Candlelntervalld 1min, 5min, 10min, 1h, 4h\nCandleFrom 0 2 1\n\n(continued)\n\nTable 7-2. (continued)\n\nObject Name Param From To Step\nCandlelnterval 0 5 1\nBbwL LookbackPeriods 7 500 1\nStandardDeviations 2 5 1\nCandleintervalld 1min, 5min, 10min, 1h, 4h\nCandleFrom 0 2 1\nCandlelnterval 0 5 1\nClose signal\nHp Candleintervalld 1min, 5min, 10min, 1h, 4h\nCandleFrom 0 2 1\nCandleinterval 0 5 1\nBbwU LookbackPeriods 7 500 1\nStandardDeviations 2 5 1\nCandlelntervalld 1min, 5min, 10min, 1h, 4h\nCandleFrom 0 2 1\nCandlelnterval 0 5 1\nStop-loss Protected Coeff 0.1% 10% 0.1%\nCoefficient\nSummary\n\nIn this chapter, I showed one of the options for implementing the\noptimization algorithms module. Two algorithms were implemented:\nbrute-force and genetic. But the module is implemented in such a way that\nadding a new algorithm will not pose a big problem.\n\nIn the generic algorithm, several operators were implemented for\neach of the steps. This will allow you to design a large number of your own\nvariations of the optimization algorithms. I also showed how to implement\none of the mathematical functions that can be used to check and test your\noptimization algorithms.\n\nNow the module of optimization algorithms is ready.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 8,
                "chapter_name": "CHAPTER 8",
                "chapter_path": "./screenshots-images-2/chapter_8",
                "sections": [
                    {
                        "section_id": 8.1,
                        "section_name": "Implementation\nof the Core Module",
                        "section_path": "./screenshots-images-2/chapter_8/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_8/section_1/677fb579-c60a-4c72-a3e1-470f81bc9a5c.png",
                            "./screenshots-images-2/chapter_8/section_1/a0b23e4b-8d14-40b7-b04a-b18676373ad7.png",
                            "./screenshots-images-2/chapter_8/section_1/2b5a24a6-89a9-43b2-b009-e8bda13c5a1d.png",
                            "./screenshots-images-2/chapter_8/section_1/3b8bae39-7473-46da-958b-a58eb4c0ba0d.png",
                            "./screenshots-images-2/chapter_8/section_1/9d6c2fbb-fed9-41ca-a26f-0e13d4299d60.png",
                            "./screenshots-images-2/chapter_8/section_1/3febee65-c7cf-466f-9f1a-f577db22629a.png",
                            "./screenshots-images-2/chapter_8/section_1/399bf3b9-ca6e-40b1-abf1-588afc3533cf.png",
                            "./screenshots-images-2/chapter_8/section_1/66c3446f-3849-4415-8472-bc66d425c809.png",
                            "./screenshots-images-2/chapter_8/section_1/ed1d3c70-ad7d-4696-b76f-01423741ae93.png",
                            "./screenshots-images-2/chapter_8/section_1/efe9f0f0-3173-4739-8060-be1178d4bd6d.png",
                            "./screenshots-images-2/chapter_8/section_1/c070aeb2-b61f-4c60-b4dc-fc2149e074b4.png",
                            "./screenshots-images-2/chapter_8/section_1/3a0bd21e-d45b-4425-a4ff-01226788808e.png",
                            "./screenshots-images-2/chapter_8/section_1/b1e6d494-09fd-4542-8c0d-a02329e95fd6.png",
                            "./screenshots-images-2/chapter_8/section_1/49c734ce-dd3d-4c22-9427-513b0546aef9.png",
                            "./screenshots-images-2/chapter_8/section_1/0ef5f231-8e8f-4966-8e95-1d2b1d83ef91.png",
                            "./screenshots-images-2/chapter_8/section_1/b23357cb-a3ef-4926-876d-6c90194a5f71.png",
                            "./screenshots-images-2/chapter_8/section_1/8a5271e2-4fd1-48a0-9bd3-64983bab9562.png",
                            "./screenshots-images-2/chapter_8/section_1/0f5fc06e-2de0-428f-b86b-1a4a7d688218.png",
                            "./screenshots-images-2/chapter_8/section_1/0dbdc8a2-6933-49ea-912c-63ee6bfceaf2.png",
                            "./screenshots-images-2/chapter_8/section_1/48b8069e-a5bd-474c-bb0b-d38704e15f08.png",
                            "./screenshots-images-2/chapter_8/section_1/6012264e-fc0e-4daa-9dd7-380c5f6a8f89.png",
                            "./screenshots-images-2/chapter_8/section_1/0400b0ce-45d9-4e52-b8c7-b673627b4069.png",
                            "./screenshots-images-2/chapter_8/section_1/8807d0be-cfbb-462c-bffd-cb39b0d6bbe2.png",
                            "./screenshots-images-2/chapter_8/section_1/616f1324-36cc-48a4-94b7-a77b5e12ed79.png",
                            "./screenshots-images-2/chapter_8/section_1/c120d60b-4371-4b21-bfcd-5530787c6463.png",
                            "./screenshots-images-2/chapter_8/section_1/8bea9ee7-6778-4c2f-aabc-cbe2f040d550.png",
                            "./screenshots-images-2/chapter_8/section_1/cb8397be-596f-43e5-9027-52743b90dd5f.png",
                            "./screenshots-images-2/chapter_8/section_1/690a1989-86ca-4e8f-addf-8d8078b222b0.png",
                            "./screenshots-images-2/chapter_8/section_1/d154ece2-cf71-4161-8bc3-06d786f47727.png",
                            "./screenshots-images-2/chapter_8/section_1/b8856a4e-e9f5-49ea-b57d-1865b61d1f42.png",
                            "./screenshots-images-2/chapter_8/section_1/4e0ad5fd-3a5f-4819-9790-4c2d483ec31f.png",
                            "./screenshots-images-2/chapter_8/section_1/871d6ad1-2ea3-4e6a-8c99-13568dc1bb20.png",
                            "./screenshots-images-2/chapter_8/section_1/8477582b-e3e5-41a2-8436-de5a6d5ee858.png",
                            "./screenshots-images-2/chapter_8/section_1/604081da-c9f7-439f-b0fe-34db04ad903d.png",
                            "./screenshots-images-2/chapter_8/section_1/4df54614-a963-4ab7-bcca-327fae27bf04.png",
                            "./screenshots-images-2/chapter_8/section_1/4e8648bc-e577-4a4a-8c32-a6ad20164a24.png",
                            "./screenshots-images-2/chapter_8/section_1/68ad0f97-d911-4d06-908a-77fca1e9f4d9.png",
                            "./screenshots-images-2/chapter_8/section_1/1731c718-de77-4b1b-9ab9-7c278190c46e.png",
                            "./screenshots-images-2/chapter_8/section_1/dafcb2ca-dde0-4b48-b4f2-b1c920364807.png",
                            "./screenshots-images-2/chapter_8/section_1/de7cf1ba-6b31-4982-a0c7-03950e15f967.png",
                            "./screenshots-images-2/chapter_8/section_1/18ba096a-68ad-43a8-8961-966589b9197d.png",
                            "./screenshots-images-2/chapter_8/section_1/514b346c-223e-457c-a2db-f38d76fd8487.png",
                            "./screenshots-images-2/chapter_8/section_1/3c1c48b2-2e97-4f56-917d-d449bc593a5d.png",
                            "./screenshots-images-2/chapter_8/section_1/ced88a71-6c77-4b06-b818-a0b668e5a987.png",
                            "./screenshots-images-2/chapter_8/section_1/f895e519-8510-4a47-b764-c87022ddfdc4.png",
                            "./screenshots-images-2/chapter_8/section_1/177a99c8-d4dc-4db5-9afc-0a2cb186904c.png",
                            "./screenshots-images-2/chapter_8/section_1/9d887a03-ca98-4ece-a273-6090a81b9886.png",
                            "./screenshots-images-2/chapter_8/section_1/ecfdb0c0-040e-426a-813f-f3bdc3b9236c.png",
                            "./screenshots-images-2/chapter_8/section_1/cf7876ff-1ca5-4e0c-b7b1-96b73a7d035f.png",
                            "./screenshots-images-2/chapter_8/section_1/436d43db-a33e-4130-bc7f-c2ea9bc2af3b.png",
                            "./screenshots-images-2/chapter_8/section_1/7051d966-a91f-4e6b-aa93-2f3da87e2317.png",
                            "./screenshots-images-2/chapter_8/section_1/66028fc5-e8dd-4c29-a8c4-d835870bbe22.png",
                            "./screenshots-images-2/chapter_8/section_1/45ac00f9-0d54-4dc5-b78e-b251e31d57d3.png",
                            "./screenshots-images-2/chapter_8/section_1/c079c3c9-87fa-4c6e-94bc-fa6ad83b8767.png",
                            "./screenshots-images-2/chapter_8/section_1/84c23760-59db-4dad-91aa-929ea0198978.png",
                            "./screenshots-images-2/chapter_8/section_1/aea44779-2d05-4233-88e5-aaaf56f87e78.png",
                            "./screenshots-images-2/chapter_8/section_1/6e9d4ab7-83fa-4439-8cc0-c585779cbffa.png",
                            "./screenshots-images-2/chapter_8/section_1/d39cf35f-08d7-4770-823c-de6530f6aaec.png",
                            "./screenshots-images-2/chapter_8/section_1/45402f8d-bff3-499b-be5d-cb54a4e53306.png",
                            "./screenshots-images-2/chapter_8/section_1/fb7cfa50-334c-4e99-8ff2-6c9a4ba63ef0.png",
                            "./screenshots-images-2/chapter_8/section_1/9698f435-9f5a-4b9e-95a5-6faff7eba073.png",
                            "./screenshots-images-2/chapter_8/section_1/cff7dd28-4c5a-4da0-9737-0dbd5ecd4d7a.png",
                            "./screenshots-images-2/chapter_8/section_1/aebdb625-2c3e-4da8-93b7-3caa21906add.png",
                            "./screenshots-images-2/chapter_8/section_1/32ec07a6-cfcb-4cdd-8418-a37032f01ae2.png",
                            "./screenshots-images-2/chapter_8/section_1/3c65c550-2388-45cd-b018-5f0e1163c567.png",
                            "./screenshots-images-2/chapter_8/section_1/408a2ca9-becd-496e-b9f9-518a3227c1f8.png",
                            "./screenshots-images-2/chapter_8/section_1/36436494-0689-4a48-b74a-2cf3d1909b59.png",
                            "./screenshots-images-2/chapter_8/section_1/1c3cc4c1-ef0b-49f6-a177-408b51d9b5be.png",
                            "./screenshots-images-2/chapter_8/section_1/9ae4c028-d3ab-4d3d-8ce9-865b0d2cd40f.png",
                            "./screenshots-images-2/chapter_8/section_1/9d5a4d7c-82fd-4a3c-825c-3eb9d8c2cb40.png",
                            "./screenshots-images-2/chapter_8/section_1/1d0ccb09-0885-4a70-982f-d29d06259b24.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In this chapter, I will show my implementation of the main component,\nnamely, the kernel of the entire system. This will be used both in the\nsubsystem for searching for a profitable strategy and in the subsystem\nfor real trading. The main purpose of this module is to give signals to\nthe broker to place or close orders on the exchange, based on trading\ninformation (see Figure 8-1).\n\n+ Trading data\n+ Deals events\n\n+ Command to place an order\n+ Command to cancel order\n\nFigure 8-1. Core module input and output data\n\nUse Cases\n\nBefore we begin, I would like to remind you of the operating logic of the\nparts of the subsystem for searching for a profitable strategy and the real\ntrading subsystem, which directly interact with the Core module.\n\nThe logic of searching for a profitable strategy is based on the\ngeneration of theories, which in turn generate subtheories. Subtheories,\nusing optimization algorithms, generate strategies. To calculate a strategy\non a certain interval of historical data, a task is created, which contains\nthe strategy identifier and the TestCandleInterval identifier. For a task to\nbe calculated, it must be placed in the queue for calculation. A queue is\na separate table in the database. Queue processing will be handled by a\nspecial application, for which several pods will be created in Kubernetes.\n\nThe scenario for using the Core module in the subsystem for searching\nfor a profitable strategy is as follows:\n\n1. One of the task queue handler pods picks up the\nnext task.\n\n2. This loads information about historical data in\nthe form of an array of candles and starts a loop to\nprocess them.\n\n3. At each iteration, this notifies Sandbox Exchange\nwhen new candles appear. Sandbox Exchange, in\nturn, notifies the Core module about any changes in\nthe order statuses.\n\n4. After notifying Sandbox Exchange, the application\nnotifies the Core module about the appearance of a\nnew candle.\n\n5. The Core module performs calculations and gives\na command to place or close an order on the\nexchange.\n\nWe have decided on the logic of using the Core module in the strategy\nsearch subsystem; let me remind you how this module will be used in the\nreal trading subsystem:\n\nThe Tasks App of the Strategy Manager Service,\nbased on information about the types of\ninstruments and the list of profitable strategies,\n\u201cdecides\u201d that it is necessary to activate the strategy-\ninstrument pair.\n\nThe Tasks App of the Strategy Manager Service\ncalls the API App method of the Strategy Service\nindicating that this pair needs to be activated.\n\nThe Strategy Service API App makes a note in\nits database that the strategy-instrument pair is\nnow active.\n\nOne of the free Worker App pods of the Strategy\nService starts working with a new pair.\n\nThis subscribes to events about the appearance of\nnew candles of the selected instrument.\n\nWhen an event occurs about the appearance\nof a new candle, the Worker App notifies the\nCore module.\n\nThe Core module performs calculations and gives\na command to place or close an order on the\nexchange.\n\nThe Worker App sends an Exchange Gateway API\ncommand to place or close an order.\n\nWhen information about a change in order status\ncomes from the exchange, the Worker App again\nnotifies the Core module about this.\n\nBoth of these scenarios are designed for the Core module to work with\nonly one strategy-instrument pair at a time. I specifically focused on this in\nthe chapter where we discussed the architectural solution. There were two\nreasons for this.\n\nFirst, the instrument can be very volatile, and therefore, with a large\nnumber of strategies running on one pod, a situation may arise in which\nthe pod will not have time to process all messages about candle changes.\nSecond, this approach allows you to further isolate running strategies from\neach other, because they will cache frequently used information.\n\nAs a result, I identified the following list of external commands and\nevents to which the Core module will respond:\n\n\u2014 InitContextCommand. This command is used to initial-\nize frequently used information.\n\n\u2014 UpdateCandleEvent. This message is generated when\ncandles are updated.\n\n\u2014 CancelExchangeOrderEvent. This message notifies the\nmodule about the fact that the order has been can-\ncelled by the broker.\n\n\u2014 CloseExchangeOrderEvent. This message notifies the\nmodule about the fact of complete execution of the\norder on the exchange.\n\n\u2014 CreateDealEvent. This message comes when a deal is\nexecuted on the exchange.\n\nIn turn, the Core service calls only one command, a handler,\nwhich must be implemented in an external application\u2014\nPlaceOrderCommand\u2014a command to place an order on the exchange.\nI did not add a command to cancel the order. We discussed this point\nin Chapter 4. Since the system will implement system orders, which\n\nare responsible for the logic of order execution, it was decided in this\nimplementation to place only market orders on the exchange, which are\nusually executed instantly.\n\nI would also like to draw your attention to the fact that events about\nchanges in candles will only come on candles at intervals of a minute,\nbecause other candles can be easily calculated based on minute candles.\nThis is also because many exchanges and brokers require a subscription to\na separate web socket connection channel for each candle interval and, of\ncourse, limit the number of such subscriptions and connections.\n\nContext\n\nAt this stage, I will not fill the context with all the necessary information,\nbecause I still don\u2019t know what might be needed. But I will lay the\nfoundation for this mechanism. The context will be a singleton, which is\nfilled with information in the InitContextCommand command handler.\n\nI leave the job of ensuring that there is a single instance of the\nStrategyContext context class entirely to IServiceCollection. To do this, I\ncreated a static CoreServiceCollectionExtensions class and added a line\nto it that declared the StrategyContext context, as shown in Listing 8-1.\n\nListing 8-1. Core Module Connection Function\n\npublic static IServiceCollection AddCore(\nthis IServiceCollection services)\n\n{\nservices .AddSingleton<StrategyContext>() ;\n\nreturn services;\n\nIn the context initialization command class, InitContextCommand\nhas so far added only the minimal required information, as shown in\nListing 8-2.\n\nListing 8-2. InitContextCommand Class\n\npublic class InitContextCommand: IRequest<bool>\n{\n\npublic required int Exchangeld;\n\npublic required int InstrumentId;\n\npublic required int StrategyId;\n\nUpdate Candle Event\n\nThis event is emitted by an application that uses the Core library. Core\ncontains a handler for this. I implemented the event class very simply, as\nshown in Listing 8-3. For this we only need a candle. You may need more\ninformation later, but for now this is enough.\n\nWhen implementing Event, I use a new feature of .NET 8 called\nprimary constructors, which allow you to increase code readability. You\ncan get more information about this at https: //learn.microsoft.com.\n\nListing 8-3. UpdateCandleEvent Class\n\npublic class UpdateCandleEvent(Candle candle) : INotification\n\n{\npublic readonly Candle Candle = candle;\n\nPerhaps it\u2019s worth revealing the implementation of Candle. At the\nsame time, I will remind you of what fields this concept consists of.\nListing 8-4 shows the implementation of this, as well as all the values of the\n\nCandleInterval enum. I implemented all the fields as required to make\nsure they were filled out in addition to the necessary fields that identify the\ncandle, such as Exchangeld, Instrumentld, and Interval. This, of course,\ncontains the Open, Close, High, and Low prices: the open, close, highest,\nand lowest price for the period of the candle, respectively. In addition to\nprices, candles also contain the volume of all past transactions (Volume) and\nthe opening date of the candle (OpenDate).\n\nListing 8-4. Candle Record\n\npublic record Candle\n\n{\n\npublic required int Exchangeld;\n\npublic\npublic\n\npublic\n\npublic\n\npublic\n\npublic\n\npublic\n\npublic\n}\n\npublic enum\n\n{\n_Amin\n_2min\n_3min\n_5min\n_10min\n_15min\n_30min\n\nrequired int InstrumentId;\nrequired CandleInterval Interval;\n\nrequired decimal Open;\nrequired decimal Close;\nrequired decimal High;\nrequired decimal Low;\nrequired decimal Volume;\nrequired DateTime OpenDate;\n\nCandleInterval\n\n1,\n2,\n3,\n5,\n= 10,\n15,\n30,\n\nhour = 60,\n\n_4hour = 240,\nday = 1440,\n\nweek = 10080,\nmonth = 43200\n\nWhen the event about the appearance of a new minute candle arrives,\nyou need to do these three things:\n\n\u00ab Check that the candle belongs to the current context.\n\n\u00ab Check system orders, as they require certain actions\nwhen trading information arrives.\n\n+ Calculate signals and, if necessary, emit commands to\nplace orders.\n\nListing 8-5 shows my implementation of a handler for this minute\ncandle event. In this, I performed basic checks to ensure that the candle\nmatches the context. Next, I called the UpdateCand1e function on the\ncontext. Very soon I will show the implementation of this function, but\nnow will say that all candles of the required intervals are updated. This\nwill be needed when calculating signal values. After all, they can use not\nonly minute candles but also candles of other intervals. After updating\nthe candles in the context, I sequentially processed the commands for\nchecking orders and signal values.\n\nListing 8-5. Handle Function of UpdateCandleEvent Handler\n\npublic async Task Handle(UpdateCandleEvent notification,\nCancellationToken cancellationToken)\n\n{\n\nCandle newCandle = notification.Candle;\n\nif (newCandle.ExchangeId != _strategyContext.Exchangeld)\n\nreturn;\nif (newCandle.InstrumentId != _strategyContext.\nInstrumentId)\nreturn;\n\n_strategyContext .UpdateCandle(newCandle) ;\n\nawait _mediator.Send(new CheckSystemOrdersCommand() ,\ncancellationToken) ;\n\nawait _mediator.Send(new CheckSignalsCommand() ,\ncancellationToken) ;\n\nCheck Signals\n\nSignal values are checked in the CheckSignalsCommand command handler.\nListing 8-6 shows the implementation of the signal check command\nhandler.\n\nHere's what happens:\n\n1. SignalData is being calculated, and then I will\nanalyze this class in detail. The most important\nthing is that it contains a field SignalValue of\ntype boo1?, containing the value of the signal true,\nfalse, or null. If this is null, then this means that\nsignal calculation is currently impossible. The fact\nis that many indicators require the availability of\nhistorical candle data, which means that if the data\nhas not been accumulated, then the calculation is\nimpossible.\n\n2. Ifatleast one of the signals cannot be calculated,\nthen the processing of the command stops, because\nitis impossible to say whether it is possible to open\nor close a position.\n\n3. Further, if the signal to open a position and close a\nposition is positive, then this situation is considered\ncontradictory, and a position is not opened\nor closed.\n\n4. Ifthe opening signal is triggered, the position\nopening command is called.\n\n5. Ifthe close signal is triggered, all open positions are\nclosed. As my experience has shown, the ability to\nopen multiple positions has a positive effect on the\nquality of strategies.\n\nListing 8-6. CheckSignalsCommand Handler\n\npublic async Task<bool> Handle(\nCheckSignalsCommand request,\nCancellationToken cancellationToken)\n\nint openSignalld = _strategyContext.Strategy.OpenSignalId;\nint closeSignalld = _strategyContext. Strategy.\nCloseSignalld;\n\nSignalData openSignalData =\nawait _mediator.Send(new CalculateSignalCommand(openS\nignalld));\n\nSignalData closeSignalData =\nawait _mediator.Send(new CalculateSignalCommand(closeS\nignallId));\n\nbool? openPosition = openSignalData.SignalValue;\nbool? closePosition = closeSignalData.SignalValue;\nif (!openPosition.HasValue\n\n|| !closePosition.HasValue\n\n|| openPosition.Value && closePosition.Value)\n\nreturn true;\n\nif (openPosition.Value)\n\nawait _mediator.Send(new OpenPositionCommand()) ;\nelse if (closePosition.Value)\n\nawait _mediator.Send(new ClosePositionsCommand());\n\nreturn true;\n\nStrategy Model\n\nBefore we move on to implementing the signal calculation command, it\nis necessary to implement a model of this. Let me remind you the main\naspects of this entity.\n\n\u2014 The purpose of the signal is to calculate a yes/no\nresponse.\n\n- The yes/no answer is obtained by calculating the value\nof the root group conditions.\n\n\u2014 There are two types of groups: with an AND condition\nand with an OR condition. .\n\n- Each conditions group can contain both child groups\nand conditions.\n\n- Conditions represent a condition for comparing the\nvalues of two indicators.\n\nListing 8-7 shows an implementation of the Signal class. Since this\nis an entity, it contains an Id field. The Name field contains a description\nfor the UL. In addition, it contains a Condition field. As was said earlier,\nCondition has a hierarchical structure, so Condition is not a list.\n\nListing 8-7. Signal Class\n\npublic class Signal\n\n{\n\npublic required int Id;\n\npublic required string Name;\n\npublic required Condition Condition;\n}\n\nThe Condition class presented in Listing 8-8 looks more interesting.\n\nListing 8-8. Condition Class\n\npublic class Condition\n{\npublic required Guid Code;\npublic required int Index;\npublic required bool IsGroup;\npublic required List<Condition> Conditions = new ();\npublic required ConditionGroupType? GroupType;\npublic required int? Indicator1Id;\npublic required ConditionType? ConditionType;\npublic required int? Indicator2Id;\n\nI added the following fields to this class:\n\n\u2014 Code. This will be needed in many places in our\nprogram, for example, when setting the value of a\nparameter of one of the condition indicators.\n\n\u2014 Index. This field is required to determine the order in\nwhich the UI will be displayed to the user. It is very\nunpleasant when the sequence of conditions changes\nafter saving and updating the page with the signal.\n\n\u2014 IsGroup. This field is necessary to understand whether\nthe condition is a group or a full-fledged condition with\nindicators.\n\n- Conditions. If the condition is a group, then of course it\ncontains children. They are stored in this parameter.\n\n- GroupType. This is a field of type enum with only two\nvalues AND and OR.\n\n\u2014 Indicator1Id. This is the ID of the first indicator.\n\n\u2014 ConditionType. This is the type of condition for\ncomparing identifier values. It is represented as an\nenum with six possible values: Equality, Inequality,\nLess, LessOrEqual, Greater, and GreaterOrEqual.\n\n-  Indicator2Id. This is the second indicator ID.\n\nKnowing the structure of the class that represents a signal, we can\ndescribe the SignalData class. Listing 8-9 shows an implementation of\nthis. I added Id to this field so that SignalData and the list of indicator\nvalues can be linked. Please note that in the SignalDataIndicatorValues\nclass I did not use the Indicatorld field but instead introduced an\nIsIndicator1 field of type bool. That is, if it is true, then this is the value\nof Indicator1Id in the condition; otherwise, it\u2019s Indicator2Id. I did this\non purpose, because there are strategies where the values of the same\nindicator are compared, but at different candle intervals.\n\nPay attention to the three fields Signal Id, ConditionCode,\nand IsIndicator1 in the classes StrategySignalParam and\nStrategySignalCandle, which are used to accurately determine the\nparameters of which indicator were set. StrategySignalParam contains\ninformation about the values of all indicator parameters; this is a list of\nvalues for the IndicatorParamTypeld field, which will be provided by a\nseparate library for calculating indicators. The StrategySignalCandle\nclass contains the CandleIntervalId field, which is the identifier of\nthe candle interval at which the indicator value is calculated, as well as\nCandleFrom and CandleTo, which determine at what depth this calculation\nshould be performed.\n\nListing 8-10. Strategy Class\n\npublic class Strategy\n\n{\npublic required int Id;\npublic required string Name;\npublic required int OpenSignalld;\npublic required int CloseSignallId;\n\npublic required List<StrategySignalParam>\nStrategySignalParams ;\npublic required List<StrategySignalCandle>\nStrategySignalCandles;\n\n}\n\npublic class StrategySignalParam\n\n{\npublic required int SignallId;\n\npublic required string ConditionCode;\npublic required bool IsIndicator1;\n\nPay attention to the three fields SignalId, ConditionCode,\nand IsIndicator1 in the classes StrategySignalParam and\nStrategySignalCandle, which are used to accurately determine the\nparameters of which indicator were set. StrategySignalParam contains\ninformation about the values of all indicator parameters; this is a list of\nvalues for the IndicatorParamTypeld field, which will be provided by a\nseparate library for calculating indicators. The StrategySignalCandle\nclass contains the CandleIntervalId field, which is the identifier of\nthe candle interval at which the indicator value is calculated, as well as\nCandleFrom and CandleTo, which determine at what depth this calculation\nshould be performed.\n\nListing 8-10. Strategy Class\n\npublic class Strategy\n\n{\npublic required int Id;\npublic required string Name;\npublic required int OpenSignalld;\npublic required int CloseSignallId;\n\npublic required List<StrategySignalParam>\nStrategySignalParams ;\npublic required List<StrategySignalCandle>\nStrategySignalCandles;\n\n}\n\npublic class StrategySignalParam\n\n{\npublic required int SignallId;\n\npublic required string ConditionCode;\npublic required bool IsIndicator1;\n\npublic required int IndicatorParamTypeld;\npublic required decimal ParamValue;\n\n}\n\npublic class StrategySignalCandle\n\n{\npublic required int SignalId;\npublic required string ConditionCode;\npublic required bool IsIndicator1;\npublic required int CandleIntervalld;\npublic required int CandleFrom;\npublic required int CandleTo;\n\n}\n\nSince strategy and signals have become complex entities whose\nparameters will most likely be needed in command handlers, it is\nnecessary to add repository interfaces for retrieving entities, as well as\nenrich the StrategyContext class with new parameters.\n\nListings 8-11 shows a new implementation of the\nInitContextCommand command handler. | get the object of the strategy\nand the necessary signals. Since these entities are received only once when\nthe strategy is launched, it is necessary to keep in mind that when the\nstrategy or signals change, it is necessary to restart the strategy.\n\nListing 8-11. InitContextCommand Handler\n\npublic async Task<bool> Handle(\nInitContextCommand request,\nCancellationToken cancellationToken)\n\n_strategyContext.ExchangeId = request.Exchangeld;\n_strategyContext.InstrumentId = request. InstrumentId;\n\n_strategyContext.Strategy =\nawait _strategyRepository.GetAsync(request.StrategyId) ;\n\n_strategyContext.Signals =\nawait _signalRepository.GetAsync([\n_strategyContext.Strategy.OpenSignalld,\n_strategyContext.Strategy.CloseSignalld,\n));\n\nreturn true;\n\nCalculate Signal\n\nLet's start implementing the CalculateSignalCommand command handler.\nThe task is to return the result of calculating signal data in the form of an\ninstance of the SignalData class and also save this data to the database.\nThe user will need this data to check the correctness of the calculations\nand the operation of the entire algorithm.\n\nListing 8-12 shows the implementation of the central command\nhandler function. I fill in some fields of the command handler class that I\nwill need in other functions. Then I create an instance of the SignalData\nclass. I call the calculation function condition CalculateCondition. Please\nnote that I have placed the SignalData instance into the class fields. I did\nthis so that the calculation functions could add the calculated indicator\nvalues to this.\n\nListing 8-12. CalculateSignalCommand Handler\n\npublic async Task<SignalData> Handle(\nCalculateSignalCommand request,\nCancellationToken cancellationToken)\n\n_Signal = _strategyContext.Signals\n\u00abFirst(s => s.Id == request.Signalld) ;\n\n_signalData = new()\n\n{\nExchangeId = _strategyContext.Exchangeld,\nInstrumentId = _strategyContext.InstrumentId,\nStrategyId = _strategyContext.Strategy.Id,\nCandleTime = _strategyContext.LastCandle! .OpenDate,\nSignalId = _signal.Id,\n\n}s\n\n_signalData.SignalValue = CalculateCondition(_signal.\n\nCondition) ;\n\n_signalData = await _signalDataRepository.SaveAsync\n(_signalData) ;\nreturn _signalData;\n\nThe implementation of the CalculateCondition function is quite\nsimple. This is where the calculation function is selected. If this is a\ncondition group, then the CalculateGroupCondition function is called;\notherwise, CalculateNotGroupCondition is called. Listing 8-13 shows my\nimplementation of the CalculateCondition function.\n\nListing 8-13. CalculateCondition Function\n\nprivate bool? CalculateCondition(Condition condition)\n{\nbool? conditionValue = false;\nif (condition. ItsGroup)\nconditionValue = CalculateGroupCondition(condition) ;\nelse\n\nconditionValue = (condition.GroupType ==\nConditionGroupType. And)\n? conditionValue.Value &&\nchildConditionValue! .Value\n: conditionValue.Value | |\nchildConditionValue! . Value;\n\n}\n\nconditionValue = oneOfChildIsNull ? null : conditionValue;\n\nreturn conditionValue;\n\nPlease note how I solved the problem that some of the conditions\ncould not be calculated. I created a variable oneOfChildIsNul11, and if\nit is true, then only the child conditions are calculated, and the result of\nexecuting the entire function will be null.\n\nAmore interesting function is the function for calculating nongroup\nconditions. To do this, you need to obtain the depths of the candles from\nthe signal settings and then check the conditions on each of the candles.\nFor example, if the condition is configured like this:\n\nindicator_1 candle from = 0 - candle to = 2\n<\nIndicator_2 candle from = 3 - candle to = 4\n\nthen the calculation is made on five-minute candles and the new candle\nhas an opening date equal to 2024-02-10T 10:45:00; then for the condition\nvalue to be positive, all conditions must be met.\n\n\u2014  indicator_1 on 2024-02-10T10:45:00 < Indicator_2 on\n2024-02-10T10:30:00 (minus 3 times for 5 minutes)\n\n\u2014  indicator_1 on 2024-02-10T10:45:00 < Indicator_2 na\n2024-02-10T10:25:00 (minus 4 times for 5 minutes)\n\nconditionValue = (condition.GroupType ==\nConditionGroupType. And)\n? conditionValue.Value &&\nchildConditionValue! . Value\n: conditionValue.Value | |\nchildConditionValue! . Value;\n\n}\n\nconditionValue = oneOfChildIsNull ? null : conditionValue;\n\nreturn conditionValue;\n\nPlease note how I solved the problem that some of the conditions\ncould not be calculated. I created a variable oneOfChildIsNul11, and if\nit is true, then only the child conditions are calculated, and the result of\nexecuting the entire function will be null.\n\nAmore interesting function is the function for calculating nongroup\nconditions. To do this, you need to obtain the depths of the candles from\nthe signal settings and then check the conditions on each of the candles.\nFor example, if the condition is configured like this:\n\nindicator_1 candle from = 0 - candle to = 2\n<\nIndicator_2 candle from = 3 - candle to = 4\n\nthen the calculation is made on five-minute candles and the new candle\nhas an opening date equal to 2024-02-10T 10:45:00; then for the condition\nvalue to be positive, all conditions must be met.\n\n\u2014  indicator_1 on 2024-02-10T10:45:00 < Indicator_2 on\n2024-02-10T10:30:00 (minus 3 times for 5 minutes)\n\n\u2014  indicator_1 on 2024-02-10T10:45:00 < Indicator_2 na\n2024-02-10T10:25:00 (minus 4 times for 5 minutes)\n\n\u2014  indicator_1 on 2024-02-10T10:40:00 < Indicator_2 ua\n2024-02-10T10:30:00 (minus 3 times for 5 minutes)\n\n\u2014  indicator_1 on 2024-02-10T10:40:00 < Indicator_2 Ha\n2024-02-10T10:25:00 (minus 4 times for 5 minutes)\n\n= indicator_1 on 2024-02-10T10:35:00 < Indicator_2 Ha\n2024-02-10T10:30:00 (minus 3 times for 5 minutes)\n\n\u2014  indicator_1 on 2024-02-10T10:35:00 < Indicator_2 Ha\n2024-02-10T10:25:00 (minus 4 times for 5 minutes)\n\nListing 8-15 shows an implementation of the\nCalculateNotGroupCondition function. I get from the settings from and\nto candle. Next I work with two cycles. In each iteration, I calculate the\nvalues of each indicator, and if both values are not null, then I check the\ncondition.\n\nListing 8-15. CalculateNotGroupCondition Function\n\nprivate bool? CalculateNotGroupCondition(Condition condition)\n\n{\n\nbool? conditionValue = false;\n\nvar (candleFrom1, candleTo1) =\nGetFromToCandles(condition.Code, true);\n\nvar (candleFrom2, candleTo2) =\nGetFromToCandles(condition.Code, false) ;\n\nfor (int i1 = candleFrom1; i1 <= candleTo1; i1++)\n{\nfor (int i2 = candleFrom2; i2 <= candleTo2; i2++)\n{\ndecimal? indicator1Value =\nCalculateIndicatorValue(condition.Code,\ntrue, i1);\n\ndecimal? indicator2Value =\nCalculateIndicatorValue(condition.Code,\nfalse, i2);\n\nbool? currentConditionValue = false;\n\nif (!indicatoriValue.HasValue || !indicator2Value.\nHasValue)\n\ncurrentConditionValue = null;\nelse\n\ncurrentConditionValue\nCalculateConditionValue(\ncondition.ConditionType! .Value,\nindicatoriValue.Value,\nindicator2Value.Value) ;\n\nconditionValue = currentConditionValue;\nif (conditionValue != true)\nreturn conditionValue;\n\n}\n\nreturn conditionValue;\n\nListing 8-16 shows implementations of the GetFromToCandles and\nCalculateConditionValue helper functions. Of course, the from and to\ncandles settings are stored in the strategy itself, so the GetFromToCandles\nfunction accesses an instance of the Strategy class.\n\nThe CalculateConditionValue function is a simple switch. Starting\nwith version c# 8, working with this has become truly convenient.\n\n}s\n\nConditionType.Greater => indicatoriValue > indicator2Value,\nConditionType.GreaterOrEqual => indicatoriValue >=\nindicator2Value,\n\nConditionType.Less => indicator1Value < indicator2Value,\nConditionType.LessOrEqual => indicatoriValue <=\nindicator2Value,\n\n_ => throw new ArgumentOutOfRangeException(nameof (condition\nType), conditionType, null)\n\nThe CalculateIndicatorValue function performs two actions. First,\n\nthe indicator value is calculated, and second, the calculated value is\n\nadded to SignalData. Of course, the indicator value is calculated in the\nCalculate function of the special class IndicatorCalculatorManager.\nNext, I will analyze in detail the logic for calculating indicators. Listing 8-17\nshows the implementation of the CalculateIndicatorValue function.\n\nListing 8-17. CalculateIndicatorValue Function\n\nprivate decimal? CalculateIndicatorValue(\n\nstring conditionCode,\nbool isIndicator1,\nint candleBackNumber)\n\ndecimal? indicatorValue = _indicatorCalculatorManager.\nCalculate(\n\n_signal.Id,\n\nconditionCode,\n\nisIndicator1,\n\ncandleBackNumber,\n\n_strategyContext .Candles) ;\n\n}s\n\nConditionType.Greater => indicatoriValue > indicator2Value,\nConditionType.GreaterOrEqual => indicator1Value >=\nindicator2Value,\n\nConditionType.Less => indicator1Value < indicator2Value,\nConditionType.LessOrEqual => indicatoriValue <=\nindicator2Value,\n\n_ => throw new ArgumentOutOfRangeException(nameof (condition\nType), conditionType, null)\n\nThe CalculateIndicatorValue function performs two actions. First,\n\nthe indicator value is calculated, and second, the calculated value is\n\nadded to SignalData. Of course, the indicator value is calculated in the\nCalculate function of the special class IndicatorCalculatorManager.\nNext, I will analyze in detail the logic for calculating indicators. Listing 8-17\nshows the implementation of the CalculateIndicatorValue function.\n\nListing 8-17. CalculateIndicatorValue Function\n\nprivate decimal? CalculateIndicatorValue(\n\nstring conditionCode,\nbool isIndicator1,\nint candleBackNumber)\n\ndecimal? indicatorValue = _indicatorCalculatorManager.\nCalculate(\n\n_signal.Id,\n\nconditionCode,\n\nisIndicator1,\n\ncandleBackNumber,\n\n_strategyContext .Candles) ;\n\n_SignalData. IndicatorValues.Add(new\nSignalDataIndicatorValues\n{\nConditionCode = conditionCode,\nIsIndicator1 = true,\nIndicatorValue = indicatorValue,\nCandleBackNumber = candleBackNumber,\n\n})5\n\nreturn indicatorValue;\n\nCalculation of Indicators\n\nWhy IndicatorCalculatorManager? After all, calculators, by their nature\nand by name, should not contain a state. But as practice has shown, this\nis not entirely true. First, we need an entity that will store the already\ncalculated indicator values for the required number of candles back to\ncalculate conditions of type indicator_1 < indicator_2 on the last three\ncandles. Second, many indicators contain variables in their formulas, the\nvalues of which depend on historical data. For example, Adx (Average\nDirectional Index), Atr (Average True Range), Bbw (Bollinger Bands\nWidth) and others depend on the previous value, which means that this\nvalue must be stored somewhere.\n\nAs a result, I built the following class architecture to solve the problem\nof calculating indicators:\n\n\u2014 IndicatorCalculatorManager. This is a Singleton that\ncreates a list of calculators and stores it. This is exactly\nwhat you turn to when calculating the indicator. The\npurpose of this class is to generate and store a list of\ncalculators.\n\n\u2014 HistoryCalculator. This is a wrapper over classes that\nimplement the indicator calculation interface. This is\nwhere the calculated data for the required number of\ncandles back will be stored. The purpose of this class is\nto provide the ability to calculate indicators with the\nability to pass the candleBackNumber parameter, which\nhelps to find the candle on which the indicator is\ncalculated.\n\n\u2014 The classes implement the IIndicatorCalculator\ninterface. There are specific classes containing all the\nnecessary logic required for calculating indicators.\n\nListing 8-18 shows an implementation of the Init function of the\nIndicatorCalculatorManager class. This generates calculators for each\nof the indicators. The Init method is called in the InitContextCommand\ncommand handler. Please note that the GenerateCalculators function\nis recursive; in fact, it initializes generator classes for each condition.\nThis means it is called for each child condition in a condition with the\n\ntype group.\nListing 8-18. Init Function\n\npublic void Init(\nStrategy strategy,\nList<Signal> signals)\n\n_calculators.Clear();\n\nforeach (Signal signal in signals)\nGenerateCalculators(strategy, signal.Id, signal.\nCondition) ;\n\nListing 8-19. GetCalculator Function\n\nprivate HistoryCalculator GetCalculator(\nStrategy strategy,\nint signalld,\nCondition condition,\nbool isIndicator1)\n\nint indicatorId =\nisIndicator1\n? condition. Indicator1Id! .Value\n: condition. Indicator2Id! .Value;\nIIndicatorCalculator indicatorCalculator =\n_serviceProvider\n-GetRequiredKeyedService<IIndicatorCalculator>\n((IndicatorIds) indicatorId);\n\nStrategySignalCandle candleParam = strategy.\nStrategySignalCandles\n-First(c =>\nc.SignallId == signalld\n&& c.ConditionCode == condition.Code\n&& c.IsIndicator1 == isIndicator1\n)\nvar calculator = new HistoryCalculator\n{\nSignallId = signalld,\nConditionCode = condition.Code,\nIsIndicator1 = isIndicator1,\nMaxCandlesCount = candleParam.CandleTo + 1,\n\nprivate HistoryCalculator GetCalculator(\nStrategy strategy,\nint signalld,\nCondition condition,\nbool isIndicator1)\n\nint indicatorId =\nisIndicator1\n? condition. Indicator1Id!.Value\n: condition. Indicator2Id! .Value;\nIIndicatorCalculator indicatorCalculator =\n_serviceProvider\n-GetRequiredKeyedService<IIndicatorCalculator>\n((IndicatorIds) indicatorId);\n\nStrategySignalCandle candleParam = strategy.\nStrategySignalCandles\n-First(c =>\nc.SignallId == signalld\n&& c.ConditionCode == condition.Code\n&& c.IsIndicator1 == isIndicator1\n)s\nvar calculator = new HistoryCalculator\n{\nSignalld = signalld,\nConditionCode = condition.Code,\nIsIndicatori = isIndicator1,\nMaxCandlesCount = candleParam.CandleTo + 1,\nCandleInterval = (CandleInterval)candleParam.\nCandleIntervalld,\n\nListing 8-19. GetCalculator Function\n\nprivate HistoryCalculator GetCalculator(\nStrategy strategy,\nint signalld,\nCondition condition,\nbool isIndicator1)\n\nint indicatorId =\nisIndicator1\n? condition. Indicator1Id!.Value\n: condition. Indicator2Id! .Value;\nIIndicatorCalculator indicatorCalculator =\n_serviceProvider\n-GetRequiredKeyedService<IIndicatorCalculator>\n((IndicatorIds) indicatorId);\n\nStrategySignalCandle candleParam = strategy.\nStrategySignalCandles\n-First(c =>\nc.SignallId == signalld\n&& c.ConditionCode == condition.Code\n&& c.IsIndicator1 == isIndicator1\n)s\nvar calculator = new HistoryCalculator\n{\nSignalld = signalld,\nConditionCode = condition.Code,\nIsIndicatori = isIndicator1,\nMaxCandlesCount = candleParam.CandleTo + 1,\nCandleInterval = (CandleInterval)candleParam.\nCandleIntervalld,\n\n354\n\nCalculator = indicatorCalculator\n\n}5\n\nreturn calculator;\n\nIn the GetCalculator function, I get instances of calculator classes\nfrom IServiceCollection by indicator ID. To have this opportunity,\nyou must first place the class in this collection. Listing 8-20 shows\nthe implementation of the IServiceCollection extension and the\nIIndicatorCalculator interface.\n\nTo implement the ability to automatically add new classes that\nimplement the IIndicatorCalculator interface, I added a static field\ncalled static IndicatorIds Id { get; } in IIndicatorCalculator. In\nthe AddIndicators function, I select all the classes that implement the\nIIndicatorCalculator interface in the current assembly and then add\neach of the classes using the AddKeyedTransient function.\n\nListing 8-20. IIndicatorCalculator Interface\n\npublic interface IIndicatorCalculator\n\n{\nstatic IndicatorIds Id { get; }\npublic void Init(\nDictionary<IndicatorParamlypes, decimal>\nindicatorParams) ;\npublic decimal? Calculate(Candle newCandle) ;\n}\n\npublic static IServiceCollection AddIndicators(this\nIServiceCollection services)\n\n{\n\nservices .AddSingleton<IndicatorCalculatorManager>() ;\n\nvar calculators = AppDomain.CurrentDomain\n.GetAssemblies()\n-SelectMany(assembly => assembly.GetTypes())\n-Where(type =>\ntypeof (IIndicatorCalculator) .IsAssignableFrom(type)\n&& !type.IsInterface\n&& !type.IsAbstract) ;\n\nforeach (var calculator in calculators)\n{\nIndicatorIds indicatorId =\n(IndicatorIds) calculator!\n-GetProperty(\"Id\")!\n-GetValue(null, null)!;\nservices .AddKeyedTransient(\ntypeof (IndicatorIds),\nindicatorId,\ncalculator) ;\n\n}\n\nreturn services;\n\nLet\u2019s move on to the implementation of the HistoryCalculator\n\nclass. It has only one public function, Calculate, the implementation of\nwhich is shown in Listing 8-21. First it finds a candle with the required\ninterval. Let me remind you that candle update events will come only at\nminute intervals, but based on this, you can calculate candles for all other\nintervals. The Calculate function will receive candles for all time intervals\n\nas a parameter, which means you need to find the right one among them.\nNext, the NeedCalculation check is performed. This checks for changes\nin the parameters of the required candle. If the candle has changed, then\n\nthe calculator is contacted for the calculation, and the new result is stored\nin a field of the HistoryCalculator class. After this, the requested value is\nreceived.\n\nListing 8-21. Calculate Function\n\npublic decimal? Calculate(int candleBackNumber, List<Candle>\ncandles)\n\n{\n\nCandle newCandle = candles.First(c => c.Interval ==\nCandleInterval) ;\n\nif (NeedCalculation(newCandle) )\n{\n\ndecimal? newValue = Calculator.Calculate(newCandle) ;\nPutNewValue(newCandle, newValue);\n}\n\nreturn GetValue(candleBackNumber) ;\n\nAverage True Range (Atr)\n\nI would like to demonstrate the implementation of the indicator calculator\nusing the example of calculating the Atr (Average True Range) indicator.\nAtr is one of the market volatility indicators widely used in technical\nanalysis. Since atr is the average value of the true range, then, of course,\n\nits parameter is the number of candles on the basis of which the average\nvalue of the indicator will be determined.\n\nThe formula for calculating Atr is as follows:\n\nH Tr;\nn\n\nThat is, in essence, this is the sum of the True Range at the required\nnumber of candle intervals divided by their number.\nTrue Range is calculated using the following formula:\n\nTr =max(H-L,|H-C,,|L-C,]|)\n\nHis the High price of the current candle.\n\nLis the Low price of the current candle.\n\nC, is the Close price of the previous candle.\n\nTo implement this, I created a separate abstract class for calculating\nAverage indicators. I put this logic in a separate class because so many\nindicators use the average value, so it makes sense to make the calculation\nof the average value common to all indicators of this type.\n\nListing 8-22 demonstrates an implementation of the\nAverageCalculator class. In addition to the Calculate method, it also\nimplements the Init method. Why Init and not a constructor? Because\nindicator parameters can be initialized only through the Init method, since\nclasses are created using IServiceProvider. And the required number of\ncandles can be found only from the indicator parameters.\n\nThe logic of the Calculate method comes down to monitoring the\nrequired list of candles and calling the calculateValue function passed as\na parameter from the child class.\n\nListing 8-22. AverageCalculator Abstract Class\n\npublic abstract class AverageCalculator\n{\nprivate int _maxCandlesCount;\nprivate SortedList<DateTime, Candle> _lastCandles;\n\nprotected void Init(int maxCandlesCount)\n{\n_lastCandles = new();\n_maxCandlesCount = maxCandlesCount;\n\n}\n\nprotected decimal? Calculate(\nCandle newCandle,\nFunc<List<Candle>, decimal?> calculateValue)\n\n_lastCandles.TryAdd(newCandle.OpenDate, newCandle) ;\n_lastCandles[newCandle.OpenDate] = newCandle;\n\ndecimal? value = null;\nif (_lastCandles.Count >= _maxCandlesCount)\n{\nif (_lastCandles.Count > _maxCandlesCount)\n_lastCandles.Remove(_lastCandles.\nGetKeyAtIndex(0));\n\nvalue = calculateValue(_lastCandles.Values.\nToList());\n}\n\nreturn value;\n\nAsa result, the implementation of the AtrIndicatorCalculator class\nis quite simple. This is demonstrated in Listing 8-23. This calculates Tr for\neach candle. These values are summed and divided by the total number of\ncandles.\n\nListing 8-23. AtrIndicatorCalculator Class\n\npublic class AtrIndicatorCalculator : AverageCalculator,\nIIndicatorCalculator\n\n{\n\npublic static IndicatorIds Id => IndicatorIds.Atr;\nprivate int _lookbackPeriods;\n\npublic void Init(Dictionary<IndicatorParamTypes, decimal>\nindicatorParams)\n{\n_lookbackPeriods = (int) indicatorParams[IndicatorParam\nTypes. LookbackPeriods ] ;\nbase. Init(_lookbackPeriods) ;\n\n}\n\npublic decimal? Calculate(Candle newCandle)\n\n{\ndecimal? value = base.Calculate(newCandle,\nCalculateValue) ;\nreturn value;\n\n}\n\nprivate decimal? CalculateValue(List<Candle> lastCandles)\n{\n\ndecimal sumTr = 0;\n\nfor (int i = 1; i < lastCandles.Count; i++)\n\n{\n\nreturn newCandle.High;\n\nProcess of Positions\n\nAt this stage, a signal calculation command handler is implemented. Based\non this, the library makes a decision to open or close a position. Moreover,\nonly one position is opened, but all are closed. This is why the commands\nare named OpenPositionCommand and ClosePositionsCommand. Initially,\n\nI created a system that allowed me to open only one position. And, as\npractice has shown, this approach is less profitable than the possibility of\nopening several positions. The main thing is to set a rule by which you will\nlimit the number and frequency of positions opened.\n\nThe position processing process is also important. For example, the\nsystem opened a position and then placed a buy order on the exchange,\nbut you did not have enough funds on the exchange account, and this\nreturned a callback with error information. In this case, the process is quite\nsimple, but what if the financial asset was purchased. Next, based on the\ntules described in risk control, several specific system orders were opened\nand the signal to close positions came. You must remember to close all\nauxiliary orders.\n\nOr what if the system sent a command to place a buy order but\nsomewhere something went wrong and the message about the status of\nthis order was never received. What do you do in this case?\n\nI tried implemented position processing based on statuses and\ntransitions between them. But as the system became more complex, the\nprocess of position processing became more complicated, and in the\nend I got confused in the statuses, and the logic of transitions between\nthem became difficult. After another unsuccessful attempt to introduce\n\nreturn newCandle.High;\n\nProcess of Positions\n\nAt this stage, a signal calculation command handler is implemented. Based\non this, the library makes a decision to open or close a position. Moreover,\nonly one position is opened, but all are closed. This is why the commands\nare named OpenPositionCommand and ClosePositionsCommand. Initially,\n\nI created a system that allowed me to open only one position. And, as\npractice has shown, this approach is less profitable than the possibility of\nopening several positions. The main thing is to set a rule by which you will\nlimit the number and frequency of positions opened.\n\nThe position processing process is also important. For example, the\nsystem opened a position and then placed a buy order on the exchange,\nbut you did not have enough funds on the exchange account, and this\nreturned a callback with error information. In this case, the process is quite\nsimple, but what if the financial asset was purchased. Next, based on the\ntules described in risk control, several specific system orders were opened\nand the signal to close positions came. You must remember to close all\nauxiliary orders.\n\nOr what if the system sent a command to place a buy order but\nsomewhere something went wrong and the message about the status of\nthis order was never received. What do you do in this case?\n\nI tried implemented position processing based on statuses and\ntransitions between them. But as the system became more complex, the\nprocess of position processing became more complicated, and in the\nend I got confused in the statuses, and the logic of transitions between\nthem became difficult. After another unsuccessful attempt to introduce\n\nanother branch of the process, I gave up. I realized it was time to change\nsomething. Then I remembered that I already have a state machine\nimplemented in my system, in which I am satisfied with everything except\nthe asynchrony.\n\nAn already implemented state machine uses a database to store\nthe current state of the entity. Jobs run periodically, read this table,\nand process the entity state. But in Core, there is no question of any\nbackground job; I simply do not have the opportunity to wait even one\nmillisecond (and most likely more) for this job to be processed. It is\nnecessary to respond to the event immediately! And I thought: What if we\ncreate a \u201clite\u201d version of the state machine, where all steps are fast and\nthe entity will move along the process map only at the moment the event\narrives?\n\nThere were two problems with this solution. The first is the\nuncontrollable number of entities being processed in parallel; in other\nwords, we won't be able to control the load. If in the implemented version\nof the state machine the number of processed entities is specified in the\nsettings, then what about the lite version? Imagine that events will come\nfor hundreds of entities at once! Will the system be able to cope with\nthis? But will there really be hundreds of positions open on one pod? It is\nunlikely, so I decided to ignore this danger, because the architecture of the\nentire system will not allow this to happen. In the real trading subsystem,\nIhave a rule: one pod = one strategy-instrument pair. And in the strategy\nsearch subsystem, one pod processes only one task at a time. Thatis, the\ntule is also followed: a one-for-one strategy-instrument pair.\n\nThe second problem is the probability of two events arriving\nsimultaneously for one entity. If the process handles them simultaneously,\nthen disaster will occur. The main idea of a state machine, based on the\nfact that at one point in time an entity can be in only one state, will be\nviolated. The fact that only one strategy-instrument pair is processed\non one pod will not help in solving this problem, because several orders\ncan be placed with the broker for one position, which means there is a\n\npossibility that they will receive status change events simultaneously. Also,\ndo not forget about the position closing event.\n\nHow do you get out of this situation? What helped me in solving\nthe problem was the understanding that event processing is a very fast\nprocess, and I also knew that there would not be many events (let me\nremind you that the system is not designed for scalping trading, when\norders are created quite often). These two points gave me an idea: what\nif, when an event arrives, the entire bot process is blocked for all threads?\nThat is, the lite version will be able to process only one event of one entity\nat a time. There is one drawback to this approach; there is a possibility\nthat the pod will not have time to process the entire queue of events. But I\ndecided to try anyway, because I was going to implement the handlers as\nquickly as possible, and the number of open positions was controlled to\nbe small.\n\nProcess Bot (Lite Version)\n\nBefore we move on to the actual implementation, let\u2019s define the operating\nlogic of this version of the state machine.\nHere are some points:\n\n\u2014 Any actions with the entity are performed only when an\nevent is received.\n\n\u2014 In this version, the waiting node type does not wait for\na certain amount of time, after which it steps further,\nbut always stays at this step until the event arrives.\n\n\u2014 When processing an event, the robot steps either to the\nend of the map or to the first node with the wait-\ning type.\n\n\u2014  Atone time, the state machine can work with only\none entity.\n\nintended to store the current state of the entity in a\ndatabase. But the integration itself with this should not\nbe implemented in this library, but rather an event\nabout a state change should be published.\n\nAs a result, the input to this library is as follows:\n\nWe input a list of process map nodes. I assumed that it\nwould be stored not in the database but directly in the\ncode, which would ensure that it would be the same in\nboth subsystems (the search subsystem and the real\ntrading subsystem).\n\nWe implement the IProcessActFactory interface with\na single method for getting IProcessAct by its type\nidentifier. Also, obtaining a class that implements\nIProcessAct could be implemented in another way, by\ncreating a command in the state machine library and a\nhandler for this in the application that uses it. However,\nI don\u2019t like this approach for one reason. In the case of\na factory implementation, I can \u201cforce\u201d the application\nto pass me the class by implementing it in the\nIServiceCollection AddProcessBotLite extension\nmethod. In the case of a team, I will not be able to\n\ndo this.\n\nWe also need the calling library to implement the\nIProcessEntityQueries interface with a single\nGetCurrentNodeIdAsync method, which returns the\ncurrent state of the entity.\n\nAs a result, this library provides an implementation of the\nMoveEntityCommand command. This is what drives the entity along the\nprocess map. See Figure 8-2.\n\n+ Ust of Nodes\n\n+ Gethet + MovetntityCommand\n+ GetCurrentNodeldAsync n\nProcessBot Lite\n\nFigure 8-2. Input and output functionality of the library\n\nThe implementation of the MoveEntityCommandHandler class is simple.\nIjust get an instance of the ProcessMap class from serviceCollection and\ncall its MoveAsync method.\n\nThe algorithm for the MoveAsync function is as follows:\n\n1. This handles the event. That is, it moves the entity to\nthe nearest trigger of this one.\n\n2. After this, the nodes are moved and processed in\na loop until the entity stands on a node with the\nwaiting type or the map runs out.\n\nListing 8-25 shows the implementation of part of the MoveAsync\nfunction, before the loop from step 2. First, notice that this function returns\na bool type. If it is false, then this means that the workflow for this entity is\nover; that is, the robot has reached the end of the process map.\n\nlisolated the state machine blocking logic for other threads in the\nLockAsync function. Also note that eventId can come with the value null;\nthis is done specifically for the first entry into this function with a new\nentity, that is, to start the process.\n\nFirst, the GetCurrentNodeIdAsync function is called to understand\nwhich node the entity is currently on. After this, the entity is moved to the\nnearest trigger in the HandleEvent function.\n\nListing 8-25. MoveAsync Function, Part 1\n\npublic Task<bool> MoveAsync(Guid entityId, int? eventId)\n{\nreturn LockAsync(async () =>\n{\nGuid? currentNodeld =\nawait _processEntityQueries.GetCurrentNodeIdAsync(\nentityId) ;\nif (!currentNodeId.HasValue && eventId.HasValue)\nreturn false;\nGuid? triggerNodeId =\nawait HandleEvent(entityId, currentNodeld,\neventId);\nif (!triggerNodeId.HasValue)\nreturn true;\n\nListing 8-26 shows the second part of the implementation of the\nMoveAsync function. The loop determines the identifier of the next node\nby calling the GetNextNodeId function. If there is no next node, this means\nthat the process map is completed and the workflow is closed. After\nreceiving the nextNodeld, the application is notified about the change in\nthe state of the entity MoveEntityEvent and of course processing the node\nby calling the HandleNode function.\n\nPay attention to the nodeHandleResult variable. There are two fields in\nthis. Move is precisely what makes it possible to understand whether it is\nnecessary to stop the cycle and Nodeld. NodeId is necessary for nodes that\nmake transitions; for example, if the condition is met, then go to Nodeld_1,\nand if not, then move on.\n\nListing 8-26. MoveAsync Function, Part 2\n\ncurrentNodeld = triggerNodeId;\n(bool move, Guid? nodeId) nodeHandleResult = (true,\ncurrentNodeId) ;\n\nwhile (nodeHandleResult.move)\n\n{\nGuid? nextNodeId =\n\nGetNextNodeId(nodeHandleResult,\ncurrentNodeld! .Value);\n\nif (!nextNodeId.HasValue)\nreturn false;\n\ncurrentNodeId = nextNodelId.Value;\n\nawait _mediator.Publish(\nnew MoveEntityEvent(entityId,\ncurrentNodeld.Value)) ;\nnodeHandleResult =\nawait HandleNode(entityId,\ncurrentNodeId.Value) ;\n\n}\n\nreturn true;\n\n})5\n\nListing 8-27 shows the implementation of the LockAsync method. I\nam using the SemaphoreS1im class provided by Microsoft. If you look at\nthe documentation, it says that \u201cThe SemaphoreSlim class represents a\nlightweight, fast semaphore that can be used for waiting within a single\nprocess when wait times are expected to be very short.\u201d That is, this class\nprovides functionality that allows you to block code execution by other\nprocesses.\n\nListing 8-27. LockAsync Function\n\nprivate readonly SemaphoreSlim semaphore =\nnew(initialCount: 1, maxCount: 1);\n\nprivate async Task<T> LockAsync<T>(Func<Task<T>> act)\n\n{\n\nawait _semaphore.WaitAsync();\n\ntry\n{\nreturn await act();\n}\nfinally\n{\n_ semaphore .Release();\n}\n\nListing 8-28 shows an implementation of the HandleEvent function.\nIn this, if the currentNodeId does not yet have a value, that is, the state\nmachine processes the entity for the first time, the first node of the map is\nsearched. If the entity is not processed for the first time, then the first node\nis searched for by code, which is a trigger for the transmitted event and\nwhose code is greater than the code of the current node.\n\nIf a trigger is found, the entity moves to it, and the application is\nnotified about the entity's movement.\n\nListing 8-28. HandleEvent Function\n\nprivate async Task<Guid?> HandleEvent(\nGuid entityId,\nGuid? currentNodeld,\nint? eventId)\n\nGuid? triggerNodeld;\n\nif (currentNodeId.HasValue)\n\n{\nNode currentNode = _nodes.First(n => n.Id ==\ncurrentNodeId) ;\ntriggerNodeId = nodes\n\u00abWhere(n =>\nn.Code > currentNode.Code\n&& n.EventId == eventId)\n-MinBy(n => n.Code)\n?.1d;\n}\nelse\n{\ntriggerNodeId = _nodes\n-Where(n => n.EventId == eventId)\n-MinBy(n => n.Code)\n?.Id;\n}\n\nif (triggerNodeId.HasValue)\nawait _mediator\n\u00abPublish(\nnew MoveEntityEvent(entityId, triggerNodeld.\nValue));\n\nreturn triggerNodeld;\n\nListing 8-29 shows the implementation of the GetNextNodelId function\nfor finding the next node identifier. In this, if the result of processing the\nprevious node contains the ID of the next node, then a transition is made\nto this one; otherwise, the first node with a code greater than the current\none is selected.\n\nListing 8-30. HandleNode Function\n\nprivate async Task<(bool move, Guid? nodeId)> HandleNode(\nGuid entityId,\nGuid nodeId)\n\nNode currentNode = _nodes.First(n => n.Id == nodeld);\n\n(bool move, Guid? nodeId) nodeHandleResult = currentNode.\nType switch\n{\nNodeTypes.Act => await MakeAction(),\nNodeTypes.Waiting => (false, null),\nNodeTypes. Trigger => (true, null),\nNodeTypes.Description => (true, null),\n_ => throw new Exception($\"unknown node type\n{currentNode.Type}\")\n}s\n\nreturn nodeHandleResult;\n\nasync Task<(bool move, Guid? nodeId)> MakeAction()\n{\nIProcessAct? act =\n_processActFactory.GetAct (currentNode.\nActId! .Value) ;\nif (act == null)\nthrow new Exception($\"act is unknown {currentNode.\nActId! .Value}\") ;\nbool moveTo = await act.Make(entityId, currentNode.\nMagicString) ;\n\nListing 8-30. HandleNode Function\n\nprivate async Task<(bool move, Guid? nodeId)> HandleNode(\nGuid entityId,\nGuid nodeId)\n\nNode currentNode = _nodes.First(n => n.Id == nodeld);\n\n(bool move, Guid? nodeId) nodeHandleResult = currentNode.\nType switch\n{\nNodeTypes.Act => await MakeAction(),\nNodeTypes.Waiting => (false, null),\nNodeTypes. Trigger => (true, null),\nNodeTypes.Description => (true, null),\n_ => throw new Exception($\"unknown node type\n{currentNode.Type}\")\n}s\n\nreturn nodeHandleResult;\n\nasync Task<(bool move, Guid? nodeId)> MakeAction()\n{\nIProcessAct? act =\n_processActFactory.GetAct(currentNode.\nActId! .Value) ;\nif (act == null)\nthrow new Exception($\"act is unknown {currentNode.\nActId! .Value}\");\nbool moveTo = await act.Make(entityId, currentNode.\nMagicString);\n\n\u2014 Close position. This event can occur in several cases:\nfirst, when a signal to close a position is triggered, and\nsecond, when a signal comes from the risk control\nmodule; in our implementation, this is equivalent to\nclosing one of the auxiliary system orders, for example, a\ntake profit order. Third, an event about closing a position\ncan occur at the user\u2019s request, when he explicitly\ninstructs the system in the UI to close the position.\n\n\u2014 Close order executed. As a result of closing a position,\nitis necessary to reduce the amount of the financial\nasset in the portfolio to zero for this position. This\nmeans that if there is a certain amount of a financial\nasset left in the portfolio, it must be sold. That is, place\na sell order. As a result of this action, two events can\noccur: the closing order is executed, and the closing\norder is an error.\n\n\u2014 Close order error. This is the second type of event for\nthe action of placing an order to sell a financial asset.\n\nAsa result, I got a list of position states presented in Table 8-1. Perhaps\nthe controversial point in this is the \u201cStop and alert\u201d state. This occurs in\nthe event of an unsuccessful order to sell assets when closing positions.\n\nIt might make sense to try placing the order again. But this approach can\nbe unprofitable, since it is unclear at what price the asset will be sold. I\ndecided to take a conservative route and send myself an alert in case of\nunforeseen circumstances.\n\nIt is also worth paying attention to the actions \u201cAdd to queue of active\npositions\u201d and \u201cRemove from queue of active positions.\u201d When opening a\nnew position, it is necessary to understand the number of open positions\nin order to control them. The number of positions will grow steadily, and\ntherefore the request for a selection of active positions will also grow. To\n\nnrevent thic T added another tahle ta ctore a lict anf nnen nacitinne\n\n\u2014 Close position. This event can occur in several cases:\nfirst, when a signal to close a position is triggered, and\nsecond, when a signal comes from the risk control\nmodule; in our implementation, this is equivalent to\nclosing one of the auxiliary system orders, for example, a\ntake profit order. Third, an event about closing a position\ncan occur at the user's request, when he explicitly\ninstructs the system in the UI to close the position.\n\n\u2014 Close order executed. As a result of closing a position,\nitis necessary to reduce the amount of the financial\nasset in the portfolio to zero for this position. This\nmeans that if there is a certain amount of a financial\nasset left in the portfolio, it must be sold. That is, place\na sell order. As a result of this action, two events can\noccur: the closing order is executed, and the closing\norder is an error.\n\n\u2014 Close order error. This is the second type of event for\nthe action of placing an order to sell a financial asset.\n\nAsa result, I got a list of position states presented in Table 8-1. Perhaps\nthe controversial point in this is the \u201cStop and alert\u201d state. This occurs in\nthe event of an unsuccessful order to sell assets when closing positions.\n\nIt might make sense to try placing the order again. But this approach can\nbe unprofitable, since it is unclear at what price the asset will be sold. I\ndecided to take a conservative route and send myself an alert in case of\nunforeseen circumstances.\n\nIt is also worth paying attention to the actions \u201cAdd to queue of active\npositions\u201d and \u201cRemove from queue of active positions.\u201d When opening a\nnew position, it is necessary to understand the number of open positions\nin order to control them. The number of positions will grow steadily, and\ntherefore the request for a selection of active positions will also grow. To\nprevent this, I added another table to store a list of open positions.\n\nTable 8-1. List of Actions\n\nName Type\nTrigger: \u2018Start\u2019 Trigger\nSet the status \u2018Created\u2019 Act\nAdd to queue of active positions Act\nCreate an opening order Act\nWait Wait\nTrigger: \u2018Open order executed\u2019 Trigger\nSet the status to \u2018Open\u2019 Act\nCreate auxiliary orders Act\nWait Wait\nTrigger: \u2018Close position\u2019 Trigger\nCancel all auxiliary orders Act\n\nGo to \u2018Sell All\u2019 if the opening order is filled Act\nWait Wait\nTrigger: \u2018Open order error\u2019 Trigger\nGo to \u2018Ending the process\u2019 Act\nTrigger: \u2018Open order executed\u2019 Trigger\nSell All Description\nPlace a closing order Act\nWait Wait\nTrigger: \u2018Close order executed\u2019 Trigger\nGo to \u2018Ending the process\u2019 Act\nTrigger: \u2018Close order error\u2019 Trigger\n\n(continued)\n\nTable 8-1. (continued)\n\nName Type\n\nStop and alert Act\n\nEnding the process Description\nSet the status to \u2018Closed\u2019 Act\nRemove from queue of active positions Act\n\nEnd of process Description\n\nThis scheme is highly expandable. For example, when you develop a\ncapital management block, steps will be added to this scheme for placing\norders for additional purchase of a financial asset or its partial sale to fix\npart of the profit.\n\nEvents\n\nNowis the time to describe the functionality that sets positions on the\nprocess map in motion. More precisely, let's write command handlers that\nlead to the emission of process events.\nFirst, this is, of course, Start. This event occurs immediately after a\nposition is created and recorded in the database. Listing 8-31\nshows the implementation of the position creation command\nhandler OpenPositionCommandHandler. Let me remind you that the\nOpenPositionCommand command is called from the CheckSignalsCommand\ncommand if the result of calculating a signal to open a position is positive.\nIn this handler, the command for generating a new position is called\nwith a further call to the ProcessBot.Lite handler. Note that the position\ngenerator may return nu11 instead of a reference to an instance of the\nposition class. This is because you can limit the number of positions open\nat the same time.\n\nListing 8-31. OpenPositionCommandHandler\n\npublic async Task<bool> Handle(\nOpenPositionCommand request,\nCancellationToken cancellationToken)\n\nvar position =\n\nawait _mediator.Send(new GeneratePositionCommand()) ;\nif (position == null)\n\nreturn false;\n\nposition = await _positionRepository.SaveAsync(position) ;\nawait _mediator.Send(\nnew MoveEntityCommand(position.Id, (int)EventIds.\nStart));\n\nreturn true;\n\nListing 8-32 presents one of the simplest implementations of the\nGeneratePositionCommand command handler. First, this involves\nsearching for active positions. If at least one is found, then a new position\nwill not be created. You can change this condition according to your\ncapital management. In general, I separated position generation into a\nseparate command with the aim of using the capital management block\nin this. Because this is where the calculation of the required amount of a\nfinancial instrument for purchase occurs.\n\nSince capital management is quite simple, I did not separate it\ninto a separate entity but added settings to the strategy. I only need\nPositionBalanceCoeff, which determines the share of the current balance\nfor which a position should be opened.\n\nPlease note the positionCount calculation and rounding. This can be\nimproved by adding a decimals field to the goods entity. Goods is one of\nthe halves of a financial instrument. This contains two goods: base goods\nand quantity goods. For example, let's look at the financial instrument\nPOWI_USD. Base goods are shares of Power Integrations Inc. Quantity\ngoods are United States dollar. That is, when we place a buy order, we are\ngoing to buy base goods and spend quantity goods. For POWI, decimals\nwill be equal to 0, but what if the base goods are not a company share but a\ncryptocurrency such as Ethereum? Ethereum has 18 decimal places, which\nmeans decimals are very important.\n\nThis code can also be improved by adding lots. The fact is that not all\nexchanges are ready to trade in small volumes and use lots. For example,\noften to purchase a currency it is necessary to indicate not the quantity of\nthe desired currency but the number of lots. For example, you cannot buy\n15,000 Costa Rican Colon (CRC), but you can place an order to buy 10 lots,\neach of which is equal to 10,000 CRC.\n\nAlso in this code it is worth taking into account the broker's restrictions\non the purchase or sale of a financial asset. All brokers limit order sizes.\nYou can\u2019t buy a CRC for one cent, any more than you can place an order to\nsell a CRC worth $1 billion.\n\nListing 8-32. GeneratePositionCommand Handler\n\npublic async Task<Position> Handle(\nGeneratePositionCommand request,\nCancellationToken cancellationToken)\n\nList<Position> activePositions =\nawait _positionRepository.GetActivePositions(\n_strategyContext.Exchangeld,\n_strategyContext.Instrument.Id,\n_strategyContext.Strategy.Id) ;\n\nif (activePositions.Count > 0)\nreturn null;\n\ndecimal currentQuoteBalance = await _balanceQueries.\nGetBalanceAsync(\n_strategyContext.Exchangeld,\n_strategyContext.Instrument.Id,\n_strategyContext.Strategy.Id,\n_strategyContext .Instrument .QuoteGoodsId\n)\ndecimal currentPrice = _strategyContext.Candles.\nFirst().Close;\ndecimal positionTotal =\n_strategyContext.Strategy.PositionBalanceCoeff *\ncurrentQuoteBalance;\ndecimal positionCount =\nMath.Round(positionTotal / currentPrice, 0,\nMidpointRounding.ToZero) ;\n\nPosition position = new()\n\n{\nId = Guid.NewGuid(),\nExchangeId = _strategyContext.Exchangeld,\nInstrumentId = _strategyContext.Instrument.Id,\nStrategyId = _strategyContext.Strategy.Id,\nCount = positionCount,\n\nhs\n\nreturn position;\n\nThe events \u201cOpen order executed,\u201d \u201cOpen order error,\u2019 \u201cClose order\nexecuted,\u2019 and \u201cClose order error\u201d are emitted only in response to events\nof changes in the status of orders at the broker. To process them, I created\n\none command, HandleFinal0rderStatusCommand, which parses the order\nstatus into a new system order status and events for position processing.\nListing 8-33 shows the first part of the implementation of a handler for\nthis command. This is where the new status of the system order is parsed\nand saved.\n\nListing 8-33. HandleFinalOrderStatusCommand Handler, Part 1\n\npublic async Task<bool> Handle(\nHandleFinal0rderStatusCommand request,\nCancellationToken cancellationToken)\n\nSystemOrder systemOrder =\nawait _systemOrderRepository\n-GetAsync (request .Order. SystemOrderId) ;\n\nsystemOrder.Status = request.Status switch\n\n{\nOrderStatus.Canceled => SystemOrderStatus.Canceled,\nOrderStatus.Error => SystemOrderStatus.Error,\n_ => SystemOrderStatus.Closed\n\nis\n\nawait _systemOrderRepository.UpdateAsync(systemOrder) ;\n\nListing 8-34 shows the implementation of the second half of the\nfunction. Depending on the new status of the system order, the required\nEventId type is selected, with a further call to the position process handler\ncommand. Please note that the \u201cOpen order executed\u201d event is generated\nnot only in response to the Closed status of the system order but also\nto the Cancelled status. I also introduced another PositionOrderType\nfield for the system order. This is necessary to understand the purpose of\ncreating this order within the position. And it can take three values: Open,\nAuxiliary, and Close. As a consequence, the reaction of position movement\n\nthrough the process is carried out only if the status of Open or Close\nsystem orders changes. In this implementation, we agreed that Auxiliary\nsystem orders are created only according to the settings in Risk Control;\nthat is, they affect only the position closing command.\n\nListing 8-34. HandleFinalOrderStatusCommand Handler, Part 2\n\nEventIds eventId = systemOrder.PositionType switch\n\n{\n(PositionOrderType.Open) => systemOrder.Status switch\n\n{\nSystemOrderStatus.Closed\nor SystemOrderStatus.Canceled => EventIds.\nOpenOrderDone,\nSystemOrderStatus.Error => EventIds.OpenOrderError,\n_ => throw new Exception(\"unknown order status\")\nbs\nPositionOrderType.Close => systemOrder.Status switch\n{\nSystemOrderStatus.Closed\nor SystemOrderStatus.Canceled => EventIds.\nCloseOrderDone,\nSystemOrderStatus.Error => EventIds.\nCloseOrderError,\n_ => throw new Exception(\"unknown order status\")\nbs\n\n_ => throw new Exception(\"unknown position type\")\n\nhs\n\nawait _mediator.Send(\nnew MoveEntityCommand(systemOrder.PositionId, (int)\neventId));\n\nreturn true;\n\nI won't bore you with the implementation of event handlers\nfor changing order statuses at the broker. They perform only two\nimportant actions: saving the new status to the database and calling the\nHandleFinal0rderStatusCommand command. I will only note that these\nevents can be implemented in different ways. You can create several events\nfor each status, or you can create one ChangeOrderStatusEvent and pass\nthe new order status as a parameter.\n\nwe still need to implement the initiation of the last event from the\nposition processing process; this is \u201cClose position.\u201d This event can\nbe emitted from two command handlers. In the first case, it is emitted\nwhen checking the signal to close positions, ClosePositionsCommand,\nand all active positions are closed. And in the second case, it is\nemitted when processing the CheckSystemOrdersCommand command.\nCheckSystemOrdersCommand is called in the event handler for the arrival of\nnew candles.\n\nListing 8-35 shows the implementation of the ClosePositionsCommand\ncommand handler. This checks for active positions. And if there are any,\nthen the position process is processed with the ClosePosition event.\n\nListing 8-35. ClosePositionsCommand Handler\n\npublic async Task<bool> Handle(\nClosePositionsCommand request,\nCancellationToken cancellationToken)\n\nvar openPositions =\nawait _positionRepository\n-GetActivePositions(\n_strategyContext.Exchangeld,\n_strategyContext. Instrument. Id,\n_strategyContext. Strategy. Id) ;\n\nif (!openPositions.Any())\nreturn true;\n\nforeach (Position openPosition in openPositions)\nawait _mediator\n.Send(\nnew MoveEntityCommand(\nopenPosition.Id,\n(int)EventIds.ClosePosition)) ;\n\nreturn true;\n\nThe HandleFinal0rderStatusCommand command handler looks more\ninteresting. But first, let\u2019s look at auxiliary system orders. I implemented\nthree types of such orders, and to configure them, I allocated a separate\nRiskControl entity. The identifier of this was placed in the field of the\nStrategy class.\n\nStop loss order. This order sends a signal to close a position if the\ncurrent price of an asset is lower than the price of the asset at the time of\ncreating this order minus a certain percentage specified in the settings. In\nother words, this system order outlines the lower limit of the asset price.\nAnd if the price drops below this level, then the position is closed.\n\nTake profit order. The logic of this order is similar to the logic of the\nStop loss order. Only it outlines the upper limit. If the asset price rises\nabove this level, the position is closed.\n\nTrailing stop order. | covered this in detail in Chapter 3 when we\ndiscussed risk control.\nThe idea of this order is to set three boundaries.\n\n\u2014 The Profit border behaves exactly the same as the Take\nProfit order, except that this level does not depend on\nthe initial price of the asset, but on the price, which\nmoves according to a certain logic.\n\n\u2014 The Stop border is the opposite of Profit border. That is,\nif the asset price falls below this value, the position\nis closed.\n\n\u2014 The Decision border is the line for making a decision to\nchange the target price, relative to which the Profit and\nStop borders are calculated. When the asset price\nreaches this, a special signal is checked, and if it is true,\nthen the target price is changed. I also introduced the\nBorderChangeCoeff parameter into the settings, which\nis responsible for reducing the shift of the Profit and\nStop borders. That is, these boundaries become closer\nto each other with each change in the target price. This\nmeans that with each positive decision, the probability\nof this system order being triggered increases.\n\nListing 8-36 shows the implementation of the main\nCheckSystem0rdersCommand command handler function. This is triggered\nwhen new candles arrive. I get all active positions and their system orders.\nNext, depending on their type, I check the conditions.\n\nListing 8-36. CheckSystemOrdersCommand Handler\n\npublic async Task<bool> Handle(\nCheckSystemOrdersCommand request,\nCancellationToken cancellationToken)\n\nList<Position> activePositions =\nawait _positionRepository.GetActivePositions(\n_strategyContext.Exchangeld,\n_strategyContext.Instrument.Id,\n_strategyContext.Strategy.Id) ;\nList<SystemOrder> systemOrders =\nawait _systemOrderRepository.GetByPositionIdAsync(\n\nactivePositions.ConvertAll(p => p.Id).Distinct());\n\nforeach (SystemOrder systemOrder in systemOrders)\n{\nvar result = systemOrder.Type switch\n{\nOrderType.StopLoss =>\nawait StopLoss_UpdatePrice(systemOrder) ,\nOrderType.TakeProfit =>\nawait TakeProfit_UpdatePrice(system0rder),\nOrderType.Trailing =>\nawait Trailing UpdatePrice(systemOrder) ,\n_ => true\nis\n}\n\nreturn true;\n\nListing 8-37 shows the implementation of handlers for stop loss and\ntake profit orders. In fact, both of these processors differ from each other\nonly by the sign of comparison with the current price.\n\nListing 8-37. Stop Loss and Take Profit Orders Handlers\nImplementation\n\nprivate async Task<bool> StopLoss_UpdatePrice(SystemOrder\nsystemOrder)\n{\ndecimal currentPrice = _strategyContext.CurrentPrice();\ndouble protectOrderLessPriceCoeff =\n_strategyContext.RiskControl.ProtectOrderLess\nPriceCoeff! .Value;\ndecimal protectPrice =\nsystemOrder.Price!.Value * (1 - (decimal)\nprotectOrderLessPriceCoeff) ;\nif (currentPrice <= protectPrice)\nawait ClosePosition(systemOrder) ;\n\nreturn true;\n\n}\n\nprivate async Task<bool> TakeProfit_UpdatePrice(SystemOrder\nsystemOrder)\n{\ndecimal currentPrice = _strategyContext.CurrentPrice();\ndouble protectOrderHighPriceCoeff =\n_strategyContext.RiskControl.\nProtectOrderHighPriceCoeff! .Value;\ndecimal protectPrice =\nsystemOrder.Price!.Value * (1 + (decimal)\nprotectOrderHighPriceCoeff) ;\n\nThe CheckProfitBorder and CheckStopBorder functions look almost\nidentical to the StopLoss_UpdatePrice and TakeProfit_UpdatePrice\nfunctions. With one difference, the new border depends not only on the\ncoefficient specified in the settings but also on the number of shifts of the\nborder itself (the ChangedCount field in the system order). Listing 8-39\nshows an implementation of one of these functions. Pay attention to the\nformula for calculating the boundary.\n\ntrailingProfitBorderCoeff: The coefficient by\nwhich the border is higher than the target price. For\nexample, if you set this to 0.1, it means that if the\ncurrent price of the asset exceeds the target price by\n10%, then you need to close the position.\n\ntrailingBorderChangeCoeff: The coefficient by\nwhich the border narrows as the number of target\nprice shifts increases. For example, if you set this\nvalue to 0.05, this means that with each border shift,\ntrailingProfitBorderCoeff will decrease by 5%.\n\nLet's look at an example.\n\nIf ChangedCount = 0, then trailingBorderChangeCoeff will be equal\nto 95% of the power of zero. And any number to the zero power is always\nequal to 1. That is, the upper limit will be equal to Price * (100% + 10%*1) =\n110% Price.\n\nWhen ChangedCount = 1, then trailingBorderChangeCoeff will be\nequal to 95% to the first power, that is, equal to 95%. This means the limit\nwill be equal to Price * (100% + 10% * 95%) = 109.5% Price. That is, the\nupper limit shifted from the target price not by 10% but by 9.5%.\n\nWhen ChangedCount = 2, then the upper limit will be equal to Price *\n(100% + 10% * 95% * 95%) = 109.025% Price. And so on. The more shifts, the\nnarrower the border.\n\nThe CheckProfitBorder and CheckStopBorder functions look almost\nidentical to the StopLoss_UpdatePrice and TakeProfit_UpdatePrice\nfunctions. With one difference, the new border depends not only on the\ncoefficient specified in the settings but also on the number of shifts of the\nborder itself (the ChangedCount field in the system order). Listing 8-39\nshows an implementation of one of these functions. Pay attention to the\nformula for calculating the boundary.\n\ntrailingProfitBorderCoeff: The coefficient by\nwhich the border is higher than the target price. For\nexample, if you set this to 0.1, it means that if the\ncurrent price of the asset exceeds the target price by\n10%, then you need to close the position.\n\ntrailingBorderChangeCoeff: The coefficient by\nwhich the border narrows as the number of target\nprice shifts increases. For example, if you set this\nvalue to 0.05, this means that with each border shift,\ntrailingProfitBorderCoeff will decrease by 5%.\n\nLet's look at an example.\n\nIf ChangedCount = 0, then trailingBorderChangeCoeff will be equal\nto 95% of the power of zero. And any number to the zero power is always\nequal to 1. That is, the upper limit will be equal to Price * (100% + 10%*1) =\n110% Price.\n\nWhen ChangedCount = 1, then trailingBorderChangeCoeff will be\nequal to 95% to the first power, that is, equal to 95%. This means the limit\nwill be equal to Price * (100% + 10% * 95%) = 109.5% Price. That is, the\nupper limit shifted from the target price not by 10% but by 9.5%.\n\nWhen ChangedCount = 2, then the upper limit will be equal to Price *\n(100% + 10% * 95% * 95%) = 109.025% Price. And so on. The more shifts, the\nnarrower the border.\n\nListing 8-39. CheckProfitBorder Function\n\nbool CheckProfitBorder()\n{\ndouble trailingProfitBorderCoeff =\n_strategyContext.RiskControl\n- TrailingProfitBorderCoeff! .Value;\ndouble trailingBorderChangeCoeff =\n_strategyContext .RiskControl\n-TrailingBorderChangeCoeff! .Value;\ntrailingBorderChangeCoeff =\nMath. Pow( (1-trailingBorderChangeCoeff), systemOrder.\nChangedCount! .Value) ;\ntrailingProfitBorderCoeff *= trailingBorderChangeCoeff;\n\ndecimal protectPrice =\nsystemOrder.Price!.Value * (1 + (decimal)\ntrailingProfitBorderCoeff) ;\n\nreturn currentPrice >= protectPrice;\n\nThe CheckBorder function, the implementation of which is presented\nin Listing 8-40, is a check for crossing a price border. If this happens, the\nsignal is checked. And it is the significance of this that determines the need\nto shift the target price.\n\nListing 8-40. CheckBorder Function\n\nasync Task<bool> CheckBorder()\n{\ndouble trailingDecisionCoeff =\n_strategyContext.RiskControl.\nTrailingDecisionCoeff! .Value;\ndecimal decisionPrice =\n\nsystem0rder.Price! .Value\n\n* (1 + (decimal)trailingDecisionCoeff) ;\nif (currentPrice <= decisionPrice)\n\nreturn false;\n\nSignalData signalData = await _mediator.Send(\nnew CalculateSignalCommand(\n_strategyContext.RiskControl.\nTrailingDecisionSignalld! .Value));\nreturn signalData.SignalValue ?? false;\n\nProcess Acts\n\nI showed the implementation of all the commands that create events that\naffect position processing. Now it\u2019s time to implement the step handlers.\nFirst you need to add them to the IServiceCollection. I'll remind you\nthat every step in a process must implement the IProcessAct interface,\nbut that won\u2019t be enough for us. Because in the future we will also\nneed to implementa class that implements the IProcessActFactory\ninterface, this has only one function for getting the IProcessAct\nimplementation by the identifier specified in the process step. To create\nthe steps, I will use IServiceProvider, and I will receive acts using the\nGetRequiredKeyedService function.\n\nThis means that each of the classes must contain a key. So I created\nanother interface, shown in Listing 8-41, called ICoreAct, with a static\nActId field. All acts will implement this interface.\n\nListing 8-41. ICoreAct Interface\n\npublic interface ICoreAct : IProcessAct\n\n{\nstatic ActIds ActId { get; }\n\nListing 8-42 shows part of the IServiceCollection implementation\nwhere I add all the acts. To do this, I find all classes of the current assembly\nthat implement the ICoreAct interface, and then I find the actld for each\nof them with the name of the static field ActId. Then I add them to the\nIServiceCollection with a key equal to actld.\n\nListing 8-42. Add Acts to IServiceCollection\n\nvar acts = AppDomain.CurrentDomain.GetAssemblies()\n\u00abSelectMany(assembly => assembly.GetTypes())\n-Where(type =>\ntypeof (ICoreAct) .IsAssignableFrom(type)\n&& !type.IsInterface) ;\n\nforeach (var act in acts)\n{\nActIds actId =\n(ActIds) act!\n-GetProperty(nameof(ICoreAct.ActId))!\n-GetValue(null, null)!;\nservices .AddKeyedTransient (typeof(IProcessAct),\nactId, act);\n\nAccordingly, the function for obtaining an instance of a class that\nimplements IProcessAct will look like that shown in Listing 8-43.\n\n\u2014 CreateCloseOrderAct. This is the action to create a\nclosing order.\n\n\u2014 AlertAct. At this step, the position will stop and make a\nlog entry marked error.\n\n\u2014 RemoveFromQueueAct. This removes a position from\nthe active list.\n\nI won't go into simple steps like AlertAct or PutToQueueAct. The logic\nbehind this is quite simple. Let's look at the CreateAuxiliaryOrdersAct\nstep. Listing 8-44 shows a partial implementation of the Make function.\nThe greatest interest in this fragment is the process of determining the\ntarget price for a new system order. Because an opening order can be\nexecuted involving two deals with different prices, I decided that the target\nprice in this case would be the average of the prices of all deals of the\nopening order.\n\nIn this I get all system position orders. After that, I select an opening\norder. I assume in advance that it has already been created. If not, then it\nis logical that the step will end with an error. After that, I receive an order\nplaced by the broker and call the AvgPrice function to obtain the average\nprice value.\n\nListing 8-44. Make Function of CreateAuxiliaryOrdersAct\n\nList<SystemOrder> systemOrders = await\n_systemOrderRepository.GetByPositionIdAsync(entityId) ;\nSystemOrder openSystemOrder =\nsystemOrders.First(o => 0.PositionType ==\nPositionOrderType.Open) ;\nList<Order> orders = await _orderRepository.GetBySystemOrder\nAsync(openSystemOrder. Id) ;\n\n\u2014 CreateCloseOrderAct. This is the action to create a\nclosing order.\n\n\u2014 AlertAct. At this step, the position will stop and make a\nlog entry marked error.\n\n\u2014 RemoveFromQueueAct. This removes a position from\nthe active list.\n\nI won't go into simple steps like AlertAct or PutToQueueAct. The logic\nbehind this is quite simple. Let\u2019s look at the CreateAuxiliaryOrdersAct\nstep. Listing 8-44 shows a partial implementation of the Make function.\nThe greatest interest in this fragment is the process of determining the\ntarget price for a new system order. Because an opening order can be\nexecuted involving two deals with different prices, I decided that the target\nprice in this case would be the average of the prices of all deals of the\nopening order.\n\nIn this I get all system position orders. After that, I select an opening\norder. I assume in advance that it has already been created. If not, then it\nis logical that the step will end with an error. After that, I receive an order\nplaced by the broker and call the AvgPrice function to obtain the average\nprice value.\n\nListing 8-44. Make Function of CreateAuxiliaryOrdersAct\n\nList<SystemOrder> systemOrders = await\n_systemOrderRepository.GetByPositionIdAsync(entityld) ;\nSystemOrder openSystemOrder =\nsystemOrders.First(o => 0.PositionType ==\nPositionOrderType.Open) ;\nList<Order> orders = await _orderRepository.GetBySystemOrder\nAsync(openSystemOrder. Id) ;\n\nOrder openOrder = orders.First();\ndecimal avgPrice = openOrder.AvgPrice();\n\nif (riskControl.CreateProtectOrderLess)\n\n{\nawait _mediator.Send(new CreateSystemOrderCommand\n{\nPositionId = entitylId,\nType = OrderType.StopLoss,\nPositionType = PositionOrderType. Auxiliary,\nCount = openOrder.Count,\nPrice = avgPrice\n})3\n}\npublic class Order\n{\npublic decimal AvgPrice()\n{\nif (Deals == null || !Deals.Any())\nreturn 0;\ndecimal price =\nDeals.Sum(d => d.Price * d.Count)\n/ Deals.Sum(d => d.Count);\nreturn price;\n}\n\nI would also like you to pay attention to CreateCloseOrderAct, where\nall the purchased assets are sold as a result of the position process. Since\nlintend to complicate the process of working on a position, the logic of\nselling all assets purchased as a result of executing an opening order would\nbe incorrect. This is because as a result of position processing, steps may\n\nbe added for an additional purchase or partial sale of a financial asset.\nTherefore, in this step, I select all orders placed on the exchange and\ncalculate the volume of the asset based on the deals executed as a result of\ntheir execution. Listing 8-45 shows an implementation of this algorithm.\n\nPlease note that in this case it is necessary not to forget about side\norders to correctly determine the sign of the amount of the asset in the\ntransaction.\n\nListing 8-45. Make Function of CreateCloseOrderAct\n\npublic async Task<bool> Make(Guid entityId, string magicString)\n{\nList<Order> orders = await _orderRepository.GetBySystemOrde\nrAsync(entityId) ;\ndecimal balance = orders\n\u00abSum(o =>\no.Deals.Sum(\ndeal =>\no.Side ==\nOrderSide.Buy\n? deal.Count\n: -deal.Count));\nif (balance > 0)\n{\nawait _mediator.Send(new CreateSystemOrderCommand\n{\nPositionId = entityld,\nType = OrderType.MarketSell,\n\nPositionType = PositionOrderType.Auxiliary,\nCount = balance\n3\n}\n\nreturn false;\n\nSummary\n\nIn this chapter, I tried to reveal the implementation of the main module of\nthe system in as much detail as possible. I showed how to work with the\ncontext, which significantly speeds up the calculation of strategies. We also\nimplemented a block for calculating signals and indicators. We created a\nprocess bot lite and used it to describe the life cycle of the position. This is\nwhat determines whether the system will bring you income or not.\n\nIncreasing the complexity and changing the calculation logic, adding\nindicators, and changing the process map will have the greatest impact on\nthe efficiency of your system.\n",
                        "extracted-code": ""
                    }
                ]
            },
            {
                "chapter_id": 9,
                "chapter_name": "CHAPTER 9",
                "chapter_path": "./screenshots-images-2/chapter_9",
                "sections": [
                    {
                        "section_id": 9.1,
                        "section_name": "Approaches to Final\nImplementation",
                        "section_path": "./screenshots-images-2/chapter_9/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_9/section_1/c2de91e6-71e8-497d-9aa3-5cfd146550aa.png",
                            "./screenshots-images-2/chapter_9/section_1/303f6bad-6152-48d4-af2d-343515d8ffed.png",
                            "./screenshots-images-2/chapter_9/section_1/7ea322eb-4ed7-4055-8ab6-08f1d687da1c.png",
                            "./screenshots-images-2/chapter_9/section_1/2645a4b0-ed70-47a5-8f1e-59788ac09c92.png",
                            "./screenshots-images-2/chapter_9/section_1/d3c5e600-a6f3-4b61-a6b9-616ba0fac47c.png",
                            "./screenshots-images-2/chapter_9/section_1/c291749b-fecc-4900-9df2-ba90eabe0dd7.png",
                            "./screenshots-images-2/chapter_9/section_1/0f3ab7d2-748a-4a3c-aedf-e50da6f1c724.png",
                            "./screenshots-images-2/chapter_9/section_1/a94c054f-49b4-464f-a32d-1b6f3fb46915.png",
                            "./screenshots-images-2/chapter_9/section_1/7604e494-51f0-482b-8b0b-e72ac2bb2ec5.png",
                            "./screenshots-images-2/chapter_9/section_1/3a5af58d-6579-430f-9098-0b80853e6594.png",
                            "./screenshots-images-2/chapter_9/section_1/51706c17-9d98-48f5-8d42-3b0f86f3eaca.png",
                            "./screenshots-images-2/chapter_9/section_1/a3ac41a5-2a9a-44b7-9901-845e89a3918a.png",
                            "./screenshots-images-2/chapter_9/section_1/213059b6-ad57-4a53-b17c-4011ae3ba659.png",
                            "./screenshots-images-2/chapter_9/section_1/efa728c4-0224-4d99-bd0c-41beb512fa73.png",
                            "./screenshots-images-2/chapter_9/section_1/a42b5ef6-9c7a-4cb3-ae86-7473a3b40d1f.png",
                            "./screenshots-images-2/chapter_9/section_1/9cf8c951-a290-4c57-bef4-75723cf7bd1c.png",
                            "./screenshots-images-2/chapter_9/section_1/b21e4a83-8aff-4d25-80d8-bfaef1882f29.png",
                            "./screenshots-images-2/chapter_9/section_1/59f636a0-8483-4623-9eea-498418bb1836.png",
                            "./screenshots-images-2/chapter_9/section_1/2c1e5213-a2a6-4fa4-a872-21b9777ca3e9.png",
                            "./screenshots-images-2/chapter_9/section_1/42a4382c-1d87-4b2c-b99d-8bc2e5cb65f4.png",
                            "./screenshots-images-2/chapter_9/section_1/6e4e7c30-0a06-43c4-ab51-715c63aaabac.png",
                            "./screenshots-images-2/chapter_9/section_1/f76973ca-0076-4ba8-9140-00fe36556f8b.png",
                            "./screenshots-images-2/chapter_9/section_1/789cdb52-7d85-4579-92c6-64a09b0811f1.png",
                            "./screenshots-images-2/chapter_9/section_1/4f5462da-869f-448e-941e-36b310de18d5.png",
                            "./screenshots-images-2/chapter_9/section_1/b49a54d8-a013-4f6b-9e0c-82314f5beffd.png",
                            "./screenshots-images-2/chapter_9/section_1/0217af4e-2314-44ce-8682-107b46c68f43.png",
                            "./screenshots-images-2/chapter_9/section_1/76e294cf-9ba0-4225-8266-f397ccdce2df.png",
                            "./screenshots-images-2/chapter_9/section_1/e78ff3b3-31f8-4da4-a56a-956c842ae18b.png",
                            "./screenshots-images-2/chapter_9/section_1/c216a3f4-d249-46e6-bf8a-40123836c0b0.png",
                            "./screenshots-images-2/chapter_9/section_1/ea9963e7-de1b-4c47-a357-b1f37b29f14b.png",
                            "./screenshots-images-2/chapter_9/section_1/819a793f-5e88-4fd0-a2bc-ae778aff6e8d.png",
                            "./screenshots-images-2/chapter_9/section_1/f4e44cf2-ce5e-4b22-b244-eaefab761863.png",
                            "./screenshots-images-2/chapter_9/section_1/db5c2f18-1c33-4b89-8567-a46573f870a5.png",
                            "./screenshots-images-2/chapter_9/section_1/e3771478-d3ef-40d0-9b04-4b61e30e699d.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In previous chapters, I described in detail how to create the main blocks\nof a trading system. I provided a large amount of information to improve\nand build a trading system, right down to the architectural solution.\nThere is another important aspect that has never been sufficiently\nexplored: the infrastructure issues. In this chapter, I will cover how to\ndeploy your services. Of course, this book is not as comprehensive as the\ndocumentation of tools discussed, but it will give you resources for further\nresearch and show how you can build a fairly complex infrastructure on\nyour home computer.\n\nIn this chapter, I would like to provide you with information on how to\ndeploy and run a project using Docker and Kubernetes. I will also tell you\nhow I deploy the infrastructure I need.\n\nBinance Adapter\n\nBefore launching the application, you need to create it. In previous\nchapters, I paid a lot of attention to the internal services of the system, or\nrather even just the domain layer of it, without details of the interaction\nbetween the database and peripheral services.\n\nIn this chapter, I will show how to create a working application. Let\u2019s\nlaunch an adapter to one of the largest and most popular cryptocurrency\nexchanges: Binance.\n\nI described in detail the part of the system related to interaction with\nexchanges in Chapter 4. Here I would like to remind you of the main goals\nand architectural features of this block.\n\nThe following is the main functionality that I included in the block of\ninteraction with exchanges:\n\n\u00a2 Possibility of placing orders\n\u00a2 Possibility of order cancellation\n\n\u00a2 Providing information on updating order statuses and\nexecuting trade transactions\n\n\u00a2 Providing trade data\n\nIn this chapter, I show how to implement the last point because it\nclearly demonstrates how much data you have to deal with.\n\nMy goal is to implement an application that connects to Binance to\nreceive small candlestick updates and put this data into a Kafka topic.\n\nImplementation\n\nTo implement the application, I created an ASP.NET project. In\n\nthe Main function, which was added by the only hosted service\nCollectDataHostedService, I implement the receiving data from Binance,\nas shown in Listing 9-1. This is also where I configured the logging and\ncontroller explorer.\n\nListing 9-1. Main Function\n\npublic static void Main(string[] args)\n{\n\nvar builder = WebApplication.CreateBuilder(args) ;\n\nbuilder. Services.AddControllers();\nbuilder. Services. AddEndpointsApiExplorer();\n\nbuilder. Services .AddHostedService<CollectDataHostedS\nervice>();\n\nstring logLevel = Environment\n-GetEnvironmentVariable(\"LOG_LEVEL\") ?? \u201cTrace\u201d;\nbuilder.Services.AddLogging(c =>\n\n{\nc.AddConsole()\n\u00abSetMinimumLevel (Enum.\nParse<LogLevel>(loglevel, true));\n})3\n\nWebApplication app = builder.Build();\n\napp.MapControllers();\n\napp.Run();\n\nTo quickly check the functionality of the application, I added a single\ncontroller, HealthCheckController (see Listing 9-2). Here I have\nimplemented two functions: liveness and readiness. I will tell you later why\nthere are two of them and what purposes each of them serves. But for now\nthey just return a response with a status of 200 Success. Please note that\nwhen you call the /status/liveness method, you will receive the response\n\u201cIt\u2019s alive!!!\u201d I added this as a simple visual check of the app\u2019s functionality.\n\nListing 9-2. Status Controller\n\n[Apicontroller]\n[Route(\"status\")]\npublic class HealthCheckController: Controller\n\n{\n[HttpGet (\"liveness\") ]\n\npublic ActionResult Liveness()\n{\nreturn Ok(\"It's alive!!!\");\n\n}\n\n[HttpGet (\"readiness\") ]\npublic ActionResult Rediness()\n\n{\nreturn 0k();\n\nListing 9-3 shows the implementation of the constructor for the\nCollectDataHostedService class. For this I use two popular packages:\none for integration with Binance (https: //www. nuget. org/packages/\nBinance.NET) and the other for interaction with Kafka (https ://www.\nnuget . org/packages/Confluent. Kafka). In the constructor, I instantiate\nthe Binance and producer client class for Kafka. The Kafka producer is a\nKafka client that writes messages to a topic.\n\nListing 9-3. Hosted Service, Part 1\n\npublic CollectDataHostedService(\nILogger<CollectDataHostedService> logger)\n\n{\n_logger = logger;\n\n_exchange = \"binance\";\n\n_symbol = Environment\n-GetEnvironmentVariable(\"SYMBOL\")\n?? \u201cbtcusdt\";\n\n_bootstrapServers =\nEnvironment\n-GetEnvironmentVariable(\"KAFKA_BOOTSTRAP_\nSERVERS\")! ;\n_binanceSocketClient = new BinanceSocketClient();\n\n_producer =\nnew ProducerBuilder<Null, string>\n(new ProducerConfig()\n\n{\n\nBootstrapServers = _bootstrapServers\n})\n-Build();\n\nThe StartAsync function subscribes to the Binance exchange candle\nupdate event. When subscribing, you must pass the message arrival\nevent handler. Listing 9-4 shows an implementation of this; here I log the\nmessage with a LogLevel trace and produce to a Kafka topic.\n\nListing 9-4. Hosted Service, Part 2\n\npublic Task StartAsync(CancellationToken cancellationToken)\n{\nvar klineSubscriptionResult =\n_binanceSocketClient.SpotApi.ExchangeData\n. SubscribeToKlineUpdatesAsync(\nsymbol: _symbol,\ninterval: KlineInterval.OneMinute,\n\nonMessage: HandleDataEvent,\ncancellationToken) ;\n\nreturn klineSubscriptionResult;\n\n}\n\npublic Task StopAsync(CancellationToken cancellationToken)\n{\n\nreturn _binanceSocketClient.UnsubscribeAllAsync() ;\n\n}\nprivate void HandleDataEvent (DataEvent<IBinanceStreamKlineData>\nmessage)\n{\nstring KafkaMessage = JsonConvert.SerializeObject (message) ;\n_logger . LogTrace(KafkaMessage) ;\nstring topic = $\"{_exchange} {_symbol}\";\n_producer\n-ProduceAsync(\ntopic,\nnew Message<Null, string>()\n{Value = KafkaMessage}) ;\n}\n\nIf you set the KAFKA_BOOTSTRAP_SERVERS environment\nvariable with the current URL to your Kafka server instance and run the\napplication, then in the logs you will see a stream of messages with current\ninformation about the minute candles of the BTC_USDT pair.\n\nDocker\n\nIn this section, I will expand on Docker. I'll explain how to create a Docker\ncontainer based on your application and run it on your computer.\n\nHistory\n\nBefore we begin, I will explain how containerization technology\ncame to be.\n\nOnce upon a time, when computers started to connect to networks,\ncompanies called providers were involved in developing the infrastructure.\nFor example, if in those days you wanted your project or website to be\npresent on the Internet, then you had to buy or rent an entire server from a\nprovider, which, of course, was not cheap.\n\nThere was a big problem with this approach: idle resources. Imagine\nthat you had a news site whose peak load occurred only in the morning\nhours. Of course, you would have to rent a server designed for peak\nload. But what would happen the rest of the time? Your server would\nsimply be idle. That is, it would cost money as if your site were constantly\nexperiencing peak load.\n\nThe solution to this problem was the development of virtual machine\ntechnology, which led to cloud providers. Cloud providers purchased\nand set up physical servers, and they rent these virtual machines to\ntheir clients. Virtualization technology has made it possible to run many\nindependent operating systems on one physical server and allocate the\nrequired amount of resources to each of them. Previously, you were forced\nto rent an entire physical server. Now you can rent the resources of the\nphysical server or servers you need and, if necessary, easily increase these\nresources.\n\nIt was at this time that companies such as Amazon Web Services,\nDigitalOcean, Google Cloud, Microsoft Azure, and others were created.\nThese companies took care of all the low-level work, such as optimizing\n\nphysical servers and improving network performance. Thanks to\n\nthis approach, a separation of application programmers and system\nadministrators occurred. Now you, as a developer, no longer need to\nunderstand the intricacies of setting up a network or operating a physical\nserver. Now the programmer can fully concentrate on writing code.\n\nThis approach ensured a boom in Internet projects and startups.\nAnd as applications grew, so did the complexity. This complexity was\nexpressed not only in the algorithmic or logical complexity of the project\nbut also in infrastructural complexity. Projects began to consist not of\none large monolithic service but of many different components, each of\nwhich requires its own set of dependencies. For example, two different\napplications might use two versions of TypeScript. See Figure 9-1.\n\n\u2018 Virtual Machines\n\nFigure 9-1. Virtual machine\n\nBecause of increasing complexity, keeping all applications within a\nsingle operating system has become difficult. An obvious idea arose about\ndistributing applications across different virtual machines. This approach\nworks and is used in many companies. But there are two problems with\nthis approach.\n\nThe first is the growing complexity. The more virtual machines\nyou have, the more different types of applications you have, and the\nmore difficult it is to support it all. Not to mention, there's updating or\nchanging the configuration. Added to all this complexity is the difficulty\nof monitoring all these virtual machines and of deploying different\n\nenvironments. Developers need a development environment, and testers\nneed a test environment. A good practice before releasing a build is to doa\nfinal check of a new version in a stage environment, which is as similar as\npossible to the production environment.\n\nThe second problem is that the virtual machine takes up a lot of server\nresources. Each virtual machine requires its own operating system. When\nyou have dozens of them, this is not so noticeable, but when you have a lot\nof them, they begin to consume a significant amount of server resources\nand therefore money.\n\nTo solve this problem, containerization technology was invented.\nCurrently, the most popular platform for this is Docker. The point of\nDocker is that instead of running the application directly on the operating\nsystem, it launches a Docker process within which the target application\nruns. From the operating system's point of view, such a process looks\nlike just another process; that is, it looks like just another application\nthat does something. And inside each Docker process, each running\napplication thinks that it is unique in the entire operating system with all\nits dependencies, users, and environment variables.\n\nDocker, unlike a virtual machine, is very lightweight; it only provides\nsecurity. That is, it ensures that one application cannot access other\napplications and processes on this system and ensures that the network\noperates to ensure communication between containers.\n\nWhy Is This Needed?\n\nHow will this technology be useful for our system? Our trading system\nis built on the microservices architecture. I described in detail the\nadvantages of this approach in Chapter 4. Here I will highlight the main\nadvantages of this approach, which are scalability and independence.\nScalability is necessary to quickly and easily increase the resources\nneeded for a portion of the system. For example, with an increase in the\nnumber of active strategies, we need to increase the resources of the\n\napplication responsible for processing trading information. At the same\ntime, there is no need to increase the resources for the UI part of the\napplication.\n\nIndependence is one of the main reasons to choose a microservices\narchitecture. If problems are identified in one part of the system, the\nremaining parts will not be affected. Imagine an example when you\ndiscovered an error in the integration block with one of the exchanges\nand you need to update the application to fix this error. In the case of a\nmonolithic architecture, the entire application will restart, which means\nthat all strategies that do not even trade on this exchange will stop working.\nFor me this option is unacceptable.\n\nThe presence of a large number of microservices presupposes the\npresence of a convenient infrastructure. Containerization technology is\nperfect for this.\n\nThe trading system also uses third-party applications for its work,\nsuch as Postgres and Kafka. Both of these applications are easier and\nmore convenient to run as containers rather than as processes on your\noperating system.\n\nIn summary, knowledge and understanding of Docker is key to\ndeveloping the trading system described in this book.\n\nDocker Components\n\nUnderstanding Docker is built on understanding the basic concepts of it.\nThe entire Docker technology is built on several key concepts.\n\n\u00a2 Docker engine. This is the main Docker application.\nThis is also called a platform. This is what ensures\nthe operation of Docker processes and network\ninteractions between them. One easy way to install\nthe Docker engine is to use Docker Desktop. Docker\n\nDesktop contains the Docker engine and many\nother components. Installation distributions can be\ndownloaded from the official Docker website.\n\n\u00a2 Docker container. This is a running Docker process on\nthe operating system. This is a running container that\nruns your application with all its dependencies.\n\n\u00ab Docker image. This is a prototype of a container or\nan image of it. Based on the Docker image, you can\nrun as many Docker containers as you like. Thanks to\nDocker image, it is guaranteed that each of the Docker\ncontainer instances will have the same version of the\ntarget application, as well as all dependencies.\n\n\u00a2 Dockerfile. This is a file describing how to create a\nDocker image. That is, this is a manifest thanks to\nwhich Docker understands what the future Docker\nimage consists of.\n\nAshort algorithm for working with Docker is as follows:\n\n1. You need to install the Docker engine. I use Docker\nDesktop on my work computer, which contains the\nDocker engine as one of the components.\n\n2. Create a Docker file describing how the target\napplication will be built as a Docker image.\n\n3. Using the docker build command, create a\nDocker image.\n\n4. Run the Docker container using the docker run\ncommand.\n\nIn this chapter we will go through all the steps except the first.\n\nBecause it is specific to each operating system and is well described in the\n\ndocumentation on the Docker website.\n\nLaunching the Application\n\nBefore starting a Docker container, you need to create an image of the\napplication. To do this, I created a Docker file in the project directory. This\nfile can be called anything, but it is usually called Dockerfile, with a capital\nletter and without specifying the file type. Listing 9-5 shows the contents of\nmy Docker file.\n\nTo create an image, you first need to do the following:\n\n1. Download all the project dependencies. Our project\nlinks to external libraries from NuGet packages. The\nDocker file runs the dotnet restore command.\nWhen this command is executed, .NET searches for\ndependencies and downloads them.\n\n2. Publish the application. To publish an application,\nuse the dotnet publish command. This compiles\nthe application and publishes the resulting files to\nthe specified directory.\n\n3. Give Docker a command to run the application.\n\nListing 9-5. Dockerfile\n\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS builder (1)\nWORKDIR /app (2)\nCOPY . ./ (3)\nRUN dotnet restore (4)\nRUN dotnet publish --no-restore -c Release -o out (5)\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 (6)\nWORKDIR /app (7)\nCOPY --from=builder /app/out . (8)\n\nENTRYPOINT [\"dotnet\", \"GatewaysApi.Binance.d11\"] (9)\n\nLet's figure out what happens on each line of this file.\n\n1. The FROM statement is executed. This specifies the\nimage with which the application\u2019s build commands\nwill be executed. For my application I am using\nimage dotnet/sdk version 8.0 located on the\nMicrosoft Artifact Registry server.\n\n2. In this step, I execute the WORKDIR instruction. This\nchanges the current directory in the container to the\none specified in the instructions.\n\n3. The COPY statement tells Docker to copy files\nand folders into the container. In our example,\nit instructs Docker to copy everything from the\ndirectory from which the build command is\nlaunched to the app directory of the container.\n\n4. Runthe dotnet restore command.\n\n5. Execute the dotnet publish command. The -o\noption instructs Docker to put the final compiled\nfiles in the out directory. It turns out that the\nresulting files will be stored at app/out in the\ncontainer. The --no-restore option indicates that\nthere is no need to check the dependency packages\nsince we ran the restore command first. -c\nspecifies the name of the build configuration; in our\ncase it is Release. After running this command, the\nassembly files (all kinds of .d11) will appear in the\napp/out folder.\n\n6. This is where the second stage of image assembly\nbegins. At this step, the FROM statement already\npoints to the base or parent image of the\n\napplication. I created an ASP.NET application\nso I am using the parent image dotnet/aspnet\nversion 8.0.\n\n7. Since a new build step has begun due to the FROM\nstatement, you must again specify the current\ncontainer directory using the WORKDIR statement.\n\n8. At this stage, all files from the /app/out directory\nfrom the previous build stage are copied to the\ncurrent directory. As a result, the resulting .d11 files\nwill be located in the current app directory.\n\n9. The ENTRYPOINT instruction tells Docker which\ncommand and with which arguments should be\ncalled during container execution. In our case, the\ndotnet GatewaysApi.Binance.d1l command will\nbe called.\n\nThe Docker file and applications are ready. Let's collect the image and\nlaunch the container. Before we begin, we need to make sure the Docker\nengine is working. To do this, you can run the docker -v command; this\nwill give you information about the current Docker version.\n\nAlso on the Docker hub registry, this is the place where people or\ncompanies publish Docker images. The image hello-world (https: //\nhub.docker.com/_/hello-world) contains a single static file. Thanks to\nthis image, you can check the performance of the Docker engine on your\ncomputer.\n\nIfyou run the docker run hello-world command, you will see\ninformation similar to Listing 9-6. In this fragment, Docker could not\nfind the image hello-world, so it downloaded this. After that, Docker\nlaunched the application, and we see the message \"Hello from Docker!\"\nThis means that Docker is working correctly.\n\nListing 9-6. docker run hello-world\n\n$ docker run hello-world\n\nUnable to find image 'hello-world:latest' locally\n\nlatest: Pulling from library/hello-world\n\nclec31eb5944: Pull complete\n\nDigest: sha256:d000bc569937abbe195e20322a0bde6b2922d805332fd6d\n8a68b19f524b7d21d\n\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working\ncorrectly.\n\nIf you now run the command to view the list of Docker images, you\nwill see an entry similar to Listing 9-7. You can see the image hello-world\nand the tag latest. Any tag for the image can be assigned, but usually the\nversion is used. This information also contains the image identifier, its\ncreation date, and its size.\n\nListing 9-7. Docker Images\n\n$ docker images\nREPOSITORY = TAG IMAGE ID CREATED SIZE\nhello-world latest d2c94e258dcb 10 months ago 13.3kB\n\nSince there is obviously no need for the hello-world container\nanymore, let\u2019s delete this image. If you run the docker rmi hello-world\ncommand, Docker will unsuccessfully try to remove the image he1lo-\nworld. Listing 9-8 demonstrates the error you will encounter.\n\nListing 9-8. docker rmi\n\n$ docker rmi hello-world\n\nError response from daemon: conflict: unable to remove\nrepository reference \"hello-world\" (must force) - container\n375244b990d2 is using its referenced image d2c94e258dcb\n\nThis happens because there is a running container that uses this\nimage. To remove image and dependent containers, you need to run the\nsame command but with the -force parameter. Then Docker will delete\nthe image and all dependent containers. Listing 9-9 shows the output of\nthe command. Nowif you run a Docker image, you will get an empty list.\n\nListing 9-9. docker rmi force\n\n$ docker rmi hello-world --force\n\nUntagged: hello-world: latest\n\nUntagged: hello-world@sha256 : d000bc569937abbe195e20322a0bde\n6b2922d805332fd6d8a68b19f524b7d21d\n\nDeleted: sha256:d2c94e258dcb3c5ac2798d32e1249e42ef01cba484\n1\u00a22234249495f87264ac5a\n\nAfter you are convinced that the Docker engine is working, let\u2019s create\nan image of our application using a ready-made Docker file. To do this,\nyou need to run the command docker build -t gateways-binance -f\nDockerfile . (note the dot at the end!). I call the docker build command\nwith the -t option, which points to the tag gateways-binance. The -f\nparameter specifies the name of the Docker file according to which the\nimage will be built. Listing 9-10 shows the result of the command.\n\nFirst of all, auxiliary images are loaded. After this, the commands\nspecified in the Docker file are executed.\n\nListing 9-10. Docker Build\n\n$ docker build -t gateways-binance -f Dockerfile .\n\n[+]\n\nBuilding 0.1s (14/14) FINISHED\n\ndocker:default => [internal] load .dockerignore\n\n=> transferring context: 2B\n\n[internal] load build definition from Dockerfile\n\n=> transferring dockerfile: 328B\n\n[internal] load metadata for mcr.microsoft.com/dotnet/\n\naspnet:8.0\n\n[internal] load metadata for mcr.microsoft.com/\n\ndotnet/sdk:8.0\n\n[builder 1/5] FROM mcr.microsoft.com/dotnet/sdk:8.0\n\n[stage-1 1/3] FROM mcr.microsoft.com/dotnet/aspnet:8.0\n\n[internal] load build context\n\n=> transferring context: 6.03kB\n\nCACHED [stage-1 2/3] WORKDIR /app\n\nCACHED [builder 2/5] WORKDIR /app\n\nCACHED [builder 3/5] COPY . ./\n\nCACHED [builder 4/5] RUN dotnet restore\n\nCACHED [builder 5/5] RUN dotnet publish --no-restore -c\n\nRelease -o out 0.0s\n\nCACHED [stage-1 3/3] COPY --from=builder /app/out .\n\nexporting to image\n\n=> exporting layers\n\n=> writing image sha256:d7b014f94643b51fc7465ea104a47075e\n330681922101d9a1ad7b3840883ed18\n\n=> naming to docker.io/library/gateways-binance\n\nAsa result, if yourun the docker images command, you will see the\n\nresult, as in Listing 9-11.\n\nListing 9-11. docker images\n\n$ docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\ngateways-binance latest d7b014f94643 15 minutes ago 293MB\n\nIt\u2019s time to launch the first container. To do this, you need to run the\ncommand docker run -d -p 1234:8080 gateways-binance. In this I\nam executing the docker run command. The -d (detach) parameter\nspecifies that the container should be launched in the background,\nand only the identifier of this container should be displayed on the\ncommand line.\n\nThe -p 1234:8080 option specifies port mapping. You will remember\nthat the application \u201cthinks\u201d it is running on a separate virtual machine,\nand in that \u201cvirtual machine\u201d it runs on port 8080, because ASP.NET\napplications run on port 8080 unless otherwise specified. If you want to\naccess your application, you will have to do it as if you were accessing\nanother computer. This is why it is necessary to determine port\ncompliance. In this I specify that when a request occurs on port 1234, the\nDocker engine forwards it to port 8080 in the container\u2019s \u201c\n\nIf you perform a GET request to http: //localhost:1234/status/\nliveness, you will see the line \u201cIt\u2019s alive!!!\u201d as shown in Listing 9-12.\n\n\u2018virtual machine.\u201d\n\nListing 9-12. get status\n\n$ curl http://localhost:1234/status/liveness\nIt's alive!!!\n\nUsing the command docker logs bbbe5ed2c573947bfa7b4c68d41d,\nyou can see the logs of your container. This should contain many\nmessages with logs of trading information received from Binance. To\nfind out the container ID, you can run the command docker ps -f\nancestor=gateways -binance. This outputs all containers formed from\nimage gateways-binance.\n\nLet's launch another instance of our application, but on port 1235.\n\nTo do this, just run the command docker run -d -p 1235:8080\ngateways-binance. Now if you run the command docker ps -f\nancestor=gateways-binance, you will see two containers and,\naccordingly, two instances of the application.\n\nHow easy is it to launch application instances using Docker? Now\nimagine that you can simply upload this application to the Docker hub and\nanyone running the Docker engine can run your application, completely\nunaware that it is written in .NET or that it has any dependencies. It is easy.\n\nKubernetes\n\nSo, we've launched two instances of the gateways-binance app, but what\nhappens when you decide to release a new version of it?\nYou will need to do the following:\n\n1. Release the image with a new version of your\napplication.\n\n2. Stop and remove all containers that were using the\nimage with the old version.\n\n3. Launch the required number of containers with the\nnew version of the image.\n\nThere is one big drawback to this procedure. Your application will\nnot work between steps 2 and 3. Steps 2 and 3 are done sequentially with\neach container and in reverse order. That is, they first launch the container\nwith the new version of the application and then stop the container with\nthe old version. Then the same actions are performed with the second\ncontainer, and so on until the target number of containers is reached. This\ndeployment strategy is called zero downtime deployment.\n\nOf course, all these steps can be done manually. But the trading system\nwill have not one, but at least 10, applications with different numbers of\ncontainers. Manually updating each application requires attention and is\nsubject to a high probability of error.\n\nIn addition to the complexity of updating, there is another disadvantage\nof an infrastructure built on pure Docker: the lack of control and monitoring.\nImagine if one of your containers stopped existing or the application in one\nof the containers stopped working? How can this be in this case? Manually\ncheck the number of containers and, in the case of problems, launch a new\ncontainer manually. Such a system can hardly be called efficient.\n\nTo automate the task of updating, scaling, and managing containers,\nspecial applications\u2014orchestrators\u2014were created. The most popular of\nthem is Kubernetes (https: //kubernetes.io/).\n\nIn this section, I will show how to deploy our application in\nKubernetes. As with Docker, I won't go into detail about installing this\napplication on your computer because it is unique to each operating\nsystem. I will only say that for personal needs it is very convenient to use\nDocker Desktop. This includes the ability to run Kubernetes.\n\nComponents\n\nThe core component of Kubernetes (k8s) is Cluster. A cluster consists of\nseveral servers called nodes. There are two types of nodes. The worker\nnode is the server on which the containers run, and the master node is\nthe server that manages the work of the worker nodes. When you run\ncommands on k8s, they are always sent to the master node.\n\nFor the normal functioning of a Kubernetes Cluster, one master node\nand one worker node are sufficient, but usually there are several worker\nnodes. By increasing the number of nodes in a cluster, your cluster can\nbe scaled horizontally. That is, if you have a large number of running\ncontainers, you can always add another worker node to the cluster. See\nFicure 9-2.\n\n.\n\u2018 Kubernetes Cluster\u2019,\n\nk8s Worker Node k8s Worker Node k&s Worker Node\n\nk8s Worker Node k8sWorkerNode k&sWorkerNode ,\n\nFigure 9-2. Kubernetes Cluster\n\nPods\n\nEach worker node can run several minimal k8s units called pods. A pod is\nthe smallest k8s object; it ensures the operation of containers. Let's create\npods with our application.\n\nFirst, you need to make sure Kubernetes is working. To do this, you can\nrun a simple command to get a list of nodes, as shown in Listing 9-13. As\nyou can see, I have one k8s node v1.27.2 running.\n\nListing 9-13. List of Nodes\n\n$ kubectl get nodes\nNAME STATUS ROLES AGE VERSION\ndocker-desktop Ready control-plane 215d vi1.27.2\n\nTo create a pod, simply run the kubect1 run command, as shown in\nListing 9-14. I pass the image from which the container inside the pod will\nbe launched and the name of the container as parameters.\n\nListing 9-14. kubectl run\n\n$ kubectl run gateways-binance-1\n--image=gateways-binance: latest\npod/gateways-binance created\n\nNow, if we run the command to get a list of pods, our pod will be\nreturned. See Listing 9-15.\n\nListing 9-15. List of Pods\n\n$ kubectl get pods\nNAME READY STATUS RESTARTS AGE\ngateways-binance-1 1/1 Running 0 2m31s\n\nTo view pod logs, you can use the kubect1 logs gateways-binance-1\ncommand.\n\nHow do you check the functionality of the application? I want to call\nthe GET method /status/liveness. To do this, I need to forward port pod\n8080 (this is the port on which ASP.NET runs the application by default) to\na port on my computer. To do this, just run the port-forward command, as\nshown in Listing 9-16.\n\nListing 9-16. kubectl port forward\n\n$ kubectl port-forward gateways-binance-1 1234:8080\nForwarding from 127.0.0.1:1234 -> 8080\nForwarding from [::1]:1234 -> 8080\n\nNow, if you call the GET method at http: //localhost :1234/status/\nliveness, you will see the response \u201cIt\u2019s alive!!!\u201d\n\nTo delete a pod, just run the kubect1 delete pods gateways-\nbinance-1 command.\n\nKnowing all these commands is great, but there is also an alternative\nway to manage Kubernetes: by using an IDE. For me, the most convenient\nare Kubernetes Dashboard (https: //github.com/kubernetes/dashboard)\nor Lens (https: //k8slens.dev/). I will continue to demonstrate working\nwith k8s through the command line, because these are the basics that I\nwould like you to know.\n\nDeployments\n\nSo, at this stage we have a pod called gateways -binance-1 with a\nrunning container built on the image of our application. But creating\nand deleting pods is essentially no different from running containers. To\nautomate the deployment and scaling of pods in Kubernetes, there is a\ndeployments entity.\n\nWe will create this not using the create command but using the so-\ncalled manifest file. Manifest files are required to save and control the\nconfiguration of Kubernetes settings. You can put these files in source\ncontrol and always see changes that are made to it.\n\nLet's create a manifest file for our deployment. Manifest files are of type\n-yaml. Create a deployment. yaml file in any directory on your computer.\nTypically, deployment-related files are stored in the .ops directory, which\nis located in the root directory of your application.\n\nBe especially careful when working with .yaml files. It is very important\nto indicate this correctly. Listing 9-17 provides a minimal manifest file for\ndeployment.\n\n\u2014 apiVersion: apps/v1 indicates the Kubernetes API\n\nversion.\n\n\u2014 kind: Deployment is a type of file manifest. For exam-\nple, if you specify kind: Pod, this will mean that this file\ndescribes the creation of a pod.\n\n\u2014 metadata: name is the name of the deployment.\n\n\u2014 metadata: labels is necessary for many things. They\ncan be used to manage Kubernetes objects. For exam-\nple, delete all objects that have a certain set of labels, or\nthey can be used to collect application logs to add\nadditional information to your logs.\n\n\u2014 spec: replicas is the target number of pods.\n\n\u2014 spec: selector: matchLabels indicates by which\nlabels the deployment and pods are matched.\n\n\u2014 The spec: template section contains a description of\nfuture pods.\n\n\u2014 template:metadata: labels specifies with which\nlabels future pods will be created.\n\n\u2014 template:metadata: containers: name is the prefix\nfor the names of future containers.\n\n\u2014 template:metadata: containers: image specifies\nwhich image will be used to launch the container on\neach pod.\n\nListing 9-17. deployment.yaml File\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: gateways-binance-deployment\nlabels:\napp: gateways-binance\nspec:\nreplicas: 2\nselector:\n\nmatchLabels:\napp: gateways-binance\ntemplate:\nmetadata:\nlabels:\napp: gateways-binance\nspec:\ncontainers:\n- name: gateways-binance-pod\nimage: gateways-binance\n\nTo use the manifest file, simply run the kubect1 apply -f\ndeployment. yaml command. That's all. If you look at the list of\ndeployments, you will see a message like Listing 9-18.\n\nListing 9-18. List of Deployments\n\n$ kubectl get deployments\nNAME READY UP-TO-DATE AVAILABLE AGE\ngateways-binance-deployment 2/2 2 2 12m\n\nIf we request a list of pods, then we will have two of them, because the\nmanifest file specifies spec: replicas = 2. See Listing 9-19.\n\nListing 9-19. List of Pods\n\n$ kubect1 get pods\n\nNAME READY STATUS RESTARTS AGE\ngateways-binance-deployment-656b7fd7d4-f76rh 1/1 Running 0 13m\ngateways-binance-deployment-656b7fd7d4-rpn95 1/1 Running 0 13m\n\nLet\u2019s check one of the Kubernetes functions for which we started using\nit: monitoring and controlling running pods. I suggest deleting one of the\npods and, immediately after doing so, running the command to get a list of\npods, as shown in Listing 9-20.\n\nListing 9-20. Deleting the Pod\n\n$ kubectl delete pod gateways-binance-deployment-656b7fd7d4-\n#76rh\npod \"gateways-binance-deployment-656b7fd7d4-f76rh\" deleted\n\nAs you can see on Listing 9-21, Kubernetes immediately launched a\nnew pod to replace the deleted one, because the actual number of running\npods was not equal to the target, that is, two.\n\nListing 9-21. Listing of Pods\n$ kubectl get pods\n\nNAME READY STATUS RESTARTS AGE\ngateways-binance-deployment-656b7fd7d4-rpn95 1/1 Running O 16m\ngateways-binance-deployment-656b7fd7d4-tnq5b 1/1 Running 0 3s\n\nIf you change the manifest file and set replicas = 3 and then call\nthe apply command again, you will see a message similar to Listing 9-22.\nKubernetes automatically added another pod to the two existing ones.\n\nListing 9-22. Scale\n\n$ kubectl apply -f deployment. yaml\ndeployment .apps/gateways-binance-deployment configured\n\n$ kubectl get pods\n\nNAME READY STATUS RESTARTS AGE\ngateways-binance-deployment-656b7fd7d4-c9jvq 1/1 Running O 3s\ngateways-binance-deployment-656b7fd7d4-rpn95 1/1 Running Oo 20m\n\ngateways-binance-deployment-656b7fd7d4-tngSb 1/1 Running 0 4m\n\nIn addition to the fact that the pod itself may cease to exist, there is\nalso the possibility that the application running inside the container will\nsuddenly cease to perform its functions. To check the functionality of the\napplication, k8s periodically makes requests (takes probes). The URL and\nthe frequency of this is set in the manifest file.\n\nThe readiness probe is necessary for k8s to understand\nwhether it is possible to switch traffic to this pod. If the\nreadiness probe is negative, then requests will not be\nsent to this port.\n\nThe liveness probe is taken at the moment that the pod\nis launched. From this, k8s understands that the appli-\ncation has been successfully launched and is\noperational.\n\nAnother important Kubernetes feature for us is\nHorizontalPodAutoscaler. Listing 9-23 shows the second part of the\ndeployment. yaml file. I have added a manifest to this with a description of\nthe HorizontalPodAutoscaler object.\n\nminReplicas specifies the minimum number of pods.\nmaxReplicas indicates the maximum number of pods.\nspec: scaleTargetRef points to our deployment.\n\nThe metrics section indicates the rules for regulating\nthe number of pods. My rule specifies that if the aver-\nage number of CPU utilization of all pods exceeds 50,\nthen another pod will be launched and so on until\nmaxReplicas is reached.\n\nIn metrics you can use not only system metrics but also your own\nmetrics. For example, for the real trading subsystem, the metric of the\nnumber of active strategies will be relevant.\n\nListing 9-23. HorizontalPodAutoscaler in deployment.yaml\n\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\nname: gateways-binance-hpa\nspec:\nscaleTargetRef:\napiVersion: apps/v1\nkind: Deployment\nname: gateways-binance-deployment\nminReplicas: 2\nmaxReplicas: 5\nmetrics:\n- type: Resource\nresource:\nname: cpu\ntarget:\ntype: Utilization\naverageUtilization: 50\n\nServices\n\nCurrently, to access our application, we have to run the port-forward\ncommand, which is not only inconvenient but also ineffective. I want to\naccess my service at a certain address and not think about which pods\nprovided the service to me. Moreover, it is necessary that the traffic is\ndistributed evenly between all my pods. To solve these problems, k8s has\na special component: service. It is thanks to this that k8s provides the\nfunctionality described.\n\nServices come in several types. In this chapter, I will show you how\nto work with a service of the NodePort type. The manifest file provided in\nListing 9-24 is the minimum required to create a service.\n\nAn important section is the spec: selector section. This defines a set\nof labels, which is used to search for pods to bind to the service. The spec:\nports section specifies the port of the service itself within the Kubernetes\ncluster, as well as the port through which the request to the pods occurs.\n\nListing 9-24. service.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\nname: gateways-binance-service\nspec:\nselector:\napp: gateways-binance\nports:\n- protocol: TCP\nport: 1234\ntargetPort: 8080\ntype: NodePort\n\nAfter creating the service. yaml file, you need to run the kubect1\napply -f service. yaml command to create a new service. Once the\nservice is created, you can see it in the list of services, as shown in\nListing 9-25.\n\nListing 9-25. List of Services\n\n$ kubectl get svc\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S)\ngateways-binance-service NodePort 10.106.71.65 <none> 1234:30550/TCP\n\nPay attention to the PORT (S) section; this indicates the port inside the\ncluster, which is 1234, as well as external port 30550, through which you can\naccess the service. Now if you make a request to http: //localhost :30550/\nstatus/liveness, you will see the message \u201cIt\u2019s alive!!!\u201d If you look at the\npod logs, you can see that the request went to one of them.\n\nWe have created several manifest files with which you can quickly launch our\napplication on the Kubernetes cluster. In the future, you will integrate not only\nwith Binance but also with other trading exchanges and brokers, which means\nyou will have many gateways -xxx applications. The main difference between\nthem will be only the name and set of environment variables. Of course,\n\nyou can store the manifest files along with the application source code, but\nwhat if you need to change something in them? For example, add one more\ncontainer to each pod that collects logs. It turns out that you will have to\nchange the manifest files in all repositories with a high probability of errors.\nAlso, as the infrastructure becomes more complex, the list of your manifest\nfiles may contain not two files as in my example, but a dozen files, and in each\nof them you must remember to write the label app: gateways -binance.\n\nTo solve these problems, a solution called helm was created. You can\nfind installation and configuration instructions on the official website at\nhttps: //helm.sh. The idea behind this is quite simple. The application\nmanifest files become templates, where individual values, for example\ngateways-binance, are replaced with variable names, and special files\n\nwith the values of these variables are added to this. Now manifest files can\nbe stored in one place, and files with individual variable values can be\nstored along with the source code. See Listing 9-26.\n\nListing 9-26. Helm Chart\n\n- HelmChart\n\n- templates\n- deployment. yaml\n- service.yaml\n\n- values. yaml\n\n- Chart.yaml\n\nThe new Chart. yaml file contains the technical information needed\nby helm to run your application. Listing 9-27 presents one version of\nsuch a file.\n\nListing 9-27. Chart.yaml\n\napiVersion: v2\nname: basechart\ntype: application\nversion: 0.1.0\n\nThe new values. yaml file contains the default variable values. I have\nidentified four variables. These are the number of replicas, images, ports,\nand targetPorts. In the end, my values. yaml file looks like the one shown\nin Listing 9-28.\n\nListing 9-28. values.yaml\n\nreplicaCount: 2\n\nimage: gateways-binance\nport: 1234\n\ntargetPort: 3000\n\nNow you need to register these variables in the manifest files.\nListing 9-29 shows the modified service. yam] file. As you can see, this\nmanifest file can be used for all gateways-xxx applications.\n\nHere I have used the technical variable . Release .Name. I will indicate\nthis when executing the helm install command.\n\nListing 9-29. service.yaml with helm Variables\n\napiVersion: v1\nkind: Service\nmetadata:\nname: {{ .Release.Name }}-service\nspec:\nselector:\napp: {{ .Release.Name }}\nports:\n- protocol: TCP\nport: {{ .Values.port }}\ntargetPort: {{ .Values.targetPort }}\ntype: NodePort\n\nTo run the application using helm, you need to run the helm install\ncommand, as shown in Listing 9-30. I specified gateways -binance in the\nRelease.Name parameter.\n\nListing 9-30. helm install Command\n\n$ helm install gateways-binance HelmChart/\nNAME: gateways-binance\n\nLAST DEPLOYED: Wed Mar 6 19:35:40 2024\nNAMESPACE: default\n\nSTATUS: deployed\n\nREVISION: 1\n\nTEST SUITE: None\n\nOnce the command has completed successfully, you can verify that all\nthe required components have been created by running the kubect1 get\npod command. To update helm-chart, you need to call the helm upgrade\ncommand.\n\nhHe1m is a powerful mechanism that allows you to easily install\ncomplex applications that consist of several components.\n\nFor example, to install Kafka, you can use helm-chart. Perhaps\nthe most popular set of charts at the moment is the set from Bitnami\n(https: //bitnami.com). This provides everything you need to deploy\nvarious applications on your Kubernetes cluster. With these kits, you can\nrun complex applications on your server using literally one command.\n\nSummary\n\nSo, we have finished our journey. You have come a long way and learned\nhow to build complex trading systems. I showed how to create the\narchitecture of such systems and approach the implementation of this.\n\nIn this chapter, I covered one of the main topics of building a trading\nsystem, namely, the topic of infrastructure. I showed how to create your\nown Docker image using the example of a small application for integration\nwith a cryptocurrency exchange. Together we launched a Docker\ncontainer.\n\nBut we didn\u2019t stop there. I also showed how to work with the most\npopular orchestration: Kubernetes. I talked about the main components of\nthis. I showed an example of creating pods, deployments, and services, as\nwell as how these manifest files can be packaged in helm-chart.\n\nAfter reading this chapter, you have enough knowledge to install all the\nnecessary infrastructure on your server or personal computer. Now you\nhave enough knowledge to create your own easily scalable trading system.\n\nI want to remind you that the system described in this book is not the\nfinal solution. There is endless room for improvement here. For example,\ninstead of using indicators in condition, you can start using entire\nformulas. Or you can create your own type of signal that does not use\nconditions but is built, for example, on the number of mentions of certain\nphrases in news reports.\n\nBuilding a trading system is an endless process in which there is always\nroom for improvement. And working on this is very pleasant, because you\nimmediately see and feel feedback from your work in monetary terms, and\nthis is one of the best motivators. I wish you success and big earnings.\n",
                        "extracted-code": ""
                    }
                ]
            }
        ]
    }
}
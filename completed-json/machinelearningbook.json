{
    "New item": {
        "chapters": [
            {
                "chapter_id": 1,
                "chapter_name": "CHAPTER 1",
                "chapter_path": "./screenshots-images-2/chapter_1",
                "sections": [
                    {
                        "section_id": 1.1,
                        "section_name": "The Machine Learning Landscape",
                        "section_path": "./screenshots-images-2/chapter_1/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_1/7b71b69d-64b0-4206-8ce0-54f868126db9.png",
                            "./screenshots-images-2/chapter_1/section_1/e36cb872-ba86-464b-b29e-aad9471f045d.png",
                            "./screenshots-images-2/chapter_1/section_1/0121e0ae-467a-42ef-b291-d3bce4cb7f7b.png",
                            "./screenshots-images-2/chapter_1/section_1/2d2d06b5-4581-4dc1-9f6d-7f6b3840d45d.png",
                            "./screenshots-images-2/chapter_1/section_1/a7dea87f-3f00-4ac2-9d8f-53742876b577.png",
                            "./screenshots-images-2/chapter_1/section_1/9039ec2b-cfba-4789-a43e-15bf21657062.png",
                            "./screenshots-images-2/chapter_1/section_1/ba19b210-662d-416f-8b2e-14fe7ca03391.png",
                            "./screenshots-images-2/chapter_1/section_1/b72c53f8-180f-45d9-abdf-a329fb98dc38.png",
                            "./screenshots-images-2/chapter_1/section_1/d17c86f4-c4f9-4c50-b64f-6c8a7367b1e8.png",
                            "./screenshots-images-2/chapter_1/section_1/12a3dcbc-7f91-4224-8de5-179884b32ffa.png",
                            "./screenshots-images-2/chapter_1/section_1/3963b81b-0621-4f9e-8728-e32a91c3a57f.png",
                            "./screenshots-images-2/chapter_1/section_1/44f1ab19-d1b7-4244-8a36-6efc3cd5c769.png",
                            "./screenshots-images-2/chapter_1/section_1/2a0377f0-1629-4bb9-970b-dc8fe16a1717.png",
                            "./screenshots-images-2/chapter_1/section_1/08386a53-b1ab-4fcd-8606-871c9c36564d.png",
                            "./screenshots-images-2/chapter_1/section_1/eff8059c-5827-4e77-844a-acbe825fa381.png",
                            "./screenshots-images-2/chapter_1/section_1/6bb4fb24-a1c1-40a1-9993-37be63416f50.png",
                            "./screenshots-images-2/chapter_1/section_1/c27e708a-a3cc-472e-9710-a1f3e32285a2.png",
                            "./screenshots-images-2/chapter_1/section_1/459c9d5d-8dff-4045-ac49-91c656b5bda4.png",
                            "./screenshots-images-2/chapter_1/section_1/47ddab51-60e1-410b-b293-818fa06a397a.png",
                            "./screenshots-images-2/chapter_1/section_1/24985a2f-9998-4624-99c8-d6aec0a24493.png",
                            "./screenshots-images-2/chapter_1/section_1/f26da41e-3cf2-41c3-83c9-2e3950f51a31.png",
                            "./screenshots-images-2/chapter_1/section_1/694caf71-095e-4f5d-86b4-36e67a84c42e.png",
                            "./screenshots-images-2/chapter_1/section_1/68aac27e-22a6-4329-b941-09b23a0b3779.png",
                            "./screenshots-images-2/chapter_1/section_1/6a649c03-877e-4069-b873-4c82f1fd9309.png",
                            "./screenshots-images-2/chapter_1/section_1/f41811bf-1fff-4b72-b8f3-2594d897e4f8.png",
                            "./screenshots-images-2/chapter_1/section_1/7d78ce2d-fb1b-497e-9258-fd24302c4fee.png",
                            "./screenshots-images-2/chapter_1/section_1/613c84a4-ab37-43ff-bd4c-f708d23c6b33.png",
                            "./screenshots-images-2/chapter_1/section_1/0227c281-9287-4217-bfc3-c26f855e8fc8.png",
                            "./screenshots-images-2/chapter_1/section_1/a7dc69bb-ecd3-4835-b8d1-d8cb4f1b5786.png",
                            "./screenshots-images-2/chapter_1/section_1/ffe101c9-381f-4bd1-a0e8-ce62ec54639c.png",
                            "./screenshots-images-2/chapter_1/section_1/19e4eee2-017c-4e71-80fa-bf4c556cd901.png",
                            "./screenshots-images-2/chapter_1/section_1/3c863eb1-5bf0-47ae-b03e-8732a3bc88d8.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "With Early Release ebooks, you get books in their earliest form\u2014\nthe author's raw and unedited content as he or she writes\u2014so you\ncan take advantage of these technologies long before the official\nrelease of these titles. The following will be Chapter 1 in the final\nrelease of the book.\n\nWhen most people hear \u201cMachine Learning,\u201d they picture a robot: a dependable but-\nler or a deadly Terminator depending on who you ask. But Machine Learning is not\njust a futuristic fantasy, it's already here. In fact, it has been around for decades in\nsome specialized applications, such as Optical Character Recognition (OCR). But the\nfirst ML application that really became mainstream, improving the lives of hundreds\nof millions of people, took over the world back in the 1990s: it was the spam filter.\nNot exactly a self-aware Skynet, but it does technically qualify as Machine Learning\n(it has actually learned so well that you seldom need to flag an email as spam any-\nmore). It was followed by hundreds of ML applications that now quietly power hun-\ndreds of products and features that you use regularly, from better recommendations\nto voice search.\n\nWhere does Machine Learning start and where does it end? What exactly does it\nmean for a machine to learn something? If I download a copy of Wikipedia, has my\ncomputer really \u201clearned\u201d something? Is it suddenly smarter? In this chapter we will\nstart by clarifying what Machine Learning is and why you may want to use it.\n\nThen, before we set out to explore the Machine Learning continent, we will take a\nlook at the map and learn about the main regions and the most notable landmarks:\nsupervised versus unsupervised learning, online versus batch learning, instance-\nbased versus model-based learning. Then we will look at the workflow of a typical ML\nproject, discuss the main challenges you may face, and cover how to evaluate and\nfine-tune a Machine Learning system.\n\nThis chapter introduces a lot of fundamental concepts (and jargon) that every data\nscientist should know by heart. It will be a high-level overview (the only chapter\nwithout much code), all rather simple, but you should make sure everything is\ncrystal-clear to you before continuing to the rest of the book. So grab a coffee and let's\nget started!\n\nIf you already know all the Machine Learning basics, you may want\nto skip directly to Chapter 2. If you are not sure, try to answer all\nthe questions listed at the end of the chapter before moving on.\n\nWhat Is Machine Learning?\n\nMachine Learning is the science (and art) of programming computers so they can\nlearn from data.\n\nHere is a slightly more general definition:\n\n[Machine Learning is the] field of study that gives computers the ability to learn\nwithout being explicitly programmed.\n\u2014Arthur Samuel, 1959\n\nAnd a more engineering-oriented one:\n\nA computer program is said to learn from experience E with respect to some task T\nand some performance measure P, if its performance on T, as measured by P, improves\nwith experience E.\n\n\u2014Tom Mitchell, 1997\n\nFor example, your spam filter is a Machine Learning program that can learn to flag\nspam given examples of spam emails (e.g., flagged by users) and examples of regular\n(nonspam, also called \u201cham\u201d) emails. The examples that the system uses to learn are\ncalled the training set. Each training example is called a training instance (or sample).\nIn this case, the task T is to flag spam for new emails, the experience E is the training\ndata, and the performance measure P needs to be defined; for example, you can use\nthe ratio of correctly classified emails. This particular performance measure is called\naccuracy and it is often used in classification tasks.\n\nIf you just download a copy of Wikipedia, your computer has a lot more data, but it is\nnot suddenly better at any task. Thus, it is not Machine Learning.\n\nWhy Use Machine Learning?\n\nConsider how you would write a spam filter using traditional programming techni-\nques (Figure 1-1):\n\n1. First you would look at what spam typically looks like. You might notice that\nsome words or phrases (such as \u201c4U,\u201d \u201ccredit card,\u201d \u201cfree,\u201d and \u201camazing\u201d) tend to\ncome up a lot in the subject. Perhaps you would also notice a few other patterns\nin the sender's name, the email\u2019s body, and so on.\n\n2. You would write a detection algorithm for each of the patterns that you noticed,\nand your program would flag emails as spam if a number of these patterns are\ndetected.\n\n3. You would test your program, and repeat steps 1 and 2 until it is good enough.\n\nFigure 1-1. The traditional approach\n\nSince the problem is not trivial, your program will likely become a long list of com-\nplex rules\u2014pretty hard to maintain.\n\nIn contrast, a spam filter based on Machine Learning techniques automatically learns\nwhich words and phrases are good predictors of spam by detecting unusually fre-\nquent patterns of words in the spam examples compared to the ham examples\n(Figure 1-2). The program is much shorter, easier to maintain, and most likely more\naccurate.\n\nFigure 1-2. Machine Learning approach\n\nMoreover, if spammers notice that all their emails containing \u201c4U\u201d are blocked, they\nmight start writing \u201cFor U\u201d instead. A spam filter using traditional programming\ntechniques would need to be updated to flag \u201cFor U\u201d emails. If spammers keep work-\ning around your spam filter, you will need to keep writing new rules forever.\n\nIn contrast, a spam filter based on Machine Learning techniques automatically noti-\nces that \u201cFor U\u201d has become unusually frequent in spam flagged by users, and it starts\nflagging them without your intervention (Figure 1-3).\n\nFigure 1-3. Automatically adapting to change\n\nAnother area where Machine Learning shines is for problems that either are too com-\nplex for traditional approaches or have no known algorithm. For example, consider\nspeech recognition: say you want to start simple and write a program capable of dis-\ntinguishing the words \u201cone\u201d and \u201ctwo.\u201d You might notice that the word \u201ctwo\u201d starts\nwith a high-pitch sound (\u201cI\u201d), so you could hardcode an algorithm that measures\nhigh-pitch sound intensity and use that to distinguish ones and twos. Obviously this\ntechnique will not scale to thousands of words spoken by millions of very different\n\npeople in noisy environments and in dozens of languages. The best solution (at least\ntoday) is to write an algorithm that learns by itself, given many example recordings\nfor each word.\n\nFinally, Machine Learning can help humans learn (Figure 1-4): ML algorithms can be\ninspected to see what they have learned (although for some algorithms this can be\ntricky). For instance, once the spam filter has been trained on enough spam, it can\neasily be inspected to reveal the list of words and combinations of words that it\nbelieves are the best predictors of spam. Sometimes this will reveal unsuspected cor-\nrelations or new trends, and thereby lead to a better understanding of the problem.\n\nApplying ML techniques to dig into large amounts of data can help discover patterns\nthat were not immediately apparent. This is called data mining.\n\nSolution\n\nlterate if needed }---\n\nUnderstand the\nproblem better\n\nFigure 1-4. Machine Learning can help humans learn\n\n\u2018To summarize, Machine Learning is great for:\n\n+ Problems for which existing solutions require a lot of hand-tuning or long lists of\nrules: one Machine Learning algorithm can often simplify code and perform bet-\nter.\n\n+ Complex problems for which there is no good solution at all using a traditional\napproach: the best Machine Learning techniques can find a solution.\n\n+ Fluctuating environments: a Machine Learning system can adapt to new data.\n\n+ Getting insights about complex problems and large amounts of data.\n\nTypes of Machine Learning Systems\n\nThere are so many different types of Machine Learning systems that it is useful to\nclassify them in broad categories based on:\n\n+ Whether or not they are trained with human supervision (supervised, unsuper-\nvised, semisupervised, and Reinforcement Learning)\n\n+ Whether or not they can learn incrementally on the fly (online versus batch\nlearning)\n\n\u00ab Whether they work by simply comparing new data points to known data points,\nor instead detect patterns in the training data and build a predictive model, much\nlike scientists do (instance-based versus model-based learning)\n\nThese criteria are not exclusive; you can combine them in any way you like. For\nexample, a state-of-the-art spam filter may learn on the fly using a deep neural net-\nwork model trained using examples of spam and ham; this makes it an online, model-\nbased, supervised learning system.\n\nLet\u2019s look at each of these criteria a bit more closely.\n\nSupervised/Unsupervised Learning\n\nMachine Learning systems can be classified according to the amount and type of\nsupervision they get during training. There are four major categories: supervised\nlearning, unsupervised learning, semisupervised learning, and Reinforcement Learn-\ning.\n\nSupervised learning\n\nIn supervised learning, the training data you feed to the algorithm includes the desired\nsolutions, called labels (Figure 1-5).\n\nTraining set\n\nOw New instance\n\nFigure 1-5. A labeled training set for supervised learning (e.g., spam classification)\n\n\nA typical supervised learning task is classification. The spam filter is a good example\nof this: it is trained with many example emails along with their class (spam or ham),\nand it must learn how to classify new emails.\n\nAnother typical task is to predict a target numeric value, such as the price of a car,\ngiven a set of features (mileage, age, brand, etc.) called predictors. This sort of task is\ncalled regression (Figure 1-6).' To train the system, you need to give it many examples\nof cars, including both their predictors and their labels (i.e., their prices).\n\nIn Machine Learning an attribute is a data type (e.g., \u201cMileage\u201d),\nwhile a feature has several meanings depending on the context, but\ngenerally means an attribute plus its value (e.g., \u201cMileage =\n15,000\u201d). Many people use the words attribute and feature inter-\nchangeably, though.\n\nValue\n\nfe)\noO 20%?\n\nO.0 OO eke)\noe) 2% 0\u00b0\nfe)\n\neke) %\n12) Value?\n\nFeature 1\n\nNew instance\n\nFigure 1-6. Regression\n\nNote that some regression algorithms can be used for classification as well, and vice\nversa. For example, Logistic Regression is commonly used for classification, as it can\noutput a value that corresponds to the probability of belonging to a given class (e.g.,\n20% chance of being spam).\n\n1 Fun fact: this odd-sounding name is a statistics term introduced by Francis Galton while he was studying the\nfact that the children of tall people tend to be shorter than their parents. Since children were shorter, he called\nthis regression to the mean. This name was then applied to the methods he used to analyze correlations\nbetween variables.\n\nHere are some of the most important supervised learning algorithms (covered in this\nbook):\n\n+ k-Nearest Neighbors\n\n\u00ab Linear Regression\n\n+ Logistic Regression\n\n+ Support Vector Machines (SVMs)\n\n+ Decision Trees and Random Forests\n\n+ Neural networks?\n\nUnsupervised learning\n\nIn unsupervised learning, as you might guess, the training data is unlabeled\n(Figure 1-7). The system tries to learn without a teacher.\n\nTraining set\n\nFigure 1-7. An unlabeled training set for unsupervised learning\n\nHere are some of the most important unsupervised learning algorithms (most of\nthese are covered in Chapter 8 and Chapter 9):\n+ Clustering\n\u2014 K-Means\n\u2014 DBSCAN\n\u2014 Hierarchical Cluster Analysis (HCA)\n+ Anomaly detection and novelty detection\n\u2014 One-class SVM\n\n\u2014 Isolation Forest\n\n2 Some neural network architectures can be unsupervised, such as autoencoders and restricted Boltzmann\nmachines. They can also be semisupervised, such as in deep belief networks and unsupervised pretraining.\n\n+ Visualization and dimensionality reduction\n\n\u2014 Principal Component Analysis (PCA)\n\n\u2014 Kernel PCA\n\n\u2014 Locally-Linear Embedding (LLE)\n\n\u2014 t-distributed Stochastic Neighbor Embedding (t-SNE)\n+ Association rule learning\n\n\u2014 Apriori\n\n\u2014 Eclat\n\nFor example, say you have a lot of data about your blog's visitors. You may want to\nrun a clustering algorithm to try to detect groups of similar visitors (Figure 1-8). At\nno point do you tell the algorithm which group a visitor belongs to: it finds those\nconnections without your help. For example, it might notice that 40% of your visitors\nare males who love comic books and generally read your blog in the evening, while\n20% are young sci-fi lovers who visit during the weekends, and so on. If you use a\nhierarchical clustering algorithm, it may also subdivide each group into smaller\ngroups. This may help you target your posts for each group.\n\nFigure 1-8. Clustering\n\nVisualization algorithms are also good examples of unsupervised learning algorithms:\nyou feed them a lot of complex and unlabeled data, and they output a 2D or 3D rep-\nresentation of your data that can easily be plotted (Figure 1-9). These algorithms try\nto preserve as much structure as they can (e.g., trying to keep separate clusters in the\ninput space from overlapping in the visualization), so you can understand how the\ndata is organized and perhaps identify unsuspected patterns.\n\nFigure 1-9. Example of a t-SNE visualization highlighting semantic clusters\u2019\n\nA related task is dimensionality reduction, in which the goal is to simplify the data\nwithout losing too much information. One way to do this is to merge several correla-\nted features into one. For example, a car\u2019s mileage may be very correlated with its age,\nso the dimensionality reduction algorithm will merge them into one feature that rep-\nresents the car\u2019s wear and tear. This is called feature extraction.\n\nIt is often a good idea to try to reduce the dimension of your train-\ning data using a dimensionality reduction algorithm before you\nfeed it to another Machine Learning algorithm (such as a super-\nvised learning algorithm). It will run much faster, the data will take\nup less disk and memory space, and in some cases it may also per-\nform better.\n\nYet another important unsupervised task is anomaly detection\u2014for example, detect-\ning unusual credit card transactions to prevent fraud, catching manufacturing defects,\nor automatically removing outliers from a dataset before feeding it to another learn-\ning algorithm. The system is shown mostly normal instances during training, so it\nlearns to recognize them and when it sees a new instance it can tell whether it looks\n\n3 Notice how animals are rather well separated from vehicles, how horses are close to deer but far from birds,\nand so on. Figure reproduced with permission from Socher, Ganjoo, Manning, and Ng (2013), \u201cT-SNE visual-\nization of the semantic word space\u201d\n\nlike a normal one or whether it is likely an anomaly (see Figure 1-10). A very similar\ntask is novelty detection: the difference is that novelty detection algorithms expect to\nsee only normal data during training, while anomaly detection algorithms are usually\nmore tolerant, they can often perform well even with a small percentage of outliers in\nthe training set.\n\nFeature 2\nNew instances\n\nAnomaly x :\ne\n\nFeature 1\n\nFigure 1-10. Anomaly detection\n\nFinally, another common unsupervised task is association rule learning, in which the\ngoal is to dig into large amounts of data and discover interesting relations between\nattributes. For example, suppose you own a supermarket. Running an association rule\non your sales logs may reveal that people who purchase barbecue sauce and potato\nchips also tend to buy steak. Thus, you may want to place these items close to each\nother.\n\nSemisupervised learning\n\nSome algorithms can deal with partially labeled training data, usually a lot of unla-\nbeled data and a little bit of labeled data. This is called semisupervised learning\n(Figure 1-11).\n\nSome photo-hosting services, such as Google Photos, are good examples of this. Once\nyou upload all your family photos to the service, it automatically recognizes that the\nsame person A shows up in photos 1, 5, and 11, while another person B shows up in\nphotos 2, 5, and 7. This is the unsupervised part of the algorithm (clustering). Now all\nthe system needs is for you to tell it who these people are. Just one label per person,*\nand it is able to name everyone in every photo, which is useful for searching photos.\n\n4 That's when the system works perfectly. In practice it often creates a few clusters per person, and sometimes\nmixes up two people who look alike, so you need to provide a few labels per person and manually clean up\nsome clusters.\n\nFigure 1-11. Semisupervised learning\n\nMost semisupervised learning algorithms are combinations of unsupervised and\nsupervised algorithms. For example, deep belief networks (DBNs) are based on unsu-\npervised components called restricted Boltzmann machines (RBMs) stacked on top of\none another. RBMs are trained sequentially in an unsupervised manner, and then the\nwhole system is fine-tuned using supervised learning techniques.\n\nReinforcement Learning\n\nReinforcement Learning is a very different beast. The learning system, called an agent\nin this context, can observe the environment, select and perform actions, and get\nrewards in return (or penalties in the form of negative rewards, as in Figure 1-12). It\nmust then learn by itself what is the best strategy, called a policy, to get the most\nreward over time. A policy defines what action the agent should choose when it is ina\ngiven situation.\n\ni >\nEnvironment 2 ? Agent \u00b0 Observe\n\nSelect action\nusing policy\n\n\u00a9 Action:\n\nGet reward\nor penalty\n\nUpdate policy\n(learning step)\nIterate until an\n\nfc] optimal policy is\nfound\n\nFigure 1-12. Reinforcement Learning\n\nFor example, many robots implement Reinforcement Learning algorithms to learn\nhow to walk. DeepMind\u2019s AlphaGo program is also a good example of Reinforcement\nLearning: it made the headlines in May 2017 when it beat the world champion Ke Jie\nat the game of Go. It learned its winning policy by analyzing millions of games, and\nthen playing many games against itself. Note that learning was turned off during the\ngames against the champion; AlphaGo was just applying the policy it had learned.\n\nBatch and Online Learning\n\nAnother criterion used to classify Machine Learning systems is whether or not the\nsystem can learn incrementally from a stream of incoming data.\n\nBatch learning\n\nIn batch learning, the system is incapable of learning incrementally: it must be trained\nusing all the available data. This will generally take a lot of time and computing\nresources, so it is typically done offline. First the system is trained, and then it is\nlaunched into production and runs without learning anymore; it just applies what it\nhas learned. This is called offline learning.\n\nIf you want a batch learning system to know about new data (such as a new type of\nspam), you need to train a new version of the system from scratch on the full dataset\n(not just the new data, but also the old data), then stop the old system and replace it\nwith the new one.\n\nFortunately, the whole process of training, evaluating, and launching a Machine\nLearning system can be automated fairly easily (as shown in Figure 1-3), so even a\n\nbatch learning system can adapt to change. Simply update the data and train a new\nversion of the system from scratch as often as needed.\n\nThis solution is simple and often works fine, but training using the full set of data can\ntake many hours, so you would typically train a new system only every 24 hours or\neven just weekly. If your system needs to adapt to rapidly changing data (e.g., to pre-\ndict stock prices), then you need a more reactive solution.\n\nAlso, training on the full set of data requires a lot of computing resources (CPU,\nmemory space, disk space, disk I/O, network I/O, etc.). If you have a lot of data and\nyou automate your system to train from scratch every day, it will end up costing you a\nlot of money. If the amount of data is huge, it may even be impossible to use a batch\nlearning algorithm.\n\nFinally, if your system needs to be able to learn autonomously and it has limited\nresources (e.g., a smartphone application or a rover on Mars), then carrying around\nlarge amounts of training data and taking up a lot of resources to train for hours\nevery day is a showstopper.\n\nFortunately, a better option in all these cases is to use algorithms that are capable of\nlearning incrementally.\n\nOnline learning\n\nIn online learning, you train the system incrementally by feeding it data instances\nsequentially, either individually or by small groups called mini-batches. Each learning\nstep is fast and cheap, so the system can learn about new data on the fly, as it arrives\n(see Figure 1-13).\n\nFigure 1-13. Online learning\n\nOnline learning is great for systems that receive data as a continuous flow (e.g., stock\nprices) and need to adapt to change rapidly or autonomously. It is also a good option\n\nif you have limited computing resources: once an online learning system has learned\nabout new data instances, it does not need them anymore, so you can discard them\n(unless you want to be able to roll back to a previous state and \u201creplay\u201d the data). This\ncan save a huge amount of space.\n\nOnline learning algorithms can also be used to train systems on huge datasets that\ncannot fit in one machine's main memory (this is called out-of-core learning). The\nalgorithm loads part of the data, runs a training step on that data, and repeats the\nprocess until it has run on all of the data (see Figure 1-14).\n\nOut-of-core learning is usually done offline (ie., not on the live\nsystem), so online learning can be a confusing name. Think of it as\nincremental learning.\n\na7, ge\n\n\u201cLots* of data\n\nStudy the\nproblem\n\nFigure 1-14. Using online learning to handle huge datasets\n\nOne important parameter of online learning systems is how fast they should adapt to\nchanging data: this is called the learning rate. If you set a high learning rate, then your\nsystem will rapidly adapt to new data, but it will also tend to quickly forget the old\ndata (you don't want a spam filter to flag only the latest kinds of spam it was shown).\nConversely, if you set a low learning rate, the system will have more inertia; that is, it\nwill learn more slowly, but it will also be less sensitive to noise in the new data or to\nsequences of nonrepresentative data points (outliers).\n\nA big challenge with online learning is that if bad data is fed to the system, the sys-\ntem\u2019s performance will gradually decline. If we are talking about a live system, your\nclients will notice. For example, bad data could come from a malfunctioning sensor\non a robot, or from someone spamming a search engine to try to rank high in search\n\nresults. To reduce this risk, you need to monitor your system closely and promptly\nswitch learning off (and possibly revert to a previously working state) if you detect a\ndrop in performance. You may also want to monitor the input data and react to\nabnormal data (e.g., using an anomaly detection algorithm).\n\nInstance-Based Versus Model-Based Learning\n\nOne more way to categorize Machine Learning systems is by how they generalize.\nMost Machine Learning tasks are about making predictions. This means that given a\nnumber of training examples, the system needs to be able to generalize to examples it\nhas never seen before. Having a good performance measure on the training data is\ngood, but insufficient; the true goal is to perform well on new instances.\n\nThere are two main approaches to generalization: instance-based learning and\nmodel-based learning.\n\nInstance-based learning\n\nPossibly the most trivial form of learning is simply to learn by heart. If you were to\ncreate a spam filter this way, it would just flag all emails that are identical to emails\nthat have already been flagged by users\u2014not the worst solution, but certainly not the\nbest.\n\nInstead of just flagging emails that are identical to known spam emails, your spam\nfilter could be programmed to also flag emails that are very similar to known spam\nemails. This requires a measure of similarity between two emails. A (very basic) simi-\nlarity measure between two emails could be to count the number of words they have\nin common. The system would flag an email as spam if it has many words in com-\nmon with a known spam email.\n\nThis is called instance-based learning: the system learns the examples by heart, then\ngeneralizes to new cases by comparing them to the learned examples (or a subset of\nthem), using a similarity measure. For example, in Figure 1-15 the new instance\nwould be classified as a triangle because the majority of the most similar instances\nbelong to that class.\n\nFeature 2\n\nFeature 1\nFigure 1-15. Instance-based learning\nModel-based learning\n\nAnother way to generalize from a set of examples is to build a model of these exam-\n\nples, then use that model to make predictions. This is called model-based learning\n(Figure 1-16).\n\nFeature 2 Model \\\nA A \u2018. Oo\nA A oO\nA WN\nA A a0\nA\n\nWN instance\n\nFeature 1\n\nFigure 1-16. Model-based learning\n\nFor example, suppose you want to know if money makes people happy, so you down-\nload the Better Life Index data from the OECD's website as well as stats about GDP\nper capita from the IMF's website. Then you join the tables and sort by GDP per cap-\nita. Table 1-1 shows an excerpt of what you get.\n\n\nTable 1-1. Does money make people happier?\nCountry GDP per capita (USD) Life satisfaction\n\nHungary 12,240 49\nKorea 27,195 58\nFrance 37,675 65\nAustralia 50,962 73\nUnited States 55,805 72\n\nLet\u2019s plot the data for a few random countries (Figure 1-17).\n\n10\nc\n6 8\nEs} . i \u201c3\n& 6 te % 2 of\n2 ee\nOo 4 US.\nBH Australia\n2 France\n5 Korea\n\nHungary\n\n0 + + Y + r\n0 10000 20000 30000 40000 50000 60000\nGDP per capita\n\nFigure 1-17. Do you see a trend here?\n\nThere does seem to be a trend here! Although the data is noisy (i.e., partly random), it\nlooks like life satisfaction goes up more or less linearly as the country\u2019s GDP per cap-\nita increases. So you decide to model life satisfaction as a linear function of GDP per\ncapita. This step is called model selection: you selected a linear model of life satisfac-\ntion with just one attribute, GDP per capita (Equation 1-1).\n\nEquation 1-1. A simple linear model\nlife_satisfaction = 4 + 4, x GDP_per_capita\n\nThis model has two model parameters, 0, and @,.\u00b0 By tweaking these parameters, you\ncan make your model represent any linear function, as shown in Figure 1-18.\n\nLife satisfaction\n\n0 + 1 + ,\n\u00a9 10000 20000 30000 40000 50000 60000\nGDP per capita\n\nFigure 1-18. A few possible linear models\n\nBefore you can use your model, you need to define the parameter values @, and @,.\nHow can you know which values will make your model perform best? To answer this\nquestion, you need to specify a performance measure. You can either define a utility\nfunction (or fitness function) that measures how good your model is, or you can define\na cost function that measures how bad it is. For linear regression problems, people\ntypically use a cost function that measures the distance between the linear model's\npredictions and the training examples; the objective is to minimize this distance.\n\nThis is where the Linear Regression algorithm comes in: you feed it your training\nexamples and it finds the parameters that make the linear model fit best to your data.\n\nThis is called training the model. In our case the algorithm finds that the optimal\nparameter values are @, = 4.85 and 6, = 4.91 x 10\u00b0.\n\nNow the model fits the training data as closely as possible (for a linear model), as you\ncan see in Figure 1-19.\n\nLife satisfaction\n\n0 . . . .\n0 10000 20000 30000 40000 50000 60000\nGDP per capita\n\nFigure 1-19. The linear model that fits the training data best\n\nYou are finally ready to run the model to make predictions. For example, say you\nwant to know how happy Cypriots are, and the OECD data does not have the answer.\nFortunately, you can use your model to make a good prediction: you look up Cyprus\u2019s\nGDP per capita, find $22,587, and then apply your model and find that life satisfac-\ntion is likely to be somewhere around 4.85 + 22,587 x 4.91 x 10\u00b0 = 5.96.\n\nTo whet your appetite, Example 1-1 shows the Python code that loads the data, pre-\npares it, creates a scatterplot for visualization, and then trains a linear model and\nmakes a prediction.\u201d\n\nExample 1-1. Training and running a linear model using Scikit-Learn\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport pandas as pd\n\nimport sklearn.linear_model\n\n# Load the data\n\noecd_bli = pd.read_csv(\"oecd_bli_2015.csv\", thousands=',')\n\ngdp_per_capita = pd.read_csv(\"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\nencoding='latini', na_values=\"n/a\")\n\n# Prepare the data\n\ncountry_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\nX = np.c_[country_stats[\"GDP per capita\"]]\n\ny = np.c_[country_stats[\"Life satisfaction\"]]\n\n# Visualize the data\ncountry_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\nplt.show()\n\n# Select a linear model\nmodel = sklearn.linear_model.LinearRegression()\n\n# Train the model\nmodel.fit(X, y)\n\n# Make a prediction for Cyprus\nX_new = [[22587]]  # Cyprus\u2018 GDP per capita\nprint(model.predict(X_new)) # outputs [[ 5.96242338]]\n\n6 The prepare_country_stats() function's definition is not shown here (see this chapter's Jupyter notebook if\nyou want all the gory details). It's just boring Pandas code that joins the life satisfaction data from the OBCD\nwith the GDP per capita data from the IMF.\n\n\nIf all went well, your model will make good predictions. If not, you may need to use\nmore attributes (employment rate, health, air pollution, etc.), get more or better qual-\nity training data, or perhaps select a more powerful model (e.g., a Polynomial Regres-\nsion model).\n\nIn summary:\n\nThis is what a typical Machine Learning project looks like. In Chapter 2 you will\n\nIf you had used an instance-based learning algorithm instead, you\nwould have found that Slovenia has the closest GDP per capita to\nthat of Cyprus ($20,732), and since the OECD data tells us that\nSlovenians\u2019 life satisfaction is 5.7, you would have predicted a life\nsatisfaction of 5.7 for Cyprus. If you zoom out a bit and look at the\ntwo next closest countries, you will find Portugal and Spain with\nlife satisfactions of 5.1 and 6.5, respectively. Averaging these three\nvalues, you get 5.77, which is pretty close to your model-based pre-\ndiction. This simple algorithm is called k-Nearest Neighbors regres-\nsion (in this example, k = 3).\n\nReplacing the Linear Regression model with k-Nearest Neighbors\n\nregression in the previous code is as simple as replacing these two\nlines:\n\nimport sklearn.linear_model\n\nmodel = sklearn.linear_model.LinearRegression()\nwith these two:\n\nimport sklearn.neighbors\nmodel = sklearn.neighbors.KkNeighborsRegressor (n_neighbors=3)\n\nYou studied the data.\nYou selected a model.\n\nYou trained it on the training data (ie., the learning algorithm searched for the\nmodel parameter values that minimize a cost function).\n\nFinally, you applied the model to make predictions on new cases (this is called\ninference), hoping that this model will generalize well.\n\nexperience this first-hand by going through an end-to-end project.\n\nWe have covered a lot of ground so far: you now know what Machine Learning is\nreally about, why it is useful, what some of the most common categories of ML sys-\ntems are, and what a typical project workflow looks like. Now let's look at what can go\n\nwrong in learning and prevent you from making accurate predictions.\n\nMain Challenges of Machine Learning\n\nIn short, since your main task is to select a learning algorithm and train it on some\ndata, the two things that can go wrong are \u201cbad algorithm\u201d and \u201cbad data\u201d Let's start\nwith examples of bad data.\n\nInsufficient Quantity of Training Data\n\nFor a toddler to learn what an apple is, all it takes is for you to point to an apple and\nsay \u201capple\u201d (possibly repeating this procedure a few times). Now the child is able to\nrecognize apples in all sorts of colors and shapes. Genius.\n\nMachine Learning is not quite there yet; it takes a lot of data for most Machine Learn-\ning algorithms to work properly. Even for very simple problems you typically need\nthousands of examples, and for complex problems such as image or speech recogni-\ntion you may need millions of examples (unless you can reuse parts of an existing\nmodel).\n\nThe Unreasonable Effectiveness of Data\n\nIn a famous paper published in 2001, Microsoft researchers Michele Banko and Eric\nBrill showed that very different Machine Learning algorithms, including fairly simple\nones, performed almost identically well on a complex problem of natural language\ndisambiguation\u2018 once they were given enough data (as you can see in Figure 1-20).\n\n1.00\n\nMillions of Words\n\nFigure 1-20. The importance of data versus algorithms\u00ae\n\nAs the authors put it: \u201cthese results suggest that we may want to reconsider the trade-\noff between spending time and money on algorithm development versus spending it\non corpus development.\u201d\n\nThe idea that data matters more than algorithms for complex problems was further\npopularized by Peter Norvig et al. in a paper titled \u201cThe Unreasonable Effectiveness\nof Data\u201d published in 2009.\"\u00b0 It should be noted, however, that small- and medium-\nsized datasets are still very common, and it is not always easy or cheap to get extra\ntraining data, so don't abandon algorithms just yet.\n\n\nNonrepresentative Training Data\n\nIn order to generalize well, it is crucial that your training data be representative of the\nnew cases you want to generalize to. This is true whether you use instance-based\nlearning or model-based learning.\n\nFor example, the set of countries we used earlier for training the linear model was not\nperfectly representative; a few countries were missing. Figure 1-21 shows what the\ndata looks like when you add the missing countries.\n\n10\n\nBrazil = Mexico Chile Czech Republic\n\nc\no . - .\n\u00a9 6 were \\\nDd eee . -\n2\no 4\nbe Norway Switzerland Luxembourg\n2\n5 2\n0 + r + -\n0 20000 40000 60000 80000 100000\n\nGDP per capita\n\nFigure 1-21. A more representative training sample\n\nIf you train a linear model on this data, you get the solid line, while the old model is\nrepresented by the dotted line. As you can see, not only does adding a few missing\ncountries significantly alter the model, but it makes it clear that such a simple linear\nmodel is probably never going to work well. It seems that very rich countries are not\nhappier than moderately rich countries (in fact they seem unhappier), and conversely\nsome poor countries seem happier than many rich countries.\n\nBy using a nonrepresentative training set, we trained a model that is unlikely to make\naccurate predictions, especially for very poor and very rich countries.\n\nIt is crucial to use a training set that is representative of the cases you want to general-\nize to. This is often harder than it sounds: if the sample is too small, you will have\nsampling noise (i.e., nonrepresentative data as a result of chance), but even very large\nsamples can be nonrepresentative if the sampling method is flawed. This is called\nsampling bias.\n\nInstead, Roosevelt won with 62% of the votes. The flaw was in the Literary Digest\u2019s\nsampling method:\n\n+ First, to obtain the addresses to send the polls to, the Literary Digest used tele-\nphone directories, lists of magazine subscribers, club membership lists, and the\nlike. All of these lists tend to favor wealthier people, who are more likely to vote\nRepublican (hence Landon).\n\n+ Second, less than 25% of the people who received the poll answered. Again, this\nintroduces a sampling bias, by ruling out people who don't care much about poli-\ntics, people who don't like the Literary Digest, and other key groups. This is a spe-\ncial type of sampling bias called nonresponse bias.\n\nHere is another example: say you want to build a system to recognize funk music vid-\neos. One way to build your training set is to search \u201cfunk music\u201d on YouTube and use\nthe resulting videos. But this assumes that YouTube's search engine returns a set of\nvideos that are representative of all the funk music videos on YouTube. In reality, the\nsearch results are likely to be biased toward popular artists (and if you live in Brazil\nyou will get a lot of \u201cfunk carioca\u201d videos, which sound nothing like James Brown).\nOn the other hand, how else can you get a large training set?\n\nPoor-Quality Data\n\nObviously, if your training data is full of errors, outliers, and noise (e.g., due to poor-\nquality measurements), it will make it harder for the system to detect the underlying\npatterns, so your system is less likely to perform well. It is often well worth the effort\nto spend time cleaning up your training data. The truth is, most data scientists spend\na significant part of their time doing just that. For example:\n\n+ Ifsome instances are clearly outliers, it may help to simply discard them or try to\nfix the errors manually.\n\n+ If some instances are missing a few features (e.g., 5% of your customers did not\nspecify their age), you must decide whether you want to ignore this attribute alto-\ngether, ignore these instances, fill in the missing values (e.g., with the median\nage), or train one model with the feature and one model without it, and so on.\n\nIrrelevant Features\n\nAs the saying goes: garbage in, garbage out. Your system will only be capable of learn-\ning if the training data contains enough relevant features and not too many irrelevant\nones. A critical part of the success of a Machine Learning project is coming up with a\ngood set of features to train on. This process, called feature engineering, involves:\n\n+ Feature selection: selecting the most useful features to train on among existing\nfeatures.\n\n+ Feature extraction: combining existing features to produce a more useful one (as\nwe saw earlier, dimensionality reduction algorithms can help).\n\n+ Creating new features by gathering new data.\n\nNow that we have looked at many examples of bad data, let\u2019s look at a couple of exam-\nples of bad algorithms.\n\nOverfitting the Training Data\n\nSay you are visiting a foreign country and the taxi driver rips you off. You might be\ntempted to say that all taxi drivers in that country are thieves. Overgeneralizing is\nsomething that we humans do all too often, and unfortunately machines can fall into\nthe same trap if we are not careful. In Machine Learning this is called overfitting: it\nmeans that the model performs well on the training data, but it does not generalize\nwell.\n\nFigure 1-22 shows an example of a high-degree polynomial life satisfaction model\nthat strongly overfits the training data. Even though it performs much better on the\ntraining data than the simple linear model, would you really trust its predictions?\n\n10\n\nLife satisfaction\n\n0 20000 40000 60000 80000 100000\nGDP per capita\n\nFigure 1-22. Overfitting the training data\n\nComplex models such as deep neural networks can detect subtle patterns in the data,\nbut if the training set is noisy, or if it is too small (which introduces sampling noise),\nthen the model is likely to detect patterns in the noise itself. Obviously these patterns\nwill not generalize to new instances. For example, say you feed your life satisfaction\nmodel many more attributes, including uninformative ones such as the country\u2019s\nname. In that case, a complex model may detect patterns like the fact that all coun-\ntries in the training data with a w in their name have a life satisfaction greater than 7:\nNew Zealand (7.3), Norway (7.4), Sweden (7.2), and Switzerland (7.5). How confident\n\nare you that the W-satisfaction rule generalizes to Rwanda or Zimbabwe? Obviously\nthis pattern occurred in the training data by pure chance, but the model has no way\nto tell whether a pattern is real or simply the result of noise in the data.\n\nOverfitting happens when the model is too complex relative to the\namount and noisiness of the training data. The possible solutions\nare:\n\n+ To simplify the model by selecting one with fewer parameters\n(e.g., a linear model rather than a high-degree polynomial\nmodel), by reducing the number of attributes in the training\ndata or by constraining the model\n\n+ To gather more training data\n\n+ To reduce the noise in the training data (e.g., fix data errors\nand remove outliers)\n\nConstraining a model to make it simpler and reduce the risk of overfitting is called\nregularization. For example, the linear model we defined earlier has two parameters,\n9, and 6,. This gives the learning algorithm two degrees of freedom to adapt the model\nto the training data: it can tweak both the height (@,) and the slope (6,) of the line. If\nwe forced 6, = 0, the algorithm would have only one degree of freedom and would\nhave a much harder time fitting the data properly: all it could do is move the line up\nor down to get as close as possible to the training instances, so it would end up\naround the mean. A very simple model indeed! If we allow the algorithm to modify 0,\nbut we force it to keep it small, then the learning algorithm will effectively have some-\nwhere in between one and two degrees of freedom. It will produce a simpler model\nthan with two degrees of freedom, but more complex than with just one. You want to\nfind the right balance between fitting the training data perfectly and keeping the\nmodel simple enough to ensure that it will generalize well.\n\nFigure 1-23 shows three models: the dotted line represents the original model that\nwas trained with a few countries missing, the dashed line is our second model trained\nwith all countries, and the solid line is a linear model trained with the same data as\nthe first model but with a regularization constraint. You can see that regularization\nforced the model to have a smaller slope, which fits a bit less the training data that the\nmodel was trained on, but actually allows it to generalize better to new examples.\n\n~-- Linear model on all data\nPS Od Linear model on partial data\n\u2014 Regularized linear model on partial data\n\nLife satisfaction\n\n0 20000 40000 60000 80000 100000\nGDP per capita\n\nFigure 1-23. Regularization reduces the risk of overfitting\n\nThe amount of regularization to apply during learning can be controlled by a hyper-\nparameter. A hyperparameter is a parameter of a learning algorithm (not of the\nmodel). As such, it is not affected by the learning algorithm itself; it must be set prior\nto training and remains constant during training. If you set the regularization hyper-\nparameter to a very large value, you will get an almost flat model (a slope close to\nzero); the learning algorithm will almost certainly not overfit the training data, but it\nwill be less likely to find a good solution. Tuning hyperparameters is an important\npart of building a Machine Learning system (you will see a detailed example in the\nnext chapter).\n\nUnderfitting the Training Data\n\nAs you might guess, underfitting is the opposite of overfitting: it occurs when your\nmodel is too simple to learn the underlying structure of the data. For example, a lin-\near model of life satisfaction is prone to underfit; reality is just more complex than\nthe model, so its predictions are bound to be inaccurate, even on the training exam-\nples.\n\nThe main options to fix this problem are:\n\n+ Selecting a more powerful model, with more parameters\n+ Feeding better features to the learning algorithm (feature engineering)\n\n+ Reducing the constraints on the model (e.g., reducing the regularization hyper-\nparameter)\n\nStepping Back\n\nBy now you already know a lot about Machine Learning. However, we went through\nso many concepts that you may be feeling a little lost, so let\u2019s step back and look at the\nbig picture:\n\n\u00ab Machine Learning is about making machines get better at some task by learning\nfrom data, instead of having to explicitly code rules.\n\n+ There are many different types of ML systems: supervised or not, batch or online,\ninstance-based or model-based, and so on.\n\n+ Ina ML project you gather data in a training set, and you feed the training set to\na learning algorithm. If the algorithm is model-based it tunes some parameters to\nfit the model to the training set (i.e., to make good predictions on the training set\nitself), and then hopefully it will be able to make good predictions on new cases\nas well. If the algorithm is instance-based, it just learns the examples by heart and\ngeneralizes to new instances by comparing them to the learned instances using a\nsimilarity measure.\n\n+ The system will not perform well if your training set is too small, or if the data is\nnot representative, noisy, or polluted with irrelevant features (garbage in, garbage\nout). Lastly, your model needs to be neither too simple (in which case it will\nunderfit) nor too complex (in which case it will overfit).\n\nThere's just one last important topic to cover: once you have trained a model, you\ndon't want to just \u201chope\u201d it generalizes to new cases. You want to evaluate it, and fine-\ntune it if necessary. Let's see how.\n\nTesting and Validating\n\nThe only way to know how well a model will generalize to new cases is to actually try\nit out on new cases. One way to do that is to put your model in production and moni-\ntor how well it performs. This works well, but if your model is horribly bad, your\nusers will complain\u2014not the best idea.\n\nA better option is to split your data into two sets: the training set and the test set. As\nthese names imply, you train your model using the training set, and you test it using\nthe test set. The error rate on new cases is called the generalization error (or out-of-\nsample error), and by evaluating your model on the test set, you get an estimate of this\nerror. This value tells you how well your model will perform on instances it has never\nseen before.\n\nIf the training error is low (i.e., your model makes few mistakes on the training set)\nbut the generalization error is high, it means that your model is overfitting the train-\ning data.\n\nIt is common to use 80% of the data for training and hold out 20%\nfor testing. However, this depends on the size of the dataset: if it\ncontains 10 million instances, then holding out 1% means your test\nset will contain 100,000 instances: that\u2019s probably more than\nenough to get a good estimate of the generalization error.\n\nHyperparameter Tuning and Model Selection\n\nSo evaluating a model is simple enough: just use a test set. Now suppose you are hesi-\ntating between two models (say a linear model and a polynomial model): how can\nyou decide? One option is to train both and compare how well they generalize using\nthe test set.\n\nNow suppose that the linear model generalizes better, but you want to apply some\n\nregularization to avoid overfitting. The question is: how do you choose the value of\nthe regularization hyperparameter? One option is to train 100 different models using\n100 different values for this hyperparameter. Suppose you find the best hyperparame-\nter value that produces a model with the lowest generalization error, say just 5% error.\n\nSo you launch this model into production, but unfortunately it does not perform as\nwell as expected and produces 15% errors. What just happened?\n\nThe problem is that you measured the generalization error multiple times on the test\nset, and you adapted the model and hyperparameters to produce the best model for\nthat particular set. This means that the model is unlikely to perform as well on new\ndata.\n\nA common solution to this problem is called holdout validation: you simply hold out\npart of the training set to evaluate several candidate models and select the best one.\nThe new heldout set is called the validation set (or sometimes the development set, or\ndev set). More specifically, you train multiple models with various hyperparameters\non the reduced training set (i.e., the full training set minus the validation set), and\nyou select the model that performs best on the validation set. After this holdout vali-\ndation process, you train the best model on the full training set (including the valida-\ntion set), and this gives you the final model. Lastly, you evaluate this final model on\nthe test set to get an estimate of the generalization error.\n\nThis solution usually works quite well. However, if the validation set is too small, then\nmodel evaluations will be imprecise: you may end up selecting a suboptimal model by\nmistake. Conversely, if the validation set is too large, then the remaining training set\nwill be much smaller than the full training set. Why is this bad? Well, since the final\nmodel will be trained on the full training set, it is not ideal to compare candidate\nmodels trained on a much smaller training set. It would be like selecting the fastest\nsprinter to participate in a marathon. One way to solve this problem is to perform\nrepeated cross-validation, using many small validation sets. Each model is evaluated\nonce per validation set, after it is trained on the rest of the data. By averaging out all\nthe evaluations of a model, we get a much more accurate measure of its performance.\nHowever, there is a drawback: the training time is multiplied by the number of valida-\ntion sets.\n\nData Mismatch\n\nIn some cases, it is easy to get a large amount of data for training, but it is not per-\nfectly representative of the data that will be used in production. For example, suppose\nyou want to create a mobile app to take pictures of flowers and automatically deter-\nmine their species. You can easily download millions of pictures of flowers on the\nweb, but they won't be perfectly representative of the pictures that will actually be\ntaken using the app on a mobile device. Perhaps you only have 10,000 representative\npictures (i.e., actually taken with the app). In this case, the most important rule to\nremember is that the validation set and the test must be as representative as possible\nof the data you expect to use in production, so they should be composed exclusively\nof representative pictures: you can shuffle them and put half in the validation set, and\nhalf in the test set (making sure that no duplicates or near-duplicates end up in both\nsets). After training your model on the web pictures, if you observe that the perfor-\nmance of your model on the validation set is disappointing, you will not know\nwhether this is because your model has overfit the training set, or whether this is just\ndue to the mismatch between the web pictures and the mobile app pictures. One sol-\nution is to hold out part of the training pictures (from the web) in yet another set that\nAndrew Ng calls the train-dev set. After the model is trained (on the training set, not\non the train-dev set), you can evaluate it on the train-dev set: if it performs well, then\nthe model is not overfitting the training set, so if performs poorly on the validation\nset, the problem must come from the data mismatch. You can try to tackle this prob-\nlem by preprocessing the web images to make them look more like the pictures that\nwill be taken by the mobile app, and then retraining the model. Conversely, if the\nmodel performs poorly on the train-dev set, then the model must have overfit the\ntraining set, so you should try to simplify or regularize the model, get more training\ndata and clean up the training data, as discussed earlier.\n\nNo Free Lunch Theorem\n\nA model is a simplified version of the observations. The simplifications are meant to\ndiscard the superfluous details that are unlikely to generalize to new instances. How-\never, to decide what data to discard and what data to keep, you must make assump-\ntions. For example, a linear model makes the assumption that the data is\nfundamentally linear and that the distance between the instances and the straight line\nis just noise, which can safely be ignored.\n\nIn a famous 1996 paper,'! David Wolpert demonstrated that if you make absolutely\nno assumption about the data, then there is no reason to prefer one model over any\nother. This is called the No Free Lunch (NFL) theorem. For some datasets the best\n\n\nmodel is a linear model, while for other datasets it is a neural network. There is no\nmodel that is a priori guaranteed to work better (hence the name of the theorem). The\nonly way to know for sure which model is best is to evaluate them all. Since this is not\npossible, in practice you make some reasonable assumptions about the data and you\nevaluate only a few reasonable models. For example, for simple tasks you may evalu-\nate linear models with various levels of regularization, and for a complex problem you\nmay evaluate various neural networks.\n\n",
                        "extracted-code": ""
                    }
                ]
            }
        ]
    }
}
{
    "New item": {
        "chapters": [
            {
                "chapter_id": 1,
                "chapter_name": "MASTER: Market-Guided Stock Transformer for Stock Price Forecasting",
                "chapter_path": "./screenshots-images-2/chapter_1",
                "sections": [
                    {
                        "section_id": 1.1,
                        "section_name": "MASTER: Market-Guided Stock Transformer for Stock Price Forecasting",
                        "section_path": "./screenshots-images-2/chapter_1/section_1",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_1/64ca1a6c-8528-4a2d-a4e1-8ffd569b5ef2.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "Abstract\n\nStock price forecasting has remained an extremely challeng-\ning problem for many decades due to the high volatility of the\nstock market. Recent efforts have been devoted to modeling\ncomplex stock correlations toward joint stock price forecast-\ning. Existing works share a common neural architecture that\nlearns temporal patterns from individual stock series and then\nmixes up temporal representations to establish stock correla-\ntions. However, they only consider time-aligned stock cor-\nrelations stemming from all the input stock features, which\nsuffer from two limitations. First, stock correlations often oc-\ncur momeatarily and in a cross-time manner. Second, the fea-\nture effectiveness is dynamic with market variation, which af-\nfects both the stock sequential patterns and their correlations.\nTo address the limitations, this paper introduces MASTER, a\nMArkert-Guided Stock TransformER, which models the mo-\nmentary and cross-time stock correlation and leverages mar-\nket information for automatic feature selection. MASTER el-\negantly tackles the complex stock correlation by alternatively\nengaging in intra-stock and inter-stock information aggrega-\ntion. Experiments show the superiority of MASTER com-\npared with previous works and visualize the captured realistic\nstock correlation to provide valuable insights.\n",
                        "extracted-code": "",
                        "gpt-text-processed": "Abstract\n\nPredicting stock prices has been a tough challenge for many years, mainly because the stock market is very unpredictable. Recently, researchers have focused on understanding how different stocks relate to one another in order to make better predictions about their prices. Many of these studies use similar methods, looking at patterns over time for individual stocks and then trying to connect these patterns to find relationships between them. However, these approaches have two main drawbacks. First, the relationships between stocks can change quickly and don't always follow a straightforward timeline. Second, the importance of different stock features can change as the market evolves, which impacts how we understand both the sequences of stock movements and their relationships.\n\nTo overcome these challenges, this paper introduces a new method called MASTER, which stands for Market-Guided Stock Transformer. MASTER effectively captures both the brief and time-crossing relationships between stocks and uses market information to automatically decide which features are the most useful. It smartly combines information from within the same stock (intra-stock) and between different stocks (inter-stock) to unravel the complexities of these relationships. Tests have shown that MASTER outperforms previous methods and helps visualize real-world stock connections, offering valuable insights into stock behavior."
                    },
                    {
                        "section_id": 1.2,
                        "section_name": "Introduction",
                        "section_path": "./screenshots-images-2/chapter_1/section_2",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_2/cc47067d-7d02-43b9-a325-5badf53c4568.png",
                            "./screenshots-images-2/chapter_1/section_2/a90d549a-c7c8-4211-bb8b-603ebf78aa29.png",
                            "./screenshots-images-2/chapter_1/section_2/d4836dc0-e4f6-40bb-900a-9d5c07814651.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "Stock price forecasting, which utilizes historical data col-\nlected from the stock market to predict future trends, is a\nvital technique for profitable stock investment. Unlike sta-\ntionary time series that often exhibit regular patterns such\nas periodicity and steady trends, the dynamics in the stock\nprice series are intricate because stock prices fluctuate sub-\nject to multiple factors, including macroeconomic factors,\ncapital flows, investor sentiments, and events. The mixing\nof factors interweaves the stock market as a correlated net-\nwork, making it difficult to precisely predict the individual\nbehavior of stocks without taking other stocks into account.\n\nMost previous works (Feng et al. 2019; Xu et al. 2021;\nWang et al. 2021, 2022; Wang, Qu, and Chen 2022) in the\nfield of stock correlation have relied on predefined concepts,\nrelationships, or rules and established a static correlation\ngraph, e.g., stocks in the same industry are connected to each\n\n| FBR esis mp\n\u201cll SSN tees\n\nstock sequences representations _carrelation module predictions\n\nFigure 1: The framework of existing works. The dashed lines\nrepresent the underlying momentary and cross-time stock\ncorrelations, which reside between some (stock, , time),\n(stock, time) pairs.\n\nother. While these methods provide insights into the rela-\ntions between stocks, they do not account for the real-time\ncorrelation of stocks. For example, different stocks within\nthe same industry can experience opposite price movements\non a particular day. Additionally, the pre-defined relation-\nships may not be generalizable to new stocks in an evolv-\ning market where events such as company listing, delist-\ning, or changes in the main business happen normally. An-\nother line of research (Yoo et al. 2021) follows the Trans-\nformer architecture (Vaswani et al. 2017), and use the self-\nattention mechanism to compute dynamic stock correlations.\nThis data-driven manner is more flexible and applicable to\nthe time-varying stock sets in the market. Despite differ-\nent schemes for establishing stock correlations, the exist-\ning methods generally follow a common two-step compu-\ntation flow. As depicted in Figure 1, the first step is using a\nsequential encoder to summarize the historical sequence of\nstock features, and obtain stock representation, and the sec-\nond step is to refine each stock representation by aggregating\ninformation from correlated stocks using graph encoders or\nattention mechanism. However, such a flow suffers from two\nlimitations.\n\nFirst, existing works distill an overall stock representation\nand blur the time-specific details of stock sequence, lead-\ning to weakness in modeling the de-facto stock correlations,\nwhich often occurs momentarily and in a cross-time man-\nner (Bennett, Cucuringu, and Reinert 2022). To be specific,\nthe stock correlation is highly dynamic and may reside in\nmisaligned time steps rather than holding true through the\nwhole lookback period. This is because the dominating fac-\ntors of stock prices constantly change, and different stocks\nmay react to the same factors with different delays. For in-\n\nstance, upstream companies\u2019 stock prices may react faster to\na shortage of raw materials than those of downstream com-\npanies, and individual stocks exhibit a lot of catch-up and\nfall-behind behaviors.\n\nSince the stock correlation may underlie between every\nstock pair and time pair, a straightforward way to simu-\nlate the momentary and cross-time correlation is to gather\nthe 7 x |S| feature vectors for pair-wise attention computa-\ntion, where 7 is the lookback window length and S is the\nstock set. However, in addition to the increased computa-\ntional complexity, this approach faces practical difficulties\nbecause the stock forecasting task is in intense data hunger.\nIntuitively, there are only around 250 trading days per year,\nproducing limited observations on stocks. When the model\nadopts such a large attention field with insufficient training\nsamples, it often struggles to optimize and may even fall\ninto suboptimal solutions. Although clustering approaches\nlike local sensitive hashing (Kitaev, Kaiser, and Levskaya\n2020) have been proposed to reduce the size of the attention\nfield, they are sensitive to initialization, which is a fatal issue\nin a data-hungry domain like stock forecasting. To address\nthese challenges, we propose a novel stock transformer ar-\nchitecture specifically designed for stock price forecasting.\nRather than directly modeling the r x |S| attention field or\nusing clustering-based approximation methods, our model\naggregates information from different time steps and differ-\nent stocks alternately to model realistic stock correlation and\nfacilitate model learning.\n\nAnother limitation of existing works is that they ignore\nthe impact of varying market status. In long-term practice\nwith the market variation, one essential observation by in-\nvestors is that the features come into effect and expire dy-\nnamically. The effectiveness of features has an influence on\nboth the intra-stock sequential pattern and the stock correla-\ntion. For instance, in a bull market, the correlations among\nstocks are more significant due to the investors\u2019 optimism.\nTraditional investors repeatedly conduct statistical examina-\ntion on to select effective feature, which is exhaustive and\nface a gap when integrated with learning-based methods.\nTo save the human efforts, we are motivated to equip our\nstock transformer with a novel gating mechanism, which in-\ncorporates the market information to perform automatically\nfeature selection. We name the proposed method MASTER,\nstanding for MArket-Guided Stock TransformER. To sum-\nmarize, our main contributions are as follows.\n\nWe propose a novel stock transformer for stock price\nforecasting to effectively capture the stock correlation. To\nthe best of our knowledge, we are the first to mine the\nmomentary and cross-time stock correlation with learning-\nbased methods.\n\nWe introduce a novel gating mechanism that integrates\nmarket information to automatically select relevant features\nand adapt to varying market scenarios.\n\nWe conducted experiments to validate the designs of our\nproposed method and demonstrated its superiority compared\nto baselines. The visualization results provided valuable in-\nsights into the real-time dynamics of stock correlations.\n",
                        "extracted-code": "",
                        "gpt-text-processed": "Stock price forecasting is the process of using historical data from the stock market to predict future price trends, which is crucial for making profitable investments. Unlike many types of data that show consistent patterns over time, stock prices are influenced by a variety of complex factors. These can include broader economic conditions, movements of money in and out of stocks, how investors feel about the market, and various events that can impact prices. Because of this complexity, it isn't easy to predict how one stock will behave, especially without considering how other stocks are performing as well.\n\nMany previous studies on stock correlation have worked with predetermined ideas and established static connections\u2014like saying that stocks in the same industry are linked. While these approaches can shed some light on stock relationships, they do not really account for how stocks interact in real-time. For example, two companies in the same industry might see their stock prices move in opposite directions on a given day. Plus, stock markets are constantly changing\u2014new companies can list, others can remove themselves, and businesses can shift focus\u2014all of which means past relationships between stocks may not apply universally.\n\nSome newer research has adopted a model called the \"Transformer,\" which allows for a more flexible and data-driven way of understanding stock correlations. Commonly, these methods involve two main steps: first, they summarize past stock information to create a general profile for each stock; then, they refine this profile by considering the relationships with other stocks. However, this method does have its downsides:\n\n1. **Overall Representation:** These previous methods often lose important time-specific details, which can weaken their ability to understand real stock correlations that may happen at specific moments. Stock responses can be quite dynamic and vary between different timeframes. For example, a company that supplies materials may respond faster to a shortage than a company that uses those materials.\n\n2. **Data Challenges:** Gathering data for every stock at every moment creates a complex problem. There are only about 250 trading days in a year, which limits how much information is available. When we try to analyze many relationships at once with limited data, it becomes hard for the model to learn properly, often leading to flawed outcomes.\n\nTo tackle these issues, we\u2019ve developed a new method called MASTER, which stands for MArket-Guided Stock TransformER. Instead of focusing on complex relationships that are difficult to analyze or using clustering approaches that can be unreliable, MASTER combines information from different stocks and time periods in a way that reflects real-world stock interactions.\n\nAlso, previous models didn\u2019t take into account how the market itself changes over time and how that can affect stock performance. For instance, during a booming market, stocks might show stronger correlations due to general investor optimism. Standard methods of reviewing which stock data is useful can be very tedious. Therefore, we've included an innovative feature in MASTER that auto-selects the most relevant stock information based on current market conditions.\n\n**In summary, our key contributions include:**\n\n1. **Introducing MASTER:** A new forecasting method that effectively captures how stocks are related at different moments in time.\n2. **Dynamic Feature Selection:** The built-in mechanism to automatically choose the most relevant features based on market conditions.\n3. **Validation of the Model:** We tested our approach and showed that it outperforms existing methods, offering new insights into how stock correlations operate in real-time.\n\nThis work aims to make stock price forecasting more effective and adaptable to the changing market landscape."
                    },
                    {
                        "section_id": 1.3,
                        "section_name": "Methodology",
                        "section_path": "./screenshots-images-2/chapter_1/section_3",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_3/ef354085-6a26-4bff-b9f6-1285f095447b.png",
                            "./screenshots-images-2/chapter_1/section_3/11c38089-1319-4df0-8411-eaa634ac641a.png",
                            "./screenshots-images-2/chapter_1/section_3/bd2b0d33-ec1b-4ff7-a390-3ddd40adddde.png",
                            "./screenshots-images-2/chapter_1/section_3/f8986c6e-46d0-400b-a24a-185f744513b7.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "Problem Formulation\n\nThe indicators of each stock u \u20ac S are collected at every\ntime step \u00a2 \u20ac [1,7] to form the feature vector r,, \u20ac R\u201d.\nFollowing existing works on stock market analysis (Feng\net al. 2018; Sawhney et al. 2020; Huynh et al. 2023), we\nfocus on the prediction of the change in stock price rather\nthan the absolute value. The retum ratio, which is the rel-\native close price change in d days, is Fu = (\u00a2u,r+a \u2014\nCu.r+1)/Cur+i+ Where e+ is the closing price of stock u\nat time step \u00a2, and d represents the predetermined prediction\ninterval. The return ratio normalizes the market price vari-\nety between different stocks in comparison to the absolute\nprice change. Since stock investment is to rank and select\nthe most profitable stocks, we perform daily Z-score normal-\nization of return ratio to encode the label with the rankings,\nr, = Norms(?,), as in previous work (Yang et al. 2020).\n\nDefinition 1 (Stock Price Forecasting) Given stock fea-\ntures {uy\u00a2}ues,te[i.r) the stock price forecasting is to\njointly predict the future normalized return ratio {r.}ues-\n\nOverview\n\nFigure 2 depicts the architecture of our proposed method\nMASTER, which consists of five steps. (1) Market-Guided\nGating. We construct a vector representing the current mar-\nket status m, and leverage it to rescale feature vectors by\na gating mechanism, achieving market-guided feature selec-\ntion. (2) Intra-Stock Aggregation. Within the sequence of\neach stock, at each time step, we aggregate information from\nother time steps to generate a local embedding that preserves\nthe temporal local details of the stock while collecting all\nimportant signals along the time axis. The local embedding\nhy will serve as relays and transport the collected signals\nto other stocks in subsequent modules. (3) Inter-Stock Ag-\ngregation. At each time step, we compute stock correlation\nwith attention mechanism, and each stock further aggregates\nthe local embedding of other stocks. The aggregated infor-\nmation 2.,\u00a2, which we refer to as temporal embedding, con-\ntains not only the information of the momentarily correlated\nstocks at t, but also preserves the personal information of\nu. (4) Temporal Aggregation. For each stock, the last tem-\nporal embedding queries from all historical temporal em-\nbedding and produce a comprehensive stock embedding e,,.\n(5) Prediction. The comprehensive stock embedding is sent\nto prediction layers for label prediction. We elaborate on\nthe details of MASTER step by step in the following sub-\nsections.\n\nMarket-Guided Gating\n\nMarket Status Representation \u2014 First, we propose to com-\nbine information from two aspects into a vector m, to give\nan abundant description of the current market status. (1)\nMarket index price. The market index price is a weighted\naverage of the prices of a group of stocks S\u2019 by their share\nof market capitalization. S\u2019 is typically composed of top\ncompanies with the most market capitalization, represent-\ning a particular market or sector, and may differ from user-\n\n1. Market-Guided Gating\n\n\u2018Time Step \u00a2\nzu 5\n\u201c\nfog\n\u2018\nYej\u2014 Stock w\n\nFigure 2: Overview of the MASTER framework.\n\ninterested stocks in investing S. We include both the cur-\nrent market index price at 7 and the historical market index\nprices, which is described by the average and standard de-\nviation in the past d\u2019 days to reveal the price fluctuations.\nHere, d\u2019 specifies the referable interval length to introduce\nhistorical market information in applications. (2) Market in-\ndex trading volume. The trading volumes of S\u2019 reveals the\ninvestors involvement, reflecting the activity of the market.\nWe include the average and standard deviation of market in-\ndex trading volume in the past d\u2019 days, to reveal the actual\nsize of the market. S' and d\u2019 are identical to the aforemen-\ntioned definitions. Now we present the market-guided stock\nprice forecasting task.\n\nDefinition 2 (Market-Guided Stock Price Forecasting)\nGiven {u,\u00a2}ues.te[i,r) and the constructed market status\nvector m,, market-guided stock price forecasting is to\njointly predict the future normalized return ratio {r,}ues-\n\nGating Mechanism The gating mechanism generates one\nscaling coefficient for each feature dimension to enlarge or\nshrink the magnitude of the feature, thereby emphasizing\nor diminishing the amount of information from the feature\nflowing to the subsequent modules. The gating mechanism\nis learned by the model training, and the coefficient is opti-\nmized by how much the feature contributes to improve fore-\ncasting performance, thus reflect the feature effectiveness.\n\nGiven the market status representation m,,|m,| = F\u2019,\nwe first use a single linear layer to transform m, into the\nfeature dimension F = |2,, \u00a2|. Then, we perform Softmax\nalong the feature dimension to obtain a distribution.\n\na(m,) = F + softmaxs(Wam, +a),\n\nwhere W,,, b,, are learnable matrix and bias, {9 is the temper-\nature hyperparameter controlling the sharpness of the output\ndistribution. Softmax compels a competition among features\nto distinguish the effective ones and ineffective ones. Here,\na smaller temperature 3 encourages the distribution to focus\non certain dimension and the gating effect is stronger while a\nlarger 3 makes the distribution incline to even and the gating\neffect is weaker. Note that we enlarge the value at each di-\nmension by F times as the scaling coefficient. This operation\n\ncompare the generated distribution with a uniform distribu-\ntion where each dimension is 1/F, to determine whether to\nenlarge or shrink the value. The intuition to generate coef-\nficients from m, is that the effectiveness of features are in-\nfluenced by market status. For example, if the model learns\nmoving average (MA) factor is useful during volatile mar-\nket periods, it will emphasize MA when the market becomes\nvolatile again. Under the same m,, a are shared for {x7 \u00a2},\nu \u20ac S,t \u20ac [1,7], in that we incorporate the most recent mar-\nket status to perform unified feature selection. The rescaled\nfeature vectors are Z,, = a(m,) o \u00a9, \u00a2, where o is the\nHadamard product.\n\nIntra-Stock Aggregation\n\nIn MASTER, we use intra-stock aggregation followed by\ninter-stock aggregation to break down the large and complex\nattention field. Although the entire market is complicated\nwith diverse behaviours of individual stocks, the patterns of\na specific stock tend to be relatively continuous. Therefore,\nwe perform intra-stock aggregation first due to its smaller at-\ntention field and simpler distribution. In our proposed intra-\nstock aggregation, the feature at each time step aggregate in-\nformation from other time steps and form a local embedding.\nCompared with existing works which initially mix the fea-\nture sequence into one representation (Yoo et al. 2021), we\nmaintain a sequence of local embedding which are advised\nwith the important signals in sequence through intra-stock\naggregation while reserve the local details.\n\nWe first send the rescaled feature vectors to a feature en-\ncoder and transform them into the embedding space, y,, \u00a2 =\nf(\u00aeu.), \\Yue| = D. We simply use a single linear layer as\nJ(-). Then, we apply a bi-directional sequential encoder to\nobtain the local output at each time step t. Inspired by the\nsuccess of transformer-based models in modeling sequential\npatterns, we instantiate the sequential encoder with a single-\nlayer transformer encoder (Vaswani et al. 2017). Each fea-\nture vector at a particular time step is treated as a token, and\nwe add a fixed D-dimensional sinusoidal positional encod-\ning p: to mark the chronically order in the look back window.\n\nYu = Sleep LN(f(@ue) + Peds\nwhere || denotes the concatenation of vectors and LN the\n\nlayer normalization. Then, the feature embedding at each\ntime step queries from all time steps in the stock sequence.\nWe introduce multi-head attention mechanisms, denoted as\nMHA(;), with V, heads to perform different aggregations in\nparallel. We also utilize feed forward layers, FFN(-), to fuse\nthe information obtained from the multi-head attention.\nQ.=WhY., KL=WkY, Vi= Wi,\n\nHD, = |leeriftue = FFN'(MHA' (Qi, KL, Vit) + Yu),\nwhere FFN is a two-layer MLP with ReLU activation and\nresidual connection. As a result, the local embedding h,, \u00a2\nboth reserve the local details and encode indicative signals\nfrom other time steps.\n\nInter-Stock Aggregation\n\nThen, we consider aggregating information from correlated\nstocks. Compared with existing works that distill an over-\nall stock correlation, we establish a series of momentary\nstock correlation corresponding to every time step. Instead\nof using pre-defined relationships that face a mismatch with\nthe proximity of real-time stock movements, we propose to\nmine the asymmetric and dynamic inter-stock correlation\nvia attention-mechanism. The quality of the correlation will\nbe measured by its contribution to improving the forecast-\ning performance, and automatically optimized by the model\ntraining process.\n\nSpecifically, at each time step, we gather the local embed-\nding of all stocks H? = |/,,cshy,. and perform multi-head\nattention mechanism with N> heads.\n\nQ?=W3H?, K?=WRH?, V2 =WH?,\n\n2, = |Iucs%ue = FFN\"(MHA*(Q?, K?, V2) + H2).\nWith the residual connection of FFN, the temporal embed-\nding 2u,+ is encoded with both the information from momen-\ntarily correlated stocks and the personal information of stock\nu itself. Our stock transformer is able to model the cross-\ntime correlation of stocks, as shown in Figure 2 (Right). The\nlocal details of y, ; can first be conveyed to h, ; by the intra-\nstock aggregation of stock v, and then transmitted to 2,\nby inter-stock aggregation at time step i, hence modeling\nthe correlation from any (v, j) to (w, i). We further visualize\nand explain the captured cross-time correlation in the exper-\niments section.\n\nTemporal Aggregation\n\nIn contrast with existing works which obtain one embedding\nfor each stock after modeling stock correlation (Feng et al.\n2019), our approach involves producing a series of temporal\nembedding z,;,\u00a2 \u20ac [1,7]. Each z,\u00a2 is encoded with in-\nformation from stocks that are momentarily correlated with\n(u, t). To summarize the obtained temporal embeddings and\nobtain a comprehensive stock embedding e,,, we employ a\ntemporal attention layer along the time axis. We use the lat-\nest temporal embedding z,, - as the query vector, and com-\npute the attention score A,, ; in a hidden space with transfor-\nmation matrix W,,\n\nexp(2eWrzu.r)\ndat = Soo = Au,t2u,t+\nDieter) PCT Wazu,r) x\u00bb\n\nPrediction and Training\n\nFinally, the stock embedding e. is fed into a predictor 9(-)\nfor label regression. We use a single linear layer as the pre-\ndictor, and the forecasting quality is measured by the MSE\nloss. In each batch, MASTER is jointly optimized for all\nu \u20ac S ona particular prediction date. And a training epoch\nis composed of multiple batches correspond to different pre-\ndiction dates in the training set.\n\nFu =9(eu), L= SO MSE(ra, Fu).\n\nues\n",
                        "extracted-code": "",
                        "gpt-text-processed": "**Understanding Stock Price Prediction with MASTER**\n\n**Problem Overview**\n\nIn the world of stock trading, we aim to forecast how stock prices will change over time, rather than just their actual values. To achieve this, we gather detailed information about each stock at different points in time. This information is used to create a series of measurements called feature vectors that represent the state of each stock.\n\nWe specifically focus on what\u2019s known as the \u201creturn ratio,\u201d which helps to illustrate how much the price of a stock has changed over a set number of days, rather than just its current price. This makes it easier to compare different stocks. Once we have this data, we also adjust it to rank the stocks based on their predicted performance.\n\n**Key Steps in Our Method, MASTER**\n\nOur method, named MASTER, consists of five main steps that work together to predict stock prices more effectively:\n\n1. **Market-Guided Gating**: We assess the overall state of the market to adjust our data for each stock. This involves using indicators like the current market index (an average of top stocks) and recent trading volumes to better frame our predictions.\n\n2. **Intra-Stock Aggregation**: We look at how each stock behaves over time and integrate information from other recent points in its own timeline. This helps to keep track of important trends and events that might affect the stock\u2019s future.\n\n3. **Inter-Stock Aggregation**: Here, we analyze how different stocks influence one another by comparing their behaviors at similar points in time. This dynamic approach helps to get real-time correlations, which can shift constantly as the market changes.\n\n4. **Temporal Aggregation**: This step involves synthesizing all the information gathered over time to create a unified representation of each stock. It helps us encapsulate everything we\u2019ve learned about stock behaviors into one comprehensive view.\n\n5. **Prediction**: Finally, we use the gathered data to make predictions about future stock prices. This process helps us apply everything we know into actionable insights.\n\n**Explaining Market-Guided Gating Further**\n\nIn the first step, we build a more detailed picture of the market by looking at two key factors:\n\n1. **Market Index Price**: This is an average price of certain prominent stocks. We include recent trends and variations in this index over a set period, which informs how price fluctuations might influence the predictions.\n\n2. **Market Trading Volume**: This tells us how actively stocks are being traded, giving us insights into market interest levels. We include averages and variations in trading volume over the same period as the index prices to gauge the market's activity.\n\n**The Gating Mechanism**\n\nThis part is about adjusting the importance of different pieces of information in our model. As the market fluctuates, certain indicators may become more or less important, and our system learns to adapt to these changes, sort of like tuning a musical instrument for a perfect pitch. \n\n**Intra-Stock and Inter-Stock Aggregation**\n\nWhile we analyze a single stock's data over time, we also recognize how important it is to consider data from other similar stocks. For instance, if two stocks are often influenced by the same market conditions, observing how they respond together can provide critical insights.\n\n**Final Steps and Prediction**\n\nAfter gathering and organizing all this information, we summarize everything to create a final stock picture or \"embedding.\" This final touch allows us to input this information into our prediction model, which then computes the expected future returns of the stocks.\n\nOnce everything is set up, we measure how well our predictions match against actual outcomes. If our predictions aren\u2019t accurate enough, we tweak the model to enhance its accuracy in the next cycle.\n\nThrough MASTER, we strive to produce well-informed stock forecasts, enabling traders and investors to make smarter decisions based on potential returns."
                    },
                    {
                        "section_id": 1.4,
                        "section_name": "Discussions",
                        "section_path": "./screenshots-images-2/chapter_1/section_4",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_4/4974376d-4a92-4341-87d6-dd07b232ad63.png",
                            "./screenshots-images-2/chapter_1/section_4/404c3ee8-bdfd-4fa2-90b9-5bf1fa918515.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "Relationships with Existing Works Modeling stock cor-\nrelations has long been an indispensable research direc-\ntion for stock price prediction. Today, many researchers\nand quantitative analysts, still opt for linear models, sup-\nport vector machines, and tree-based methods for stock price\nforecasting (Nugroho, Adji, and Fauziati 2014; Chen and\nGuestrin 2016; Kamble 2017; Xie et al. 2013; Li et al. 2015;\nPiccolo 1990). The aggregation of correlation information\nwithin and between stocks is often achieved through fea-\nture engineering, which relies heavily on manual expertise\nand constantly faces the risk of factor decay. Inspired by\nthe success of neural sequential data analysis, researchers\nare driven to take into account the stock feature sequences\nand learn the temporal correlation automatically. They de-\nsign various sequential models, such as RNN-based (Feng\net al. 2019; Sawhney et al. 2021; Yoo et al. 2021; Huynh\net al. 2023), CNN-based (Wang et al. 2021), and attention-\nbased models(Liu et al. 2019; Ding et al. 2020), to mine the\ninternal temporal dynamics of a stock. Recent research focus\non the modeling of stock correlation, which add a correlation\nmodule in posterior to the sequential model as illustrated in\nFigure 1. They propose to use graph-based (Feng et al. 2019;\nXu et al. 2021; Wang et al. 2021, 2022), hypergraph-based\n(Sawhney et al. 2021; Huynh et al. 2023) and attention-\nbased (Yoo et al. 2021; Xiang et al. 2022) modules to build\nthe overall stock correlation and perform joint prediction.\nOur MASTER is dedicated to momentary and cross-time\nstock correlation mining. To do so, we develop a novel\nmodel architecture as in Figure 2 that is genuinely different\nfrom all existing methods. Furthermore, MASTER is spe-\ncialized for stock price forecasting, which is distinct in data\nform and task properties from existing transformer-based\nmodels in spatial-temporal data (Bulat et al. 2021; Cong\net al. 2021; Xu et al. 2020; Li et al. 2023) or multivariate\ntime series domains (Zhang and Yan 2022; Nie et al. 2022).\n\nComplexity Analysis We now analyze the computation\ncomplexity of our proposed method. Let M = |S|, the\nmarket-guided gating rescale M x 7 feature vectors of\ndimension F. In intra-stock aggregation, the calculation\namount of pair-wise attention is 7? for each stock at\neach attention head. In inter-stock aggregation, the calcu-\nlation amount is M? at each time step and each atten-\ntion head. In temporal aggregation, we compute 7 atten-\ntion scores for each stock. The overall computation com-\nplexity is O(F Mr + NiMr?D? + N2M?rD? + MrD*),\n\nwhere M >> r. Therefore, MASTER is of O(N2M?7D*)\ntime complexity. Compared with directly operating on the\nM x 7 attention field with N attention heads, which is\nin O(NM?r*D*), we reduce the computation cost by\nabout 7 times and achieve modeling cross-time correla-\ntions between stocks more efficiently. The overall param-\neters to be trained in MASTER are transformation matri-\nces Wh,Whk, Wy, W3,Wk, We, Wa, which is in shape\nD x D, and parameters in MLP layers \u00ab, f,FFN',FFN?\nand g.\n",
                        "extracted-code": "",
                        "gpt-text-processed": "**Connecting with Existing Research**\n\nUnderstanding how stocks influence one another is crucial for predicting their prices. Traditionally, many researchers and analysts have relied on straightforward methods like linear models, support vector machines, and tree-based methods for stock price forecasting. These approaches often depend on manually curated features to assess how stocks relate to each other, which can sometimes lead to outdated or less relevant information.\n\nRecently, some experts have begun to adopt more modern techniques inspired by advancements in analyzing sequential data, like how we understand sequences of events or data points over time. This shift has led to the development of various models that automatically learn the relationships and patterns in stock data, rather than relying solely on human expertise. For instance, researchers have utilized models known as RNN (Recurrent Neural Networks), CNN (Convolutional Neural Networks), and attention-based approaches to capture the changing dynamics of stock behavior over time.\n\nThe latest studies have placed a spotlight on enhancing our understanding of stock correlations, often adding specialized tools to existing sequential models to improve predictions. Some of these new tools involve graph-based and hypergraph-based modeling techniques that help map out relationships between stocks more intuitively.\n\nThe novel approach we present, called MASTER, focuses specifically on both instant and time-related correlations between different stocks. Our model is designed distinctly, providing a fresh perspective that separates it from current methods used for stock price forecasts and other time-related data sets.\n\n**Understanding Complexity**\n\nNow, let's break down how our model works in terms of its computational demands. When we talk about complexity, we refer to how much computational power and time it takes for a model to process data.\n\nIn MASTER, we work with a set of features collected from various stocks. The process begins by aggregating information about individual stocks and then about stocks in relation to each other. We perform multiple calculations at different levels to determine how stocks influence one another over time. \n\nA key point is that MASTER handles these relationships more efficiently than many existing approaches. By reducing the amount of computation needed by about seven times, we can more effectively analyze and make predictions about how stocks interact with one another across different time periods.\n\nIn summary, our model, MASTER, is optimized for understanding stock price movements and their interconnections while being computationally efficient. It uses a series of parameters that help train the model and enhance its predictive power, all while ensuring we can handle large datasets effectively."
                    },
                    {
                        "section_id": 1.5,
                        "section_name": "Experiments",
                        "section_path": "./screenshots-images-2/chapter_1/section_5",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_5/22a1f759-bf16-4034-b73e-c26a1d33231b.png",
                            "./screenshots-images-2/chapter_1/section_5/b6aedd37-534e-47bd-9bc1-8d1a88f6f663.png",
                            "./screenshots-images-2/chapter_1/section_5/7fec84df-d137-4ef5-817a-fcfe4c6ff0d0.png",
                            "./screenshots-images-2/chapter_1/section_5/39e62ca4-116f-4824-8ef2-0e15557f9cc4.png",
                            "./screenshots-images-2/chapter_1/section_5/13bcbbc7-fd26-46fa-9317-71675732f4c5.png",
                            "./screenshots-images-2/chapter_1/section_5/d58d0036-a31e-43bb-9f05-d8abc83455c2.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "In this section, we conduct experiments to answer the fol-\nlowing four research questions:\n\n* RQI How is the overall performance of MASTER com-\npared with state-of-the-art methods?\n\n* RQ2 Is the proposed stock transformer architecture ef-\nfective for stock price forecasting?\n\n* RQ3 How do hyper-parameter configurations affect the\nperformance of MASTER?\n\n* RQ4 What insights on the stock correlation can we get\nthrough visualizing the attention map?\n\nDatasets We evaluate our framework on the Chinese stock\nmarket with CSI300 and CSI800 stock sets. CSI300 and\nCSI800 are two stock sets containing 300 and 800 stocks\nwith the highest capital value on the Shanghai Stock Ex-\nchange and the Shenzhen Stock Exchange. The dataset\ncontains daily information ranging from 2008 to 2022 of\nCSI300 and CSI800. We use the data from QI 2008 to QI\n2020 as the training set, data in Q2 2020 as the validation\nset, and the last ten quarters, ie., Q3 2020 to Q4 2022, are\nreserved as the test set. We apply the public Alphal58 in-\ndicators (Yang et al. 2020) to extract stock features from\nthe collected data. The lookback window length 7 and pre-\ndiction interval d are set as 8 and 5 respectively. For mar-\nket representation, we constructed 63 features with CSI300,\nCSIS00 and CSI800 market indices, and refereable interval\nd\u2019 = 5, 10, 20, 30, 60.\n\nBaselines We compare the performance of MASTER with\nseveral stock price forecasting baselines from different cate-\ngories. e XGBoost (Chen and Guestrin 2016): A decision-\ntree based method. According to the leaderboard of Qlib\nplatform (Yang et al. 2020), it is one of the strongest base-\nlines. e LSTM (Graves and Graves 2012), GRU (Cho et al.\n2014), TCN (Bai, Kolter, and Koltun 2018), and Trans-\nformer (Vaswani et al. 2017): Sequential baselines that lever-\nage vanilla LSTM/GRU/Temporal convolutional network/-\nTransformer along the time axis for stock price forecasting.\n\u00a2 GAT (Velitkovi\u00e9 et al. 2017): A graph-based baseline,\nwhich first use sequential encoder to gain stock presenta-\ntion and then aggregate information by graph attention net-\nworks', e DTML (Yoo et al. 2021): A state-of-the-art stock\ncorrelation mining method, which follows the framework in\nFigure 1. DTML adopts the attention-mechanism to mine\n\nthe dynamic correlation among stocks and also incorporates\nthe market information into the modeling.\n\nEvaluation We adopt both ranking metrics and portfolio-\nbased metrics to give a thorough evaluation of the model\nperformance. Four ranking metrics, Information Coefficient\n(IC), Rank Information Coefficient (RankIC), Information\nRatio based IC (ICIR) and Information Ratio based RankIC\n(RankICIR) are considered. IC and RankIC are the Pearson\ncoefficient and Spearman coefficient averaged at a daily fre-\nquency. ICIR and RankICIR are normalized metrics of IC\nand RankIC by dividing the standard deviation. Those met-\nrics are commonly used in literature (e.g., Xu et al. 2021 and\nYang et al. 2020) to describe the performance of the forecast-\ning results from the value and rank perspectives. Further-\nmore, we employ two portfolio-based metrics to compare\nthe investment profit and risk of each method. We simulate\ndaily trading using a simple strategy that selects the top 30\nstocks with the highest return ratio and reports the Excess\nAnnualized Return (AR) and Information Ratio (IR) met-\nrics. AR measures the annual expected excess return gener-\nated by the investment, while IR measures the risk-adjusted\nperformance of an investment.\n\nImplementation We implemented MASTER? with Py-\n\u2018Torch and build our methods based on the open-source quan-\ntitative investment platform Qlib (Yang et al. 2020). For\nDTML, we implement it based on the original paper since\nthere is no official implementation publicly. For other base-\nlines, we use their Qlib implementations. For hyperparame-\nters of each baseline method, the layer number and model\nsize are tuned from {1,2,3} and {128,256,512} respec-\ntively. The learning rate [r is tuned among {10~*}e(3,4.5,6}+\nand we selected the best hyperparameters based on the IC\nperformance in the validation stage. For hyperparameters of\nMASTER, we tune the model size D and learning rate Ir\namong the same range as the baselines, and the final selec-\ntion is D=256, Ir=10~S for all datasets; we set N,=4, N2=2\nfor all datasets and S=5 and \u00a7=2 for CSI300 and CSI800\nrespectively. More implementation details of baseline meth-\nods are summarized in the supplementary materials. Each\nmodel is trained for at most 40 epochs with early stopping.\nAll the experiments are conducted on a server equipped with\nIntel(R) Xeon(R) Platinum 8163 CPU, 128GB Memory, and\na Tesla V100-SXM2 GPU (16GB Memory). Each experi-\nment was repeated 5 times with random initialization and\nthe average performance was reported.\n\nOverall Performance (RQ1)\n\nThe overall performance are reported in Table 1 MAS-\nTER achieves the best results on 6/8 of the ranking met-\nrics, and consistently outperforms all benchmarks in the\nportfolio-based metrics. In particular, MASTER achieve\n13% improvements in ranking metrics and 47% improve-\nments in portfolio-based metrics compared to the second-\nbest results on the average sense. Note that ranking matrics\nare computed with the whole set and portfolio-based metrics\n\nDataset | Model 1 Ic Ick RankIC RankICIR AR IR\nXGBoost 0.0514\u00a30.001 0.370.010.0504 0.001 0.36 \u00a30.01 | 0.234003 1.9403\nLSTM 0.049 + 0.001 0.05140.002 0.414003 | 0204004 20+04\nGRU 0.052 + 0.004 0.05240.005 0.344004 | 0.194004 T5203\n\nCSI300 TCN 0.050 + 0.002 0.33 + 0.04 0.049 + 0.002 0.31 + 0.04 0.18 + 0.05 14405\nTransformer | 0.04740.007 0.3940.040.0514.0.002 0.42 40.04 | 0.2240.06 20404\nGAT 0.05440.002 0.360.020.0414 0.002 0.25 \u00a30.02 | 0.194003 13403\nDTML 0.049\u00a30.006 0.3340.04 0.0524.0.005 0.3340.04 | 0.214003 17403\nMASTER | 0.064\" + 0.006 0.42+0.04 0.0767\u00a30.005 0.49+0.04 | 0.27+0.05 2.4404\nXGBoost 0.040 + 0.000 0.37 + 0.01 0.047 + 0.000 0.42 + 0.01 0.08 + 0.02 0640.2\nLSTM 0.028 40.002 0.320.020.0839 0.002 0.41 \u00a30.03 | 0.094002 0.9402\nGRU 0.039 + 0.002 0.36 + 0.05 0.044 + 0.003 0.39 + 0.07 0.07 + 0.04 0640.3\n\ncsisoo | TN 0.038 40.002 0.8340.04 0.0454.0.002 0.3840.05 | 0.054004 04403\n\u2018Transformer 0.040 + 0.003 0.43 + 0.03 0.048 + 0.003 0.51 + 0.05 0.13 + 0.04 11403\nGAT 0.043 +0.002 0.394 0.020.042 4.0.002 0.35 40.02 | 0.104004 0.7403\nDTML 0.039 + 0.004 0.29 + 0.03 0.053 + 0.008 0.37 + 0.06 0.16 + 0.03 1340.2\nMASTER | 0.052\"+0.006 0.40+0.06 0.06640.007  0.4840.06 | 0.287 \u00a30.02 2.3\u00b0\u00a30.3\n\nTable 1: Overall performance comparison. The best results are in bold and the second-best results are underlined. And * denotes\nstatistically significant improvement (measured by t-test with p-value < 0.01) over all baselines.\n\nModel | Ic IcIR RankIC RankICIR_ | AR IR\n\n(MA)STER 0.064+0.003 0.43+0.02 0.074+0.004 0.48+0.04 | 0.25+0.03 2140.3\n(MA)STER-Bi | 0.058+0.005 0.88+ 0.04 0.066 + 0.008 =\u2014-0.41+ 0.05 | 0.19+0.03 16+0.2\nNaive 0.041+0.008 0.304005 0.04620.007 0.32+0.04 | 0.18+0.05 16406\nClustering 0.044+0.003 = 0.36+0.02 0.049+ 0.005 = 0.39 + 0.04 | 0.184004 L7+03\n\nTable 2: Experiments on CS1300 to validate the effectiveness of proposed stock transformer architecture. The best results are in\n\nbold and the second-best results are underlined.\n\nmostly consider the 30 top-performed stocks. The achieve-\nments in both types of metrics imply that MASTER is of\ngood predicting ability on the whole stock set without sacri-\nficing the accuracy of the important stocks. The significant\nimprovements cast light on the importance of stock correla-\ntion modeling, so each stock can also benefit from the his-\ntorical signals of other momentarily correlated stocks. We\nalso observe all methods gain better performance on CS1300\nover CSI800. We believe it is because CSI300 consists of\ncompanies with larger capitalization whose stock prices are\nmore predictable. When compared to the existing stock cor-\nrelation method (i.e, DTML), MASTER outperforms in all\n6 metrics, which tells our proposed Market-Guided Gat-\ning and aggregation techniques are more efficient in mining\ncross-stock information than existing literature.\n\nStock Transformer Architecture (RQ2)\n\nWe validate the effectiveness of our specialized stock trans-\nformer architecture by experiments on four settings. (1)\n(MA)STER, which is our stock transformer without the gat-\ning. (2) (MA)STER-Bi, in which we substitute the single-\nlayer transformer encoder with a bi-directional LSTM to\nevince that the effectiveness of our proposed architecture\nis not coupled with strong sequential encoders. (3) Naive,\nwhich directly performs information aggregation among 7 x\n|S| tokens. (4) Clustering, in which we adapt the Local Sen-\nsitive Hashing (Kitaev, Kaiser, and Levskaya 2020) to allo-\n\ncate all tokens into 10 buckets by similarity and perform ag-\ngregation within each group, which is a classic task-agnostic\ntechnique to reduce the scale of the attention field. For a fair\ncomparison, in (3) and (4), we first use the same transformer\nencoder to extract token embedding and then use the same\nmulti-head attention mechanism as in our stock transformer,\nso the only difference is the attention field. Due to resource\nlimits, we only conduct experiment on CSI300 dataset. The\nresults in Table 2 illustrate the efficacy of our tailored stock\ntransformer architecture, which performs intra-stock aggre-\ngation and inter-stock aggregation alternatively.\n\nAblation Study (RQ3)\n\nFirst, we conduct ablation study on (NV, ,. V2) combination.\n\u2018The results of CS1300 are shown in Figure 3 and the results\non CSI800 are similar. The difference among head combina-\ntions is not significant compared with the inherent variance\nunder each setting. In the studied range, most settings con-\nsistently performed better than the baselines.\n\nSecond, we study the influence of temperature \u00a7 in the\ngating mechanism. As explained before, a smaller 9 forces\na stronger feature selection while a larger 8 turns off the gat-\ning effect. Figure 4 shows the performance with varying 8.\nThe CSI300 is a relatively easier dataset where most fea-\ntures are quite effective, so the temperature is expected to\nbe larger to relax the feature selection, while more powerful\nfeature selection intervention is needed for the sophisticated\n\nIc cir Rankic\n\nRarkiCla AR IR\n\nFigure 3: The average and standard deviation of metrics with different (Ni, N2) combinations on CS1300.\n\nankle\n\naa\n\nFigure 4: MASTER performance with varying \u00a7. The horizontal dash lines are performance without market-guided gating.\n\ncnecysi601857) ae\nIeACSHEDII3E 002\nCATLISZ 500750) ua\nFigure 5: The correlation towards three target stocks on Aug\n19th, 2022. The y-axis is time steps in the lookback win-\n\ndow and the x-axis is source stocks. Avg. denotes the evenly\ndistributed value.\n\nCRACK CATE CATLA CNPC. 190 CNPC A ICRC 19th CREE eMC 78h\n\nTijasers faaesers\n\n3\nTisaseoe\n\nFigure 6: Cross-time correlation of stock pairs on Aug 19th\nand 25th, 2022. The x-axis is the source time steps and the\ny-axis is the target time steps.\n\nCSI800 dataset whose 9 of the best performance is smaller.\n\nVisualization of Attention Maps (RQ4)\n\nWe show how MASTER captures the momentary and cross-\ntime stock correlation that previous methods are not ex-\npressive enough to model. Figure 5 shows the inter-stock\nattention map at different time steps in the lookback win-\ndow. We choose three representative stocks as the target\nand sample 100 random stocks as sources for visualiza-\ntion. The highlighted part is scattered instead of exhibit-\ning neat strips, implying that the correlation is momentary\nrather than long-standing. Also, the inter-stock correlation\nis sparse, with only a few stocks having strong correlations\ntoward the target stocks. Figure 6 displays the correlation\nbetween stock pairs to show how the correlation resides in\ntime. From source stock v to target stock u, we compute\nTucvli, fj] = S}/i, j]S?[u, v] as the r x 7 correlation map,\nwhile S* and S* are the intra-stock and inter-stock atten-\ntion map. First, the highlighted blocks are not centered on\nthe diagonal, because the stock correlation is usually cross-\ntime rather than temporally aligned. Second, the left two\nfigures are totally different, illustrating that correlation is\n\nhighly asymmetric between u \u00a2~ v and uv \u00a2 u. Third, the\nimportance of mined correlation changes slowly when the\nlookback window slides to forecast on different dates. For\nexample, blocked regions in the right two figures correspond\nto the same absolute time scope of different prediction dates,\nwhose patterns are to a certain degree similar.\n",
                        "extracted-code": "",
                        "gpt-text-processed": "In this section, we discuss the experiments conducted to examine the effectiveness of our model, MASTER, in predicting stock prices. We focus on four key questions:\n\n1. **Overall Performance**: How does MASTER perform when compared to other leading methods?\n2. **Effectiveness of Architecture**: Is our specific design for the stock prediction tool working well?\n3. **Impact of Settings**: How do different settings (called hyperparameters) influence how well MASTER performs?\n4. **Insights on Stock Relationships**: What can we learn about how stocks relate to one another by looking at our model's attention maps?\n\n### Datasets\nTo evaluate our model, we used data from the Chinese stock market, specifically two groups of stocks: CSI300 and CSI800, which include 300 and 800 of the largest stocks listed on the Shanghai and Shenzhen Stock Exchanges. We gathered daily data from 2008 to 2022. To train our model, we used data from the first quarter of 2008 to the first quarter of 2020, set aside data from the second quarter of 2020 to check our model's accuracy, and used the last few periods (from the third quarter of 2020 to the end of 2022) to test how well our model predicts future prices.\n\n### Baselines\nWe compared MASTER\u2019s performance against several other forecasting methods. These included diverse approaches such as:\n- **XGBoost**: A decision-tree based model recognized for its strong performance.\n- **LSTM and GRU**: Types of models that analyze sequences of data over time.\n- **Transformers**: A popular approach in machine learning that looks at time series data.\n- **Graph Attention Networks (GAT)**: A technique that organizes information by using graphs.\n- **Dynamic Time Market Linkages (DTML)**: A method focusing on the relationships between different stocks, which also considers market information.\n\n### Evaluation\nTo measure how well MASTER and its competitors are performing, we looked at two types of metrics: \n- **Ranking Metrics**: These help us see how well the model ranks stocks.\n- **Portfolio Metrics**: These assess how profitable investments could be based on model predictions.\n\nBy simulating trades based on our model's predictions, we evaluated potential returns and risks.\n\n### Implementation\nWe built MASTER using a programming framework called PyTorch and followed guidelines from an open-source investment platform called Qlib to implement our model and compare it with others. We tuned various settings, like the number of layers and size of the models to enhance performance. Each model was trained multiple times to ensure accuracy, using powerful computer hardware for processing.\n\n### Results\nIn our experiments, MASTER consistently outperformed the other methods in most metrics, showing significant improvements\u2014around 13% in ranking metrics and 47% in investment-related metrics. This indicates that MASTER can predict not just individual stocks but also understand the relationships between them, which is crucial for making informed investment decisions.\n\n### Stock Transformer Architecture\nWe tested how effective our chosen architecture is by comparing it to several variations. These included using simpler methods as benchmarks to highlight the unique advantages of our design. We found that our architecture really shines when it comes to combining information across different stocks.\n\n### Ablation Study\nTo understand the different components of our model, we looked into how specific settings and parameters influenced performance. Interestingly, minor changes often didn't lead to drastic differences, highlighting MASTER\u2019s resilience to variable adjustments.\n\n### Visualization of Attention Maps\nFinally, we created visual representations to understand how MASTER identifies relationships between stocks over time. The maps showed that relationships can be fleeting, indicating that today's relevant data might not always be relevant tomorrow. This insight is essential for understanding the dynamic nature of the stock market and improving predictions.\n\nOverall, our research demonstrates that MASTER is a powerful tool for analyzing stock predictions, helping investors understand how different stocks might behave together."
                    },
                    {
                        "section_id": 1.6,
                        "section_name": "Conclusion",
                        "section_path": "./screenshots-images-2/chapter_1/section_6",
                        "images": [
                            "./screenshots-images-2/chapter_1/section_6/bc7f9e42-d4aa-42d9-bc76-5d7961801049.png"
                        ],
                        "code_images": [],
                        "status": "images tested ok",
                        "errors": [],
                        "extracted-text": "We introduce a novel method MASTER for stock price\nforecasting, which models the realistic stock correlation\nand guide feature selection with market information. MAS-\nTER consists of five steps, market-guided gating, intra-stock\naggregation, inter-stock aggregation, temporal aggregation,\nand prediction. Experiments on the Chinese market with 2\nstock universe shows that MASTER achieves averagely 13%\nimprovements on ranking metrics and 47% on portfolio-\nbased metrics compared with all baselines. Visualization of\nattention maps reveals the de-facto momentary and cross-\ntime stock correlation. In conclusion, we provide a more\ngranular perspective for studying stock correlation, while\nalso indicating an effective application of market informa-\ntion. Future work can explore to mine stock correlations of\nhigher quality and study other uses of market information.\n",
                        "extracted-code": "",
                        "gpt-text-processed": "We have developed a new method called MASTER for predicting stock prices, which helps us understand how different stocks are related to one another and uses market trends to choose the most relevant factors for analysis. The MASTER process involves five key steps: First, it evaluates how the market influences stock prices (market-guided gating); next, it looks at the relationships within a single stock (intra-stock aggregation) and then across different stocks (inter-stock aggregation). It also considers how these relationships evolve over time (temporal aggregation) and finally makes predictions based on all of this information. \n\nTests conducted on two groups of stocks in the Chinese market showed that MASTER improved our ability to rank stocks by an average of 13% and enhanced the performance of investment portfolios by 47% compared to traditional methods. Additionally, by using visual tools, we can better understand the immediate and long-term relationships between stocks.\n\nIn summary, MASTER offers a detailed approach for examining how stocks are connected and demonstrates effective ways to utilize market data. Looking ahead, there is potential to further enhance our understanding of these stock relationships and explore additional ways to apply market insights."
                    }
                ]
            }
        ]
    }
}